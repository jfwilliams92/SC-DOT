{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC DOT Data and Zillow Home Sales - How has traffic in South Carolina changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of my least favorite parts of the day is my daily commute. Anecdotally, I feel as if traffic has worsened/increased in South Carolina since I moved here in 2007, and it's worsening at an increasing rate every year.\n",
    "I stumbled across some data on the SC-DOT GIS page that I thought might help confirm or deny my suspicion.\n",
    "Here's where the data can be downloaded - https://www.scdot.org/travel/travel-mappinggis.aspx.\n",
    "The data in question that I'm examining is Annual Average Daily Traffic counts from the years 2009 - 2018.\n",
    "This data is recorded at the level of StationID and RouteIdentifier with additional information as well, including Latitude and Longitude of the recording Station.\n",
    "I downloaded the .zip files for each separately and then renamed them and put them into one folder - shp_files.\n",
    "The data comes in both .shp and .dbf (Xbase) format.\n",
    "More about these file types here:\n",
    "TODO\n",
    "\n",
    "SCDOT has some interactive ArcGIS maps with these data points plotted already - http://scdot.maps.arcgis.com/apps/MinimalGallery/index.html?appid=7420aa1f39d84400a6d7e8cdaacc89cd\n",
    "\n",
    "However, these plots don't fully convey (to me) the true amount of traffic, as all station points are plotted as little cars with no information about AADT, nor the change in traffic patterns year over year.\n",
    "Nor do they address any underlying causes of what may be driving potential traffic pattern changes.\n",
    "\n",
    "Tangentially, SCDOT does provide a wealth of other data for citizens to browse, some of which look quite interesting.\n",
    "http://scdot.maps.arcgis.com/apps/MinimalGallery/index.html?appid=e8ace63de0e6423394d04c9c091e893b#\n",
    "I am particularly interested in how the \"South Carolina Roads by Pavement Status\" dataset folds into the questions at hand here, but that goes beyond the scope of this post. Perhaps to be addressed later.\n",
    "\n",
    "Getting back on topic, one of the most intuitive drivers of change in traffic patterns could be popluation growth/decline in the areas nearby. I chose to use a data set from Zillow - https://www.zillow.com/research/data/ - that details Monthly Home Sales by ZipCode as a proxy to population growth per Zip Code.\n",
    "\n",
    "Finally, I also downloaded a data set from OpenDataSoft - https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/table/ - that cross references ZipCode to latitude and longitude. I only downloaded data for South Carolina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What the data looks like and what does it take to get into a unified format?\n",
    "\n",
    "2) Has overall traffic increased in SC over the past 10 years?\n",
    "\n",
    "3) Are there are any areas in SC that show more aggressive traffic growth?\n",
    "\n",
    "4) Does number of home sales in Zip Codes within a certain radius of a station (e.g. 50 km) have any bearing on traffic numbers the next or same year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simpledbf import Dbf5\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change into the directory where the shp files live\n",
    "os.chdir(\"./shp_files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read GIS dbf data into dataframes, one file for each year between 2009 and 2018\n",
    "shp_dfs = {}\n",
    "for root, dirs, files in os.walk(os.getcwd()):\n",
    "    for file in files:\n",
    "        if file.endswith(\".dbf\"):\n",
    "            # print(file.split('.')[0])\n",
    "            dbf = Dbf5(os.path.join(root, file))\n",
    "            df = dbf.to_dataframe()\n",
    "            shp_dfs[file.split('.')[0]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyNumb</th>\n",
       "      <th>RouteTypeN</th>\n",
       "      <th>RouteType1</th>\n",
       "      <th>RouteNumbe</th>\n",
       "      <th>MeterMileP</th>\n",
       "      <th>BeginMileP</th>\n",
       "      <th>EndMilePoi</th>\n",
       "      <th>StationNum</th>\n",
       "      <th>Termini</th>\n",
       "      <th>FactoredAA</th>\n",
       "      <th>FactoredA1</th>\n",
       "      <th>MapLRS</th>\n",
       "      <th>Status1</th>\n",
       "      <th>ID1</th>\n",
       "      <th>RouteAuxil</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.82</td>\n",
       "      <td>101.0</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>34.41979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4.345</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.91</td>\n",
       "      <td>103.0</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (MAIN ST W)</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.35324</td>\n",
       "      <td>34.38344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>5.633</td>\n",
       "      <td>4.91</td>\n",
       "      <td>7.28</td>\n",
       "      <td>105.0</td>\n",
       "      <td>SC 184 (MAIN ST W) TO County Line - GREENWOOD</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>34.37099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>109.0</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71...</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38017</td>\n",
       "      <td>34.17889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>111.0</td>\n",
       "      <td>SC 71 (N MAIN ST) TO L- 170 (RICHEY ST)</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38114</td>\n",
       "      <td>34.18369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CountyNumb  RouteTypeN RouteType1  RouteNumbe  MeterMileP  BeginMileP  \\\n",
       "0         1.0         2.0         US       178.0       1.196        0.00   \n",
       "1         1.0         2.0         US       178.0       4.345        3.82   \n",
       "2         1.0         2.0         US       178.0       5.633        4.91   \n",
       "3         1.0         4.0         SC        20.0       0.074        0.00   \n",
       "4         1.0         4.0         SC        20.0       0.439        0.18   \n",
       "\n",
       "   EndMilePoi  StationNum                                            Termini  \\\n",
       "0        3.82       101.0        County Line - ANDERSON TO S- 166 (DRAKE RD)   \n",
       "1        4.91       103.0            S- 166 (DRAKE RD) TO SC 184 (MAIN ST W)   \n",
       "2        7.28       105.0      SC 184 (MAIN ST W) TO County Line - GREENWOOD   \n",
       "3        0.18       109.0  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71...   \n",
       "4        0.45       111.0            SC 71 (N MAIN ST) TO L- 170 (RICHEY ST)   \n",
       "\n",
       "   FactoredAA  FactoredA1        MapLRS Status1  ID1 RouteAuxil CountyName  \\\n",
       "0      4300.0      2018.0  01020017800E     NaN    1        NaN  ABBEVILLE   \n",
       "1      4600.0      2018.0  01020017800E     NaN    2        NaN  ABBEVILLE   \n",
       "2      3600.0      2018.0  01020017800E     NaN    3        NaN  ABBEVILLE   \n",
       "3      4900.0      2018.0  01040002000E     NaN    4        NaN  ABBEVILLE   \n",
       "4      2200.0      2018.0  01040002000E     NaN    5        NaN  ABBEVILLE   \n",
       "\n",
       "        Long       Lat  \n",
       "0  -82.38521  34.41979  \n",
       "1  -82.35324  34.38344  \n",
       "2  -82.33765  34.37099  \n",
       "3  -82.38017  34.17889  \n",
       "4  -82.38114  34.18369  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give an ol look see at the most recent year\n",
    "shp_dfs['2018'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by eyeballing, it can be surmised what each field name means, along with the helpful data dictionary supplied by SCDOT.\n",
    "For example \"FactorerA1\" is clearly the year of this particular dataset, while \"Long\" and \"Lat\" hold the longitude and latitude of the datapoint.\n",
    "\n",
    "Next, we'll check to see if the column names match across all the dataframes we have, one for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the columns in the dfs match - per df, convert columns to sets. Check the intersection of all sets.\n",
    "col_sets = map(lambda x: set(x.columns), shp_dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the list of column sets into set.intersection, which returns common elements in set\n",
    "common_cols = set.intersection(*col_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see what's common between the dfs\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! There's only one column that is common between all of the dataframes. Let's dig in a little more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CountyNumb', 'RouteTypeN', 'RouteType1', 'RouteNumbe', 'MeterMileP',\n",
      "       'BeginMileP', 'EndMilePoi', 'StationNum', 'Termini', 'FactoredAA',\n",
      "       'FactoredA1', 'MapLRS', 'Status1', 'ID1', 'RouteAuxil', 'CountyName',\n",
      "       'Long', 'Lat'],\n",
      "      dtype='object') 18\n",
      "Index(['Station_Nu', 'Route_LRS', 'County_ID', 'Route_Type', 'Route_Numb',\n",
      "       'Route_Auxi', 'Descriptio', 'Count', 'Year', 'ID1'],\n",
      "      dtype='object') 10\n",
      "Index(['STATION_NU', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'ROUTE_TYPE', 'ROUTE_NUMB', 'ROUTE_AUX',\n",
      "       'COUNT', 'YEAR', 'DESCRIPTIO', 'ID1', 'GMRotation'],\n",
      "      dtype='object') 15\n",
      "Index(['CountyName', 'RouteTypeN', 'RouteNumbe', 'RouteAuxil', 'MeterMileP',\n",
      "       'BegiNMileP', 'EndMilePoi', 'StationNum', 'Termini', 'FactoredAA',\n",
      "       'FactoredA1', 'MapLRS', 'Status1', 'ID1', 'Latitude', 'Longitude'],\n",
      "      dtype='object') 16\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'ATR_NUM', 'MAP', 'RouteNum', 'termini', 'Count', 'Year',\n",
      "       'County', 'RouteType', 'AUX', 'GMRotation'],\n",
      "      dtype='object') 17\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'ATR_NUM', 'County', 'Station_Nu',\n",
      "       'Route_Type', 'Route_Numb', 'AUX', 'Count', 'Year', 'Descriptio',\n",
      "       'GMRotation'],\n",
      "      dtype='object') 18\n",
      "Index(['Route_Type', 'Route_Numb', 'Route_Auxi', 'Meter_Mile', 'Begin_Mile',\n",
      "       'End_MilePo', 'Station_Nu', 'Termini', 'Factored_A', 'Factored_1',\n",
      "       'RouteLRS', 'ID1', 'County_Nam'],\n",
      "      dtype='object') 13\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'county', 'F2', 'station1', 'rtetype',\n",
      "       'rtenumb', 'rteaux', 'bmp', 'emp', 'termini', 'rtelrs', 'CONNN', 'aadt',\n",
      "       'aadtyr', 'GMRotation'],\n",
      "      dtype='object') 22\n",
      "Index(['STATION_NU', 'COUNT', 'DESCRIPTIO', 'YEAR', 'ROUTE_TYPE', 'ROUTE_NUMB',\n",
      "       'ROUTE_AUX', 'MILE_POINT', 'ROUTE_LRS', 'COUNTY_ID', 'MAP_TYPE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ID1', 'GMRotation'],\n",
      "      dtype='object') 15\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'CountyName', 'RouteType', 'rtenum', 'AUX', 'ATR_NUM',\n",
      "       'MAP', 'termini', 'Year', 'Count', 'ID2', 'GMRotation'],\n",
      "      dtype='object') 18\n"
     ]
    }
   ],
   "source": [
    "# Let's check to see what the actual columns are named and how many there are\n",
    "for df in shp_dfs.values():\n",
    "    print(df.columns, len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see that we have different numbers of columns per year, and that most of the columns are all named differently. We'll try to address that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we'll get better results if we do some simple string formatting first\n",
    "for df in shp_dfs.values():\n",
    "    df.columns = [c.replace('_', '').lower().strip() for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check set intersection again\n",
    "col_sets = list(map(lambda x: set(x.columns), shp_dfs.values()))\n",
    "set.intersection(*col_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still only one column that's the same! Time to do some brute-force mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 Index(['countynumb', 'routetypen', 'routetype1', 'routenumbe', 'metermilep',\n",
      "       'beginmilep', 'endmilepoi', 'stationnum', 'termini', 'factoredaa',\n",
      "       'factoreda1', 'maplrs', 'status1', 'id1', 'routeauxil', 'countyname',\n",
      "       'long', 'lat'],\n",
      "      dtype='object') 18\n",
      "2013 Index(['stationnu', 'routelrs', 'countyid', 'routetype', 'routenumb',\n",
      "       'routeauxi', 'descriptio', 'count', 'year', 'id1'],\n",
      "      dtype='object') 10\n",
      "2010 Index(['stationnu', 'milepoint', 'routelrs', 'maptype', 'latitude',\n",
      "       'longitude', 'countyid', 'routetype', 'routenumb', 'routeaux', 'count',\n",
      "       'year', 'descriptio', 'id1', 'gmrotation'],\n",
      "      dtype='object') 15\n",
      "2016 Index(['countyname', 'routetypen', 'routenumbe', 'routeauxil', 'metermilep',\n",
      "       'beginmilep', 'endmilepoi', 'stationnum', 'termini', 'factoredaa',\n",
      "       'factoreda1', 'maplrs', 'status1', 'id1', 'latitude', 'longitude'],\n",
      "      dtype='object') 16\n",
      "2015 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'atrnum', 'map', 'routenum', 'termini', 'count', 'year',\n",
      "       'county', 'routetype', 'aux', 'gmrotation'],\n",
      "      dtype='object') 17\n",
      "2009 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyid', 'atrnum', 'county', 'stationnu', 'routetype',\n",
      "       'routenumb', 'aux', 'count', 'year', 'descriptio', 'gmrotation'],\n",
      "      dtype='object') 18\n",
      "2017 Index(['routetype', 'routenumb', 'routeauxi', 'metermile', 'beginmile',\n",
      "       'endmilepo', 'stationnu', 'termini', 'factoreda', 'factored1',\n",
      "       'routelrs', 'id1', 'countynam'],\n",
      "      dtype='object') 13\n",
      "2012 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyid', 'county', 'f2', 'station1', 'rtetype',\n",
      "       'rtenumb', 'rteaux', 'bmp', 'emp', 'termini', 'rtelrs', 'connn', 'aadt',\n",
      "       'aadtyr', 'gmrotation'],\n",
      "      dtype='object') 22\n",
      "2011 Index(['stationnu', 'count', 'descriptio', 'year', 'routetype', 'routenumb',\n",
      "       'routeaux', 'milepoint', 'routelrs', 'countyid', 'maptype', 'latitude',\n",
      "       'longitude', 'id1', 'gmrotation'],\n",
      "      dtype='object') 15\n",
      "2014 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyname', 'routetype', 'rtenum', 'aux', 'atrnum',\n",
      "       'map', 'termini', 'year', 'count', 'id2', 'gmrotation'],\n",
      "      dtype='object') 18\n"
     ]
    }
   ],
   "source": [
    "for year, df in shp_dfs.items():\n",
    "    print(year, df.columns, len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that will allow us to rename columns from key to value.\n",
    "# we won't map every column - only keep a subset\n",
    "\n",
    "col_mapping_dict = {\n",
    "    **dict.fromkeys(['station', 'stationnu', 'stationnum'], 'station_id'),\n",
    "    **dict.fromkeys(['latitude', 'lat'], 'latitude'),\n",
    "    **dict.fromkeys(['longitude', 'long'], 'longitude'), \n",
    "    **dict.fromkeys(['aadtyr', 'year', 'factored1', 'factoreda1'], 'year'),\n",
    "    **dict.fromkeys(['routelrs', 'maplrs'], 'route_identifier'),\n",
    "    **dict.fromkeys(['termini', 'descriptio'], 'route_leg_descrip'),\n",
    "    # **dict.fromkeys(['beginmilep', 'beginmile'], 'route_leg_beginmile'),\n",
    "    # **dict.fromkeys(['endmilepo', 'endmilepoi'], 'route_leg_endmile'),\n",
    "    **dict.fromkeys(['routetype', 'rtetype', 'routetypen'], 'route_type_id'),   # has to be a numeric column as well, some collision here\n",
    "    **dict.fromkeys(['rtenum', 'rtenumb', 'routenumb', 'routenum', 'routenumbe'], 'route_number'),\n",
    "    **dict.fromkeys(['county', 'countyname', 'countynam'], 'county_name'),\n",
    "    # **dict.fromkeys(['countyid', 'countynumb'], 'county_id'),\n",
    "    **dict.fromkeys(['aadt', 'factoreda', 'count', 'factoredaa'], 'average_daily_traffic'),\n",
    "    **dict.fromkeys(['id1'], 'row_number')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns as per mapping dict\n",
    "shp_dfs_renamed = {year: df.rename(columns=col_mapping_dict) for year, df in shp_dfs.items()}\n",
    "# drop columns not mapped\n",
    "shp_dfs_renamed = {year: df.drop([c for c in df.columns if c not in col_mapping_dict.values()], axis=1) for year, df in shp_dfs_renamed.items()}\n",
    "# drop any duplicated columns\n",
    "shp_dfs_renamed = {year: df.loc[:, ~df.columns.duplicated()] for year, df in shp_dfs_renamed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still some collision - column name can mean different things in different years.\n",
    "# rename some columns that aren't right\n",
    "shp_dfs_renamed['2010'].rename(columns={'route_type_id':'route_type'}, inplace=True)\n",
    "shp_dfs_renamed['2016'].rename(columns={'route_type_id':'route_type'}, inplace=True)\n",
    "shp_dfs_renamed['2015'].rename(columns={'route_type_id':'route_type'}, inplace=True)\n",
    "shp_dfs_renamed['2017'].rename(columns={'route_type_id':'route_type'}, inplace=True)\n",
    "shp_dfs_renamed['2011'].rename(columns={'route_type_id':'route_type'}, inplace=True)\n",
    "shp_dfs_renamed['2014'].rename(columns={'route_type_id':'route_type'}, inplace=True)\n",
    "shp_dfs_renamed['2017'].rename(columns={'county_name':'county_id'}, inplace=True)\n",
    "shp_dfs_renamed['2009'].drop('county_name', axis=1, inplace=True)\n",
    "shp_dfs_renamed['2012'].drop('county_name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - columns should now all be corrently named across years. We also dropped a subset of the columns, only keeping a subset.\n",
    "Let's check now to make sure that the records we have are unique where they're supposed to be - namely, we should only have one row per year for a stationid/routeid/routenumber combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       32020000100N      1.0             2\n",
      "133.0       28020000100N      1.0             2\n",
      "173.0       10020007800E      78.0            2\n",
      "192.0       30040006600E      66.0            3\n",
      "            36040006600E      66.0            2\n",
      "278.0       30090028900N      289.0           2\n",
      "279.0       15070003600E      36.0            2\n",
      "306.0       24070005000E      50.0            2\n",
      "321.0       21070013200E      132.0           2\n",
      "411.0       14070010400E      104.0           2\n",
      "413.0       02070004600E      46.0            2\n",
      "415.0       13090015900N      159.0           2\n",
      "426.0       10070004600E      46.0            2\n",
      "429.0       10070010300N      103.0           2\n",
      "463.0       39070030400E      304.0           2\n",
      "492.0       16070016400E      164.0           2\n",
      "495.0       02070018200E      182.0           2\n",
      "498.0       04070009800E      98.0            2\n",
      "509.0       02070030900N      309.0           2\n",
      "551.0       42090056300N      563.0           2\n",
      "557.0       39070035400E      354.0           2\n",
      "            39090035400E      354.0           2\n",
      "584.0       43070006900N      69.0            2\n",
      "713.0       04090117900N      1179.0          2\n",
      "850.0       42070059000E      590.0           2\n",
      "897.0       38070025800E      258.0           2\n",
      "911.0       42090098600E      986.0           2\n",
      "969.0       42090019100N      191.0           2\n",
      "2419.0      21010009500N      95.0            2\n",
      "dtype: int64\n",
      "2013 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       13020000100N      1.0             2\n",
      "113.0       36070064200E      642.0           2\n",
      "127.0       46070011800E      118.0           2\n",
      "133.0       28020000100N      1.0             2\n",
      "160.0       32070016200E      162.0           2\n",
      "                                             ..\n",
      "956.0       42070103800E      1038.0          2\n",
      "969.0       42090019100N      191.0           3\n",
      "989.0       42090048900N      489.0           2\n",
      "1037.0      42090098900N      989.0           2\n",
      "2419.0      21010009500N      95.0            2\n",
      "Length: 100, dtype: int64\n",
      "2010 \n",
      " station_id  route_identifier  route_number\n",
      "169.0       04040002400E      24.0            2\n",
      "170.0       40020007600E      76.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "            22070039100N      391.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "2601.0      02010052000E      520.0           2\n",
      "dtype: int64\n",
      "2016 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       13020000100N      1.0             2\n",
      "            32020000100N      1.0             2\n",
      "113.0       36070064200E      642.0           2\n",
      "133.0       28020000100N      1.0             2\n",
      "173.0       10020007800E      78.0            2\n",
      "189.0       30040006600E      66.0            3\n",
      "            36040006600E      66.0            2\n",
      "277.0       30070028900N      289.0           2\n",
      "279.0       15070003600E      36.0            2\n",
      "296.0       02090010500N      105.0           2\n",
      "329.0       06070016800E      168.0           2\n",
      "331.0       35070006600E      66.0            2\n",
      "359.0       04070014100N      141.0           2\n",
      "411.0       14070010400E      104.0           2\n",
      "413.0       02070004600E      46.0            2\n",
      "415.0       13090015900N      159.0           2\n",
      "423.0       40070172200E      1722.0          2\n",
      "426.0       10070004600E      46.0            2\n",
      "429.0       10070010300N      103.0           2\n",
      "437.0       02070055900N      559.0           2\n",
      "463.0       39070030400E      304.0           2\n",
      "494.0       30070049900N      499.0           2\n",
      "495.0       02070018200E      182.0           2\n",
      "498.0       04070009800E      98.0            2\n",
      "551.0       42090056300N      563.0           2\n",
      "557.0       39070035400E      354.0           2\n",
      "            39090035400E      354.0           2\n",
      "584.0       43070006900N      69.0            2\n",
      "601.0       10070066900N      669.0           2\n",
      "625.0       38070009200E      92.0            2\n",
      "678.0       23090031100N      311.0           3\n",
      "713.0       04090117900N      1179.0          2\n",
      "815.0       23070196700N      1967.0          2\n",
      "850.0       42070059000E      590.0           2\n",
      "897.0       38070025800E      258.0           2\n",
      "911.0       42090098600E      986.0           2\n",
      "969.0       42090019100N      191.0           2\n",
      "2419.0      21010009500N      95.0            2\n",
      "dtype: int64\n",
      "2015 \n",
      " Series([], dtype: int64)\n",
      "2009 \n",
      " station_id  route_identifier  route_number\n",
      "331.0       11070020900N      209.0           2\n",
      "dtype: int64\n",
      "2017 \n",
      " station_id  route_identifier  route_number\n",
      "133.0       28020000100N      1.0             2\n",
      "173.0       10020007800E      78.0            2\n",
      "192.0       30040006600E      66.0            3\n",
      "            36040006600E      66.0            2\n",
      "277.0       30070028900N      289.0           2\n",
      "279.0       15070003600E      36.0            2\n",
      "321.0       21070013200E      132.0           2\n",
      "411.0       14070010400E      104.0           2\n",
      "413.0       02070004600E      46.0            2\n",
      "429.0       10070010300N      103.0           2\n",
      "463.0       39070030400E      304.0           2\n",
      "495.0       02070018200E      182.0           2\n",
      "551.0       42090056300N      563.0           2\n",
      "557.0       39090035400E      354.0           2\n",
      "601.0       10070066900N      669.0           2\n",
      "850.0       42070059000E      590.0           2\n",
      "897.0       38070025800E      258.0           2\n",
      "969.0       42090019100N      191.0           2\n",
      "2419.0      21010009500N      95.0            2\n",
      "dtype: int64\n",
      "2012 \n",
      " station_id  route_identifier  route_number\n",
      "170.0       40020007600E      76.0            2\n",
      "279.0       15070003600E      36.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "            22070039100N      391.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "384.0       42070006400E      64.0            3\n",
      "407.0       10070039300N      393.0           2\n",
      "435.0       10070086300N      863.0           2\n",
      "485.0       21070035400E      354.0           2\n",
      "515.0       07070033300N      333.0           2\n",
      "653.0       04090031000E      310.0           2\n",
      "2419.0      21010009500N      95.0            2\n",
      "dtype: int64\n",
      "2011 \n",
      " station_id  route_identifier  route_number\n",
      "100.0       01040018500N      185.0           2\n",
      "            04020002900N      29.0            2\n",
      "            08020001702N      17.0            2\n",
      "            15020001500N      15.0            2\n",
      "            23020017600E      176.0           2\n",
      "                                             ..\n",
      "2520.0      08010052600E      526.0           2\n",
      "2521.0      10010052600W      526.0           2\n",
      "2601.0      02010052000E      520.0           4\n",
      "2603.0      02010052000E      520.0           2\n",
      "2605.0      02010052000E      520.0           2\n",
      "Length: 11242, dtype: int64\n",
      "2014 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       13020000100N      1.0             2\n",
      "113.0       36070064200E      642.0           2\n",
      "127.0       46070011800E      118.0           2\n",
      "133.0       28020000100N      1.0             2\n",
      "160.0       32070016200E      162.0           2\n",
      "                                             ..\n",
      "956.0       42070103800E      1038.0          2\n",
      "969.0       42090019100N      191.0           3\n",
      "989.0       42090048900N      489.0           2\n",
      "1037.0      42090098900N      989.0           2\n",
      "2419.0      21010009500N      95.0            2\n",
      "Length: 102, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# records should be unique across station_id, route_identifier, and route_number - do some verification\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).size()\n",
    "    # print rows where the size of the group is > 1 (duplicates)\n",
    "    print(year,'\\n', temp_df.loc[temp_df > 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that we have some duplicates, or we think we have duplicates. We'll define a quick function to spot check some records and get a sense of why rows are duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>53400.0</td>\n",
       "      <td>SEVEN FARMS RD TO S- 97 (CHARLESTON)</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>I-</td>\n",
       "      <td>526.0</td>\n",
       "      <td>08010052600E</td>\n",
       "      <td>32:51:39.5474</td>\n",
       "      <td>-79:53:52.4178</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13028</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>53400.0</td>\n",
       "      <td>SEVEN FARMS RD TO S- 97 (CHARLESTON)</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>I-</td>\n",
       "      <td>526.0</td>\n",
       "      <td>08010052600E</td>\n",
       "      <td>32:51:39.5474</td>\n",
       "      <td>-79:53:52.4178</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_id  average_daily_traffic  \\\n",
       "1675       2520.0                53400.0   \n",
       "13028      2520.0                53400.0   \n",
       "\n",
       "                          route_leg_descrip    year route_type  route_number  \\\n",
       "1675   SEVEN FARMS RD TO S- 97 (CHARLESTON)  2011.0         I-         526.0   \n",
       "13028  SEVEN FARMS RD TO S- 97 (CHARLESTON)  2011.0         I-         526.0   \n",
       "\n",
       "      route_identifier       latitude       longitude  row_number  \n",
       "1675      08010052600E  32:51:39.5474  -79:53:52.4178        1676  \n",
       "13028     08010052600E  32:51:39.5474  -79:53:52.4178        1676  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can spot check some of these to see what's up with the records\n",
    "def check_records(year, station_id, route_identifier):\n",
    "    mask = (shp_dfs_renamed[year]['station_id'] == station_id) & (shp_dfs_renamed[year]['route_identifier'] == route_identifier)\n",
    "    return shp_dfs_renamed[year].loc[mask]\n",
    "\n",
    "check_records('2011', 2520.0, '08010052600E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing a few sets of records leads me to belive that we are in fact dealing with duplicate rows. Most are only unique based on the row number. We'll drop our duplicates to make sure they don't sully the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeballing the records reveals that they are duplicated rows. we'll take the first from every group\n",
    "# head(1) will return the first row per group\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).head(1)\n",
    "    shp_dfs_renamed[year] = temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 \n",
      " Series([], dtype: int64)\n",
      "2013 \n",
      " Series([], dtype: int64)\n",
      "2010 \n",
      " Series([], dtype: int64)\n",
      "2016 \n",
      " Series([], dtype: int64)\n",
      "2015 \n",
      " Series([], dtype: int64)\n",
      "2009 \n",
      " Series([], dtype: int64)\n",
      "2017 \n",
      " Series([], dtype: int64)\n",
      "2012 \n",
      " Series([], dtype: int64)\n",
      "2011 \n",
      " Series([], dtype: int64)\n",
      "2014 \n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#check for dupes again\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).size()\n",
    "    print(year,'\\n', temp_df.loc[temp_df > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>53400.0</td>\n",
       "      <td>SEVEN FARMS RD TO S- 97 (CHARLESTON)</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>I-</td>\n",
       "      <td>526.0</td>\n",
       "      <td>08010052600E</td>\n",
       "      <td>32:51:39.5474</td>\n",
       "      <td>-79:53:52.4178</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id  average_daily_traffic                     route_leg_descrip  \\\n",
       "1675      2520.0                53400.0  SEVEN FARMS RD TO S- 97 (CHARLESTON)   \n",
       "\n",
       "        year route_type  route_number route_identifier       latitude  \\\n",
       "1675  2011.0         I-         526.0     08010052600E  32:51:39.5474   \n",
       "\n",
       "           longitude  row_number  \n",
       "1675  -79:53:52.4178        1676  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify we took the first row in the duplicated group, and that we only have one row returning.\n",
    "check_records('2011', 2520.0, '08010052600E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we've realized that the data can very quite widely from year to year. In order to clean the data up a little bit more, we will try to standardize the data across years. To accomplish this we'll use pandas' update method - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.update.html - and overwrite the values in every year with our standardized values. Because the 2017 and 2018 dataframes don't have all the columns that we're interested in looking at, we'll use the 2016 dataframe to update/overwrite values in a specific subset of columns across all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index of all dfs to the unique identifiers\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.set_index(['station_id', 'route_identifier', 'route_number'])\n",
    "    shp_dfs_renamed[year] = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing year value in any dfs\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df['year'] = df.year.fillna(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county_name                0\n",
       "route_type                 0\n",
       "route_leg_descrip          0\n",
       "average_daily_traffic      0\n",
       "year                       0\n",
       "row_number                 0\n",
       "latitude                 179\n",
       "longitude                179\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2018 and 2017 dfs don't have all the columns, so use the 2016 df to standardize fields\n",
    "# check how many nas in each columns in the 2016 df\n",
    "shp_dfs_renamed['2016'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have some NaNs for lat/long in the 2016 df, so we'll try and reduce those as much as we can.\n",
    "# update 2016 latitudes/longitudes with 2018 latitudes/longitudes where stationid, route_id, and route_number match (index of each df)\n",
    "\n",
    "shp_dfs_renamed['2016'].update(shp_dfs_renamed['2018'][['latitude', 'longitude']])\n",
    "\n",
    "# still some nulls - try the 2015 df\n",
    "shp_dfs_renamed['2016'].update(shp_dfs_renamed['2015'][['latitude', 'longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county_name                0\n",
       "route_type                 0\n",
       "route_leg_descrip          0\n",
       "average_daily_traffic      0\n",
       "year                       0\n",
       "row_number                 0\n",
       "latitude                 153\n",
       "longitude                153\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nas again\n",
    "shp_dfs_renamed['2016'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 and 2017 dfs don't have all the columns, so use the 2016 df to standardize fields\n",
    "# we're standardizing data across the five following columns - DON'T want to overwrite AADT.\n",
    "cols_to_update = ['route_type', 'route_leg_descrip', 'latitude', 'longitude', 'county_name']\n",
    "update_df = shp_dfs_renamed['2016'][cols_to_update]\n",
    "\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df.update(update_df, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we should be ready to combine all the dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all the data frames together\n",
    "traffic_df = pd.concat(shp_dfs_renamed.values(), sort=True, axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_id</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_type_id</th>\n",
       "      <th>row_number</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.41979</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.38344</td>\n",
       "      <td>-82.35325</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.37099</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>SC 184 (N MAIN ST) TO County Line - GREENWOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.17888</td>\n",
       "      <td>-82.38016</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.18359</td>\n",
       "      <td>-82.38115</td>\n",
       "      <td>SC 71 TO L- 170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "0       101.0     01020017800E         178.0                 4300.0   \n",
       "1       103.0     01020017800E         178.0                 4600.0   \n",
       "2       105.0     01020017800E         178.0                 3600.0   \n",
       "3       109.0     01040002000E          20.0                 4900.0   \n",
       "4       111.0     01040002000E          20.0                 2200.0   \n",
       "\n",
       "   county_id county_name  latitude  longitude  \\\n",
       "0        NaN   ABBEVILLE  34.41979  -82.38521   \n",
       "1        NaN   ABBEVILLE  34.38344  -82.35325   \n",
       "2        NaN   ABBEVILLE  34.37099  -82.33765   \n",
       "3        NaN   ABBEVILLE  34.17888  -82.38016   \n",
       "4        NaN   ABBEVILLE  34.18359  -82.38115   \n",
       "\n",
       "                                route_leg_descrip route_type  route_type_id  \\\n",
       "0     County Line - ANDERSON TO S- 166 (DRAKE RD)        NaN            2.0   \n",
       "1         S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)        NaN            2.0   \n",
       "2   SC 184 (N MAIN ST) TO County Line - GREENWOOD        NaN            2.0   \n",
       "3  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71        NaN            4.0   \n",
       "4                                 SC 71 TO L- 170        NaN            4.0   \n",
       "\n",
       "   row_number  year  \n",
       "0           1  2018  \n",
       "1           2  2018  \n",
       "2           3  2018  \n",
       "3           4  2018  \n",
       "4           5  2018  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eyeball the data \n",
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns I actually don't want\n",
    "traffic_df = traffic_df.drop(['county_id', 'route_type_id', 'row_number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.41979</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.38344</td>\n",
       "      <td>-82.35325</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.37099</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>SC 184 (N MAIN ST) TO County Line - GREENWOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.17888</td>\n",
       "      <td>-82.38016</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.18359</td>\n",
       "      <td>-82.38115</td>\n",
       "      <td>SC 71 TO L- 170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "0       101.0     01020017800E         178.0                 4300.0   \n",
       "1       103.0     01020017800E         178.0                 4600.0   \n",
       "2       105.0     01020017800E         178.0                 3600.0   \n",
       "3       109.0     01040002000E          20.0                 4900.0   \n",
       "4       111.0     01040002000E          20.0                 2200.0   \n",
       "\n",
       "  county_name  latitude  longitude  \\\n",
       "0   ABBEVILLE  34.41979  -82.38521   \n",
       "1   ABBEVILLE  34.38344  -82.35325   \n",
       "2   ABBEVILLE  34.37099  -82.33765   \n",
       "3   ABBEVILLE  34.17888  -82.38016   \n",
       "4   ABBEVILLE  34.18359  -82.38115   \n",
       "\n",
       "                                route_leg_descrip route_type  year  \n",
       "0     County Line - ANDERSON TO S- 166 (DRAKE RD)        NaN  2018  \n",
       "1         S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)        NaN  2018  \n",
       "2   SC 184 (N MAIN ST) TO County Line - GREENWOOD        NaN  2018  \n",
       "3  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71        NaN  2018  \n",
       "4                                 SC 71 TO L- 170        NaN  2018  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the head indicates that there are STILL NaNs in the data - the index of our update df (stationid, routeid, routenumber) did not overlap every possible combination in the data across the years. We can handle these NaNs with a similar operation - grouping the data by our unique identifers and then filling within groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fill in cols that are still na by unique id - NOT the average traffic column (main data we care about)\n",
    "# fill nas by group\n",
    "cols_to_fill = ['county_name', 'latitude', 'longitude', 'route_leg_descrip', 'route_type']\n",
    "for col in cols_to_fill:\n",
    "    traffic_df[col] = traffic_df.groupby(['station_id', 'route_identifier', 'route_number'])[col].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id                0\n",
       "route_identifier          0\n",
       "route_number              0\n",
       "average_daily_traffic    69\n",
       "county_name               0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "route_leg_descrip         0\n",
       "route_type                0\n",
       "year                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any nas remaining\n",
    "traffic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop remaining nas - no data!\n",
    "traffic_df = traffic_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some plotting on pct changes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't plot all lats and longs because the lats/longs are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 0\n",
      "2010 404\n",
      "2016 0\n",
      "2015 0\n",
      "2009 442\n",
      "2012 359\n",
      "2011 371\n",
      "2014 163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year, df in shp_dfs_renamed.items():\n",
    "    try:\n",
    "        print(year, df.latitude.str.contains(':').sum())\n",
    "    except:\n",
    "        pass\n",
    "update_df.latitude.str.contains(':').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "      <th>traffic_yearly_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>103549</td>\n",
       "      <td>100.0</td>\n",
       "      <td>08020001702S</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35500.0</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>33:2:13.817</td>\n",
       "      <td>-80:9:13.399</td>\n",
       "      <td>County Line - DORCHESTER TO I- 26</td>\n",
       "      <td>US</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58253</td>\n",
       "      <td>106.0</td>\n",
       "      <td>07020001706N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>32:36:03.3216</td>\n",
       "      <td>-80:45:31.8595</td>\n",
       "      <td>U.S. 17 TO U.S. 21</td>\n",
       "      <td>US</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24188</td>\n",
       "      <td>106.0</td>\n",
       "      <td>07020001706N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>32:36:03.3216</td>\n",
       "      <td>-80:45:31.8595</td>\n",
       "      <td>U.S. 17 TO U.S. 21</td>\n",
       "      <td>US</td>\n",
       "      <td>2010</td>\n",
       "      <td>-0.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92058</td>\n",
       "      <td>106.0</td>\n",
       "      <td>07020001706N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>32:36:03.3216</td>\n",
       "      <td>-80:45:31.8595</td>\n",
       "      <td>US 17 TO US 21</td>\n",
       "      <td>US</td>\n",
       "      <td>2011</td>\n",
       "      <td>-0.097561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80804</td>\n",
       "      <td>106.0</td>\n",
       "      <td>07020001706N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>32:36:03.3216</td>\n",
       "      <td>-80:45:31.8595</td>\n",
       "      <td>US 17 TO US 21</td>\n",
       "      <td>US</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92990</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>10010052600W</td>\n",
       "      <td>526.0</td>\n",
       "      <td>22200.0</td>\n",
       "      <td>CHEROKEE</td>\n",
       "      <td>32:49:14.6714</td>\n",
       "      <td>-79:50:55.6515</td>\n",
       "      <td>S- 56 TO US 17</td>\n",
       "      <td>I-</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.067308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81738</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>10010052600W</td>\n",
       "      <td>526.0</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>CHEROKEE</td>\n",
       "      <td>32:49:14.6714</td>\n",
       "      <td>-79:50:55.6515</td>\n",
       "      <td>S- 56 TO US 17</td>\n",
       "      <td>I-</td>\n",
       "      <td>2012</td>\n",
       "      <td>-0.018018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104258</td>\n",
       "      <td>2521.0</td>\n",
       "      <td>10010052600W</td>\n",
       "      <td>526.0</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>32:49:14.671</td>\n",
       "      <td>-79:50:55.652</td>\n",
       "      <td>S- 56 TO US 17</td>\n",
       "      <td>I-</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.050420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59176</td>\n",
       "      <td>2523.0</td>\n",
       "      <td>10010052600E</td>\n",
       "      <td>526.0</td>\n",
       "      <td>14900.0</td>\n",
       "      <td>CHEROKEE</td>\n",
       "      <td>32:48:47.4084</td>\n",
       "      <td>-79:50:58.4613</td>\n",
       "      <td>US 17 To End</td>\n",
       "      <td>I-</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25113</td>\n",
       "      <td>2523.0</td>\n",
       "      <td>10010052600E</td>\n",
       "      <td>526.0</td>\n",
       "      <td>14500.0</td>\n",
       "      <td>CHEROKEE</td>\n",
       "      <td>32:48:51.8257</td>\n",
       "      <td>-79:50:58.6546</td>\n",
       "      <td>US 17 To End</td>\n",
       "      <td>I-</td>\n",
       "      <td>2010</td>\n",
       "      <td>-0.026846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "103549       100.0     08020001702S          17.0                35500.0   \n",
       "58253        106.0     07020001706N          17.0                 4700.0   \n",
       "24188        106.0     07020001706N          17.0                 4100.0   \n",
       "92058        106.0     07020001706N          17.0                 3700.0   \n",
       "80804        106.0     07020001706N          17.0                 3700.0   \n",
       "...            ...              ...           ...                    ...   \n",
       "92990       2521.0     10010052600W         526.0                22200.0   \n",
       "81738       2521.0     10010052600W         526.0                21800.0   \n",
       "104258      2521.0     10010052600W         526.0                25000.0   \n",
       "59176       2523.0     10010052600E         526.0                14900.0   \n",
       "25113       2523.0     10010052600E         526.0                14500.0   \n",
       "\n",
       "       county_name       latitude       longitude  \\\n",
       "103549    Berkeley    33:2:13.817    -80:9:13.399   \n",
       "58253     BEAUFORT  32:36:03.3216  -80:45:31.8595   \n",
       "24188     BEAUFORT  32:36:03.3216  -80:45:31.8595   \n",
       "92058     BEAUFORT  32:36:03.3216  -80:45:31.8595   \n",
       "80804     BEAUFORT  32:36:03.3216  -80:45:31.8595   \n",
       "...            ...            ...             ...   \n",
       "92990     CHEROKEE  32:49:14.6714  -79:50:55.6515   \n",
       "81738     CHEROKEE  32:49:14.6714  -79:50:55.6515   \n",
       "104258  Charleston   32:49:14.671   -79:50:55.652   \n",
       "59176     CHEROKEE  32:48:47.4084  -79:50:58.4613   \n",
       "25113     CHEROKEE  32:48:51.8257  -79:50:58.6546   \n",
       "\n",
       "                        route_leg_descrip route_type  year  \\\n",
       "103549  County Line - DORCHESTER TO I- 26         US  2014   \n",
       "58253                  U.S. 17 TO U.S. 21         US  2009   \n",
       "24188                  U.S. 17 TO U.S. 21         US  2010   \n",
       "92058                      US 17 TO US 21         US  2011   \n",
       "80804                      US 17 TO US 21         US  2012   \n",
       "...                                   ...        ...   ...   \n",
       "92990                      S- 56 TO US 17         I-  2011   \n",
       "81738                      S- 56 TO US 17         I-  2012   \n",
       "104258                     S- 56 TO US 17         I-  2014   \n",
       "59176                        US 17 To End         I-  2009   \n",
       "25113                        US 17 To End         I-  2010   \n",
       "\n",
       "        traffic_yearly_pct_change  \n",
       "103549                        NaN  \n",
       "58253                         NaN  \n",
       "24188                   -0.127660  \n",
       "92058                   -0.097561  \n",
       "80804                    0.000000  \n",
       "...                           ...  \n",
       "92990                    0.067308  \n",
       "81738                   -0.018018  \n",
       "104258                   0.050420  \n",
       "59176                         NaN  \n",
       "25113                   -0.026846  \n",
       "\n",
       "[1749 rows x 11 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.loc[traffic_df.latitude.str.contains(':')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.037171388888886"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_lat_long(string):\n",
    "    split = string.split(':')\n",
    "   \n",
    "    converted = float(split[0]) + float(split[1])/60 + float(split[2])/(60*60)\n",
    "    \n",
    "    return converted\n",
    "\n",
    "test = '33:2:13.817'\n",
    "\n",
    "convert_lat_long(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.loc[traffic_df.latitude.str.contains(':'), 'latitude'] = traffic_df.loc[traffic_df.latitude.str.contains(':'), 'latitude'].apply(convert_lat_long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.loc[traffic_df.longitude.str.contains(':'), 'longitude'] = traffic_df.loc[traffic_df.longitude.str.contains(':'), 'longitude'].apply(convert_lat_long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df['latitude'] = traffic_df.latitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df['longitude'] = traffic_df.longitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pct change year over year for average daily traffic\n",
    "traffic_df['traffic_yearly_pct_change'] = traffic_df \\\n",
    "    .sort_values(['station_id', 'route_identifier', 'route_number', 'year']) \\\n",
    "    .groupby(['station_id', 'route_identifier', 'route_number']) \\\n",
    "    .average_daily_traffic \\\n",
    "    .pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = traffic_df.sort_values(['station_id', 'route_identifier', 'route_number', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "      <th>traffic_yearly_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46302</td>\n",
       "      <td>100.0</td>\n",
       "      <td>04020002900N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>34.35590</td>\n",
       "      <td>-82.81412</td>\n",
       "      <td>State Line - GEORGIA TO SC 187 (HIGHWAY 187  S)</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>08020001702N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>53100.0</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>33.03701</td>\n",
       "      <td>-80.15366</td>\n",
       "      <td>County Line - DORCHESTER TO I- 26</td>\n",
       "      <td>US</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.288835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107867</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28040001200E</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>KERSHAW</td>\n",
       "      <td>34.11999</td>\n",
       "      <td>-80.77968</td>\n",
       "      <td>County Line - RICHLAND TO S- 47 (FORT JACKSON RD)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46303</td>\n",
       "      <td>101.0</td>\n",
       "      <td>04020002900N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>34.40918</td>\n",
       "      <td>-82.79075</td>\n",
       "      <td>SC 187 (HIGHWAY 187  S) TO US 29 BUS (HIGHWAY ...</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35410</td>\n",
       "      <td>101.0</td>\n",
       "      <td>07020001700N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>32.64004</td>\n",
       "      <td>-80.85637</td>\n",
       "      <td>County Line - JASPER TO US 17 ALT (CASTLE HALL...</td>\n",
       "      <td>US</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.441860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50675</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>23010018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>34.77331</td>\n",
       "      <td>-82.44549</td>\n",
       "      <td>SC 153 (153 HWY) TO I- 85</td>\n",
       "      <td>I-</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95757</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>23010018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>16700.0</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>34.80352</td>\n",
       "      <td>-82.42446</td>\n",
       "      <td>US 25 (WHITE HORSE RD) TO  , SC 20</td>\n",
       "      <td>I-</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.590476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9271</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>42010058500S</td>\n",
       "      <td>585.0</td>\n",
       "      <td>32200.0</td>\n",
       "      <td>SPARTANBURG</td>\n",
       "      <td>34.97494</td>\n",
       "      <td>-81.94188</td>\n",
       "      <td>US 176 CO2 (N CHURCH ST), SC 9 TO US 221 (WHIT...</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.201493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9272</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>42010058500S</td>\n",
       "      <td>585.0</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>SPARTANBURG</td>\n",
       "      <td>34.97158</td>\n",
       "      <td>-81.93761</td>\n",
       "      <td>US 221 (WHITNEY RD) TO US 176 (N PINE ST)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.214008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46224</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>AIKEN</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>US 25 CON (US 25 CONNECTOR) TO I- 20</td>\n",
       "      <td>I-</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.202381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6200 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "46302        100.0     04020002900N          29.0                 4000.0   \n",
       "69660        100.0     08020001702N          17.0                53100.0   \n",
       "107867       100.0     28040001200E          12.0                 4100.0   \n",
       "46303        101.0     04020002900N          29.0                 2100.0   \n",
       "35410        101.0     07020001700N          17.0                12400.0   \n",
       "...            ...              ...           ...                    ...   \n",
       "50675       2435.0     23010018500N         185.0                 5000.0   \n",
       "95757       2439.0     23010018500N         185.0                16700.0   \n",
       "9271        2489.0     42010058500S         585.0                32200.0   \n",
       "9272        2491.0     42010058500S         585.0                31200.0   \n",
       "46224       2607.0     02010052000E         520.0                10100.0   \n",
       "\n",
       "        county_name  latitude  longitude  \\\n",
       "46302      ANDERSON  34.35590  -82.81412   \n",
       "69660      BERKELEY  33.03701  -80.15366   \n",
       "107867      KERSHAW  34.11999  -80.77968   \n",
       "46303      ANDERSON  34.40918  -82.79075   \n",
       "35410      BEAUFORT  32.64004  -80.85637   \n",
       "...             ...       ...        ...   \n",
       "50675    GREENVILLE  34.77331  -82.44549   \n",
       "95757    GREENVILLE  34.80352  -82.42446   \n",
       "9271    SPARTANBURG  34.97494  -81.94188   \n",
       "9272    SPARTANBURG  34.97158  -81.93761   \n",
       "46224         AIKEN  33.56019  -81.92848   \n",
       "\n",
       "                                        route_leg_descrip route_type  year  \\\n",
       "46302     State Line - GEORGIA TO SC 187 (HIGHWAY 187  S)         US  2015   \n",
       "69660                   County Line - DORCHESTER TO I- 26         US  2017   \n",
       "107867  County Line - RICHLAND TO S- 47 (FORT JACKSON RD)         SC  2014   \n",
       "46303   SC 187 (HIGHWAY 187  S) TO US 29 BUS (HIGHWAY ...         US  2015   \n",
       "35410   County Line - JASPER TO US 17 ALT (CASTLE HALL...         US  2016   \n",
       "...                                                   ...        ...   ...   \n",
       "50675                           SC 153 (153 HWY) TO I- 85         I-  2015   \n",
       "95757                  US 25 (WHITE HORSE RD) TO  , SC 20         I-  2011   \n",
       "9271    US 176 CO2 (N CHURCH ST), SC 9 TO US 221 (WHIT...         SC  2018   \n",
       "9272            US 221 (WHITNEY RD) TO US 176 (N PINE ST)         SC  2018   \n",
       "46224                US 25 CON (US 25 CONNECTOR) TO I- 20         I-  2015   \n",
       "\n",
       "        traffic_yearly_pct_change  \n",
       "46302                    0.290323  \n",
       "69660                    0.288835  \n",
       "107867                   0.413793  \n",
       "46303                    0.312500  \n",
       "35410                    0.441860  \n",
       "...                           ...  \n",
       "50675                    0.250000  \n",
       "95757                    0.590476  \n",
       "9271                     0.201493  \n",
       "9272                     0.214008  \n",
       "46224                    0.202381  \n",
       "\n",
       "[6200 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df[traffic_df['traffic_yearly_pct_change'] > 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zillow Sales data by Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate up\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>StateName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>2008-03</th>\n",
       "      <th>2008-04</th>\n",
       "      <th>2008-05</th>\n",
       "      <th>2008-06</th>\n",
       "      <th>2008-07</th>\n",
       "      <th>2008-08</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>seasAdj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61639</td>\n",
       "      <td>10025</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>61637</td>\n",
       "      <td>10023</td>\n",
       "      <td>New York</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Texas</td>\n",
       "      <td>4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  RegionName StateName  SizeRank  2008-03  2008-04  2008-05  \\\n",
       "0     61639       10025  New York         1      NaN      NaN      NaN   \n",
       "1     84654       60657  Illinois         2      NaN      NaN      NaN   \n",
       "2     61637       10023  New York         3      NaN      NaN      NaN   \n",
       "3     91982       77494     Texas         4     56.0     71.0     84.0   \n",
       "4     84616       60614  Illinois         5      NaN      NaN      NaN   \n",
       "\n",
       "   2008-06  2008-07  2008-08  ...  2019-01  2019-02  2019-03  2019-04  \\\n",
       "0      NaN      NaN      NaN  ...     76.0     33.0     47.0     56.0   \n",
       "1      NaN      NaN      NaN  ...     91.0     77.0    113.0    157.0   \n",
       "2      NaN      NaN      NaN  ...     80.0     45.0     63.0     45.0   \n",
       "3     95.0    116.0     86.0  ...     86.0    112.0    186.0    218.0   \n",
       "4      NaN      NaN      NaN  ...     75.0     85.0    144.0    163.0   \n",
       "\n",
       "   2019-05  2019-06  2019-07  2019-08  2019-09  seasAdj  \n",
       "0     35.0     70.0     78.0     66.0     63.0        0  \n",
       "1    189.0    165.0    186.0    141.0    152.0        0  \n",
       "2     66.0     85.0     79.0     90.0     95.0        0  \n",
       "3    200.0    204.0    245.0    226.0      NaN        0  \n",
       "4    219.0    209.0    204.0    196.0    173.0        0  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "sales_df = pd.read_csv('Sale_Counts_Zip.csv')\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very wide - sales are recording in columns. Our steps for prepping this data will be to:\n",
    "1) Filter down to only South Carolina Zip Codes\n",
    "\n",
    "2) Drop columns we don't care about\n",
    "\n",
    "3) Convert records from wide to tall format\n",
    "\n",
    "4) Get the sum of sales per zipcode per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only SC\n",
    "sales_df = sales_df.loc[sales_df.StateName == 'South Carolina']\n",
    "\n",
    "# drop columns we don't care about and rename columns\n",
    "sales_df = sales_df.drop(['RegionID', 'StateName', 'SizeRank', 'seasAdj'], axis=1)\n",
    "sales_df.rename(columns={'RegionName': 'ZipCode'}, inplace=True)\n",
    "sales_df = sales_df.set_index('ZipCode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2008-03</th>\n",
       "      <th>2008-04</th>\n",
       "      <th>2008-05</th>\n",
       "      <th>2008-06</th>\n",
       "      <th>2008-07</th>\n",
       "      <th>2008-08</th>\n",
       "      <th>2008-09</th>\n",
       "      <th>2008-10</th>\n",
       "      <th>2008-11</th>\n",
       "      <th>2008-12</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-12</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZipCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29072</td>\n",
       "      <td>63.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29464</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         2008-03  2008-04  2008-05  2008-06  2008-07  2008-08  2008-09  \\\n",
       "ZipCode                                                                  \n",
       "29732        NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "29072       63.0     89.0     75.0     70.0     76.0     65.0     68.0   \n",
       "29730        NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "29464       58.0     78.0     73.0     88.0     81.0     73.0     57.0   \n",
       "29681        NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "         2008-10  2008-11  2008-12  ...  2018-12  2019-01  2019-02  2019-03  \\\n",
       "ZipCode                             ...                                       \n",
       "29732        NaN      NaN      NaN  ...    127.0     75.0     75.0    134.0   \n",
       "29072       47.0     42.0     43.0  ...    165.0     88.0     88.0    126.0   \n",
       "29730        NaN      NaN      NaN  ...    119.0     71.0     60.0     91.0   \n",
       "29464       69.0     49.0     35.0  ...     76.0     63.0     91.0     94.0   \n",
       "29681        NaN      NaN      NaN  ...    100.0     99.0    118.0    150.0   \n",
       "\n",
       "         2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  \n",
       "ZipCode                                                        \n",
       "29732      140.0    125.0    136.0    128.0    138.0    151.0  \n",
       "29072      132.0    192.0    156.0    180.0    169.0    142.0  \n",
       "29730       95.0    116.0    111.0     87.0    100.0    107.0  \n",
       "29464      138.0    116.0    135.0    146.0    141.0      NaN  \n",
       "29681      129.0    165.0    136.0    151.0    150.0    161.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51258</td>\n",
       "      <td>820</td>\n",
       "      <td>2019-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51259</td>\n",
       "      <td>820</td>\n",
       "      <td>2019-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51260</td>\n",
       "      <td>820</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51261</td>\n",
       "      <td>820</td>\n",
       "      <td>2019-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51262</td>\n",
       "      <td>820</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51263 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZipCode YearMonth  Sales\n",
       "0        29732   2014-08  127.0\n",
       "1        29732   2014-09  145.0\n",
       "2        29732   2014-10  124.0\n",
       "3        29732   2014-11  121.0\n",
       "4        29732   2014-12  124.0\n",
       "...        ...       ...    ...\n",
       "51258      820   2019-05    0.0\n",
       "51259      820   2019-06    0.0\n",
       "51260      820   2019-07    0.0\n",
       "51261      820   2019-08    0.0\n",
       "51262      820   2019-09    0.0\n",
       "\n",
       "[51263 rows x 3 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack all sales into one column\n",
    "sales_df = sales_df.stack().reset_index()\n",
    "sales_df.columns = ['ZipCode', 'YearMonth', 'Sales']\n",
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29732</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ZipCode YearMonth  Sales  Year\n",
       "0    29732   2014-08  127.0  2014\n",
       "1    29732   2014-09  145.0  2014\n",
       "2    29732   2014-10  124.0  2014\n",
       "3    29732   2014-11  121.0  2014\n",
       "4    29732   2014-12  124.0  2014"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the year out of the Sales record\n",
    "sales_df['Year'] = sales_df['YearMonth'].str.split('-').str[0]\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipCode  Year\n",
       "29944    2017    42.0\n",
       "         2018    28.0\n",
       "         2019     3.0\n",
       "29945    2008    22.0\n",
       "         2009    20.0\n",
       "         2010    20.0\n",
       "         2011    25.0\n",
       "         2012    30.0\n",
       "         2013    23.0\n",
       "         2014    23.0\n",
       "         2015    26.0\n",
       "         2016    14.0\n",
       "         2017    23.0\n",
       "         2018    17.0\n",
       "         2019     3.0\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yearly sales calculated - sum over ZipCode and year\n",
    "yearly_sales = sales_df.groupby(['ZipCode', 'Year']).Sales.sum()\n",
    "yearly_sales.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip to Lat/Long xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "zip_xref = pd.read_csv('sc-zip-code-latitude-and-longitude.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Daylight savings time flag</th>\n",
       "      <th>geopoint</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29607</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29164</td>\n",
       "      <td>Wagener</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29325</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29520</td>\n",
       "      <td>Cheraw</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29615</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Zip        City State   Latitude  Longitude  Timezone  \\\n",
       "0  29607  Greenville    SC  34.825592  -82.34099        -5   \n",
       "1  29164     Wagener    SC  33.659078  -81.40845        -5   \n",
       "2  29325     Clinton    SC  34.470115  -81.86761        -5   \n",
       "3  29520      Cheraw    SC  34.688620  -79.92315        -5   \n",
       "4  29615  Greenville    SC  34.866801  -82.31739        -5   \n",
       "\n",
       "   Daylight savings time flag   geopoint  Unnamed: 8  \n",
       "0                           1  34.825592   -82.34099  \n",
       "1                           1  33.659078   -81.40845  \n",
       "2                           1  34.470115   -81.86761  \n",
       "3                           1  34.688620   -79.92315  \n",
       "4                           1  34.866801   -82.31739  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_xref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the zip code to lat/long xref to the yearly sales data\n",
    "merged_sales = yearly_sales.reset_index().merge(zip_xref, how='left', left_on='ZipCode', right_on='Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop zip codes that have a length less than 5\n",
    "merged_sales = merged_sales.loc[merged_sales.ZipCode.apply(lambda x: len(str(x)) >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns i don't care about\n",
    "merged_sales = merged_sales.drop(['Zip', 'Timezone', 'Daylight savings time flag', 'geopoint', 'Unnamed: 8'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29001</td>\n",
       "      <td>2008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29001</td>\n",
       "      <td>2009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>29001</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>29001</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>29001</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>29001</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>29001</td>\n",
       "      <td>2014</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>29001</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>29001</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>29001</td>\n",
       "      <td>2017</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>29001</td>\n",
       "      <td>2018</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>29001</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>29003</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>29003</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>29003</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>29003</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29003</td>\n",
       "      <td>2012</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29003</td>\n",
       "      <td>2013</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>29003</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>29003</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>29003</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>29003</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>29003</td>\n",
       "      <td>2018</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>29003</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>29006</td>\n",
       "      <td>2008</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Batesburg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.872503</td>\n",
       "      <td>-81.55245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ZipCode  Year  Sales       City State   Latitude  Longitude\n",
       "12    29001  2008   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "13    29001  2009   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "14    29001  2010   11.0     Alcolu    SC  33.769930  -80.17278\n",
       "15    29001  2011    8.0     Alcolu    SC  33.769930  -80.17278\n",
       "16    29001  2012    9.0     Alcolu    SC  33.769930  -80.17278\n",
       "17    29001  2013   12.0     Alcolu    SC  33.769930  -80.17278\n",
       "18    29001  2014   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "19    29001  2015    3.0     Alcolu    SC  33.769930  -80.17278\n",
       "20    29001  2016   14.0     Alcolu    SC  33.769930  -80.17278\n",
       "21    29001  2017   12.0     Alcolu    SC  33.769930  -80.17278\n",
       "22    29001  2018   19.0     Alcolu    SC  33.769930  -80.17278\n",
       "23    29001  2019    4.0     Alcolu    SC  33.769930  -80.17278\n",
       "24    29003  2008    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "25    29003  2009    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "26    29003  2010    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "27    29003  2011    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "28    29003  2012   19.0    Bamberg    SC  33.272026  -81.03203\n",
       "29    29003  2013   26.0    Bamberg    SC  33.272026  -81.03203\n",
       "30    29003  2014    3.0    Bamberg    SC  33.272026  -81.03203\n",
       "31    29003  2015    1.0    Bamberg    SC  33.272026  -81.03203\n",
       "32    29003  2016    7.0    Bamberg    SC  33.272026  -81.03203\n",
       "33    29003  2017    2.0    Bamberg    SC  33.272026  -81.03203\n",
       "34    29003  2018    9.0    Bamberg    SC  33.272026  -81.03203\n",
       "35    29003  2019    3.0    Bamberg    SC  33.272026  -81.03203\n",
       "36    29006  2008   93.0  Batesburg    SC  33.872503  -81.55245"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_sales.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I'd like to calculate how far each Zip Code is from each station. \n",
    "I searched online for a way to calculate the as-the-crow-flies distance between two lat/long points.\n",
    "The first reference I found referred to the \"haversine\" formula, detailed here - https://www.movable-type.co.uk/scripts/latlong.html. \n",
    "I found a nice numpy implmentation on Stack Overflow here: https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas from derricw.\n",
    "\n",
    "In order to calculate the distance between each possible combination of points, I will be taking all unique lat/long points from traffic data and crossjoining with all unique lat/long points from zip code data. Then, I will apply the haversine formula to get the linear distance between each pair of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique zip to lat/long\n",
    "zip_xref['Latitude'] = zip_xref.Latitude.astype('float')\n",
    "zip_xref['Longitude'] = zip_xref.Longitude.astype('float')\n",
    "unique_zip = zip_xref.loc[:, ['Zip', 'Latitude', 'Longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zip   Latitude  Longitude\n",
       "0    29607  34.825592  -82.34099\n",
       "1    29164  33.659078  -81.40845\n",
       "2    29325  34.470115  -81.86761\n",
       "3    29520  34.688620  -79.92315\n",
       "4    29615  34.866801  -82.31739\n",
       "..     ...        ...        ...\n",
       "549  29592  34.283207  -79.47272\n",
       "550  29646  34.169781  -82.15474\n",
       "551  29142  33.462378  -80.50903\n",
       "552  29449  32.715745  -80.26738\n",
       "553  29564  33.493553  -79.87402\n",
       "\n",
       "[554 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique station/routeid/route number lat/long\n",
    "unique_station = traffic_df \\\n",
    "    .loc[:, ['station_id', 'route_identifier', 'route_number', 'latitude', 'longitude']] \\\n",
    "    .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_long</th>\n",
       "      <th>Zip</th>\n",
       "      <th>zip_lat</th>\n",
       "      <th>zip_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061833</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061834</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061835</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061836</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061837</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7061838 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_id route_identifier  route_number  station_lat  station_long  \\\n",
       "0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "...             ...              ...           ...          ...           ...   \n",
       "7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "\n",
       "           Zip    zip_lat  zip_long  \n",
       "0        29607  34.825592 -82.34099  \n",
       "1        29164  33.659078 -81.40845  \n",
       "2        29325  34.470115 -81.86761  \n",
       "3        29520  34.688620 -79.92315  \n",
       "4        29615  34.866801 -82.31739  \n",
       "...        ...        ...       ...  \n",
       "7061833  29592  34.283207 -79.47272  \n",
       "7061834  29646  34.169781 -82.15474  \n",
       "7061835  29142  33.462378 -80.50903  \n",
       "7061836  29449  32.715745 -80.26738  \n",
       "7061837  29564  33.493553 -79.87402  \n",
       "\n",
       "[7061838 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the cartesian product/crossjoin by merging on a uniform key\n",
    "unique_zip['key'] = 0\n",
    "unique_station['key'] = 0\n",
    "\n",
    "station_zip_xref = unique_station.merge(unique_zip, on='key').drop('key', axis=1)\n",
    "station_zip_xref.columns = [\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'station_lat',\n",
    "        'station_long',\n",
    "        'Zip',\n",
    "        'zip_lat',\n",
    "        'zip_long'\n",
    "    ]\n",
    "\n",
    "station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_zip_xref['distance_km'] = haversine_np(\n",
    "    station_zip_xref.station_long.values,\n",
    "    station_zip_xref.station_lat.values,\n",
    "    station_zip_xref.zip_long.values,\n",
    "    station_zip_xref.zip_lat.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_long</th>\n",
       "      <th>Zip</th>\n",
       "      <th>zip_lat</th>\n",
       "      <th>zip_long</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "      <td>50.578796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "      <td>124.877525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "      <td>54.263882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "      <td>233.784632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "      <td>55.504933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061833</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "      <td>240.272498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061834</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "      <td>70.885076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061835</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "      <td>131.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061836</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "      <td>180.818763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061837</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "      <td>190.459639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7061838 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_id route_identifier  route_number  station_lat  station_long  \\\n",
       "0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "...             ...              ...           ...          ...           ...   \n",
       "7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "\n",
       "           Zip    zip_lat  zip_long  distance_km  \n",
       "0        29607  34.825592 -82.34099    50.578796  \n",
       "1        29164  33.659078 -81.40845   124.877525  \n",
       "2        29325  34.470115 -81.86761    54.263882  \n",
       "3        29520  34.688620 -79.92315   233.784632  \n",
       "4        29615  34.866801 -82.31739    55.504933  \n",
       "...        ...        ...       ...          ...  \n",
       "7061833  29592  34.283207 -79.47272   240.272498  \n",
       "7061834  29646  34.169781 -82.15474    70.885076  \n",
       "7061835  29142  33.462378 -80.50903   131.964450  \n",
       "7061836  29449  32.715745 -80.26738   180.818763  \n",
       "7061837  29564  33.493553 -79.87402   190.459639  \n",
       "\n",
       "[7061838 rows x 9 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_zip_xref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I can calculate the home sales within a certain radius of a station for the current year or previous year and see if that has any bearing on traffic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29001</td>\n",
       "      <td>2008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29001</td>\n",
       "      <td>2009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>29001</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>29001</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>29001</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4507</td>\n",
       "      <td>29945</td>\n",
       "      <td>2015</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4508</td>\n",
       "      <td>29945</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4509</td>\n",
       "      <td>29945</td>\n",
       "      <td>2017</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4510</td>\n",
       "      <td>29945</td>\n",
       "      <td>2018</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4511</td>\n",
       "      <td>29945</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ZipCode  Year  Sales      City State   Latitude  Longitude\n",
       "12      29001  2008   10.0    Alcolu    SC  33.769930  -80.17278\n",
       "13      29001  2009   10.0    Alcolu    SC  33.769930  -80.17278\n",
       "14      29001  2010   11.0    Alcolu    SC  33.769930  -80.17278\n",
       "15      29001  2011    8.0    Alcolu    SC  33.769930  -80.17278\n",
       "16      29001  2012    9.0    Alcolu    SC  33.769930  -80.17278\n",
       "...       ...   ...    ...       ...   ...        ...        ...\n",
       "4507    29945  2015   26.0  Yemassee    SC  32.681058  -80.83348\n",
       "4508    29945  2016   14.0  Yemassee    SC  32.681058  -80.83348\n",
       "4509    29945  2017   23.0  Yemassee    SC  32.681058  -80.83348\n",
       "4510    29945  2018   17.0  Yemassee    SC  32.681058  -80.83348\n",
       "4511    29945  2019    3.0  Yemassee    SC  32.681058  -80.83348\n",
       "\n",
       "[4500 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_home_sales(traffic_df, sales_df, zip_xref, radius_cutoff, curr_or_prev='curr'):\n",
    "    filtered_zips = zip_xref.loc[zip_xref.distance_km <= radius_cutoff]\n",
    "    sales_modified = sales_df.copy(deep=True)\n",
    "    sales_modified['next_year'] = sales_modified.Year + 1\n",
    "    sales_per_station = zip_xref.merge(sales_modified, how='left', left_on='Zip', right_on='ZipCode')\n",
    "    sales_per_station = sales_per_station.groupby(['station_id', 'route_identifier', 'route_number'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      ZipCode  Year  Sales      City State   Latitude  Longitude\n",
       " 12      29001  2008   10.0    Alcolu    SC  33.769930  -80.17278\n",
       " 13      29001  2009   10.0    Alcolu    SC  33.769930  -80.17278\n",
       " 14      29001  2010   11.0    Alcolu    SC  33.769930  -80.17278\n",
       " 15      29001  2011    8.0    Alcolu    SC  33.769930  -80.17278\n",
       " 16      29001  2012    9.0    Alcolu    SC  33.769930  -80.17278\n",
       " ...       ...   ...    ...       ...   ...        ...        ...\n",
       " 4507    29945  2015   26.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4508    29945  2016   14.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4509    29945  2017   23.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4510    29945  2018   17.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4511    29945  2019    3.0  Yemassee    SC  32.681058  -80.83348\n",
       " \n",
       " [4500 rows x 7 columns],\n",
       "          station_id route_identifier  route_number  station_lat  station_long  \\\n",
       " 0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " ...             ...              ...           ...          ...           ...   \n",
       " 7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " \n",
       "            Zip    zip_lat  zip_long  distance_km  \n",
       " 0        29607  34.825592 -82.34099    50.578796  \n",
       " 1        29164  33.659078 -81.40845   124.877525  \n",
       " 2        29325  34.470115 -81.86761    54.263882  \n",
       " 3        29520  34.688620 -79.92315   233.784632  \n",
       " 4        29615  34.866801 -82.31739    55.504933  \n",
       " ...        ...        ...       ...          ...  \n",
       " 7061833  29592  34.283207 -79.47272   240.272498  \n",
       " 7061834  29646  34.169781 -82.15474    70.885076  \n",
       " 7061835  29142  33.462378 -80.50903   131.964450  \n",
       " 7061836  29449  32.715745 -80.26738   180.818763  \n",
       " 7061837  29564  33.493553 -79.87402   190.459639  \n",
       " \n",
       " [7061838 rows x 9 columns])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_sales, station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalprojects",
   "language": "python",
   "name": "generalprojects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
