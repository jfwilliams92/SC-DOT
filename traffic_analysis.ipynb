{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC DOT Data and Zillow Home Sales - How has traffic in South Carolina changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of my least favorite parts of the day is my daily commute. Anecdotally, I feel as if traffic has worsened/increased in South Carolina since I moved here in 2007, and it's worsening at an increasing rate every year.\n",
    "I stumbled across some data on the SC-DOT GIS page that I thought might help confirm or deny my suspicion.\n",
    "Here's where the data can be downloaded - https://www.scdot.org/travel/travel-mappinggis.aspx.\n",
    "The data in question that I'm examining are Annual Average Daily Traffic counts from the years 2009 - 2018.\n",
    "These data are recorded at the level of StationID and RouteIdentifier with additional information as well, including Latitude and Longitude of the recording Station.\n",
    "I downloaded the .zip files for each separately and then renamed them and put them into one folder - shp_files.\n",
    "The data come in both .shp and .dbf (Xbase) format.\n",
    "More about these file types here:\n",
    "TODO\n",
    "\n",
    "SCDOT has some interactive ArcGIS maps with these data points plotted already - http://scdot.maps.arcgis.com/apps/MinimalGallery/index.html?appid=7420aa1f39d84400a6d7e8cdaacc89cd\n",
    "\n",
    "However, these plots don't fully convey (to me) the true amount of traffic in SC, as all station points are plotted as little cars with no information about AADT, nor the change in traffic patterns year over year.\n",
    "Nor do they address any underlying causes of what may be driving potential traffic pattern changes.\n",
    "\n",
    "Tangentially, SCDOT does provide a wealth of other data for citizens to browse, some of which look quite interesting.\n",
    "http://scdot.maps.arcgis.com/apps/MinimalGallery/index.html?appid=e8ace63de0e6423394d04c9c091e893b#\n",
    "I am particularly interested in how the \"South Carolina Roads by Pavement Status\" dataset folds into the questions at hand here, but that goes beyond the scope of this post. Perhaps to be addressed later.\n",
    "\n",
    "Getting back on topic, one of the most intuitive drivers of change in traffic patterns could be popluation growth/decline in the areas nearby. I chose to use a data set from Zillow - https://www.zillow.com/research/data/ - that details Monthly Home Sales by ZipCode as a proxy to population growth per Zip Code.\n",
    "\n",
    "Finally, I also downloaded a data set from OpenDataSoft - https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/table/ - that cross references ZipCode to latitude and longitude. I only downloaded data for South Carolina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What do the data look like and what does it take to get them in a unified format?\n",
    "\n",
    "2) Has overall traffic increased in SC over the past 10 years?\n",
    "\n",
    "3) Are there are any areas in SC that show more aggressive traffic growth?\n",
    "\n",
    "4) Does number of home sales in Zip Codes within a certain radius of a station (e.g. 50 km) have any bearing on traffic numbers the next or same year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simpledbf import Dbf5\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read GIS dbf data into dataframes, one file for each year between 2009 and 2018\n",
    "shp_dfs = {}\n",
    "for root, dirs, files in os.walk(\"./shp_files\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".dbf\"):\n",
    "            # print(file.split('.')[0])\n",
    "            dbf = Dbf5(os.path.join(root, file))\n",
    "            df = dbf.to_dataframe()\n",
    "            shp_dfs[file.split('.')[0]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyNumb</th>\n",
       "      <th>RouteTypeN</th>\n",
       "      <th>RouteType1</th>\n",
       "      <th>RouteNumbe</th>\n",
       "      <th>MeterMileP</th>\n",
       "      <th>BeginMileP</th>\n",
       "      <th>EndMilePoi</th>\n",
       "      <th>StationNum</th>\n",
       "      <th>Termini</th>\n",
       "      <th>FactoredAA</th>\n",
       "      <th>FactoredA1</th>\n",
       "      <th>MapLRS</th>\n",
       "      <th>Status1</th>\n",
       "      <th>ID1</th>\n",
       "      <th>RouteAuxil</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.82</td>\n",
       "      <td>101.0</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>34.41979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4.345</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.91</td>\n",
       "      <td>103.0</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (MAIN ST W)</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.35324</td>\n",
       "      <td>34.38344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>5.633</td>\n",
       "      <td>4.91</td>\n",
       "      <td>7.28</td>\n",
       "      <td>105.0</td>\n",
       "      <td>SC 184 (MAIN ST W) TO County Line - GREENWOOD</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>34.37099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>109.0</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71...</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38017</td>\n",
       "      <td>34.17889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>111.0</td>\n",
       "      <td>SC 71 (N MAIN ST) TO L- 170 (RICHEY ST)</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38114</td>\n",
       "      <td>34.18369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CountyNumb  RouteTypeN RouteType1  RouteNumbe  MeterMileP  BeginMileP  \\\n",
       "0         1.0         2.0         US       178.0       1.196        0.00   \n",
       "1         1.0         2.0         US       178.0       4.345        3.82   \n",
       "2         1.0         2.0         US       178.0       5.633        4.91   \n",
       "3         1.0         4.0         SC        20.0       0.074        0.00   \n",
       "4         1.0         4.0         SC        20.0       0.439        0.18   \n",
       "\n",
       "   EndMilePoi  StationNum                                            Termini  \\\n",
       "0        3.82       101.0        County Line - ANDERSON TO S- 166 (DRAKE RD)   \n",
       "1        4.91       103.0            S- 166 (DRAKE RD) TO SC 184 (MAIN ST W)   \n",
       "2        7.28       105.0      SC 184 (MAIN ST W) TO County Line - GREENWOOD   \n",
       "3        0.18       109.0  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71...   \n",
       "4        0.45       111.0            SC 71 (N MAIN ST) TO L- 170 (RICHEY ST)   \n",
       "\n",
       "   FactoredAA  FactoredA1        MapLRS Status1  ID1 RouteAuxil CountyName  \\\n",
       "0      4300.0      2018.0  01020017800E     NaN    1        NaN  ABBEVILLE   \n",
       "1      4600.0      2018.0  01020017800E     NaN    2        NaN  ABBEVILLE   \n",
       "2      3600.0      2018.0  01020017800E     NaN    3        NaN  ABBEVILLE   \n",
       "3      4900.0      2018.0  01040002000E     NaN    4        NaN  ABBEVILLE   \n",
       "4      2200.0      2018.0  01040002000E     NaN    5        NaN  ABBEVILLE   \n",
       "\n",
       "        Long       Lat  \n",
       "0  -82.38521  34.41979  \n",
       "1  -82.35324  34.38344  \n",
       "2  -82.33765  34.37099  \n",
       "3  -82.38017  34.17889  \n",
       "4  -82.38114  34.18369  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give an ol look see at the most recent year\n",
    "shp_dfs['2018'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by eyeballing, it can be surmised what each field name means, along with the helpful data dictionary supplied by SCDOT.\n",
    "For example \"FactorerA1\" is clearly the year of this particular dataset, while \"Long\" and \"Lat\" hold the longitude and latitude of the datapoint.\n",
    "\n",
    "Next, we'll check to see if the column names match across all the dataframes we have, one for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the columns in the dfs match - per df, convert columns to sets. Check the intersection of all sets.\n",
    "col_sets = map(lambda x: set(x.columns), shp_dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the list of column sets into set.intersection, which returns common elements in set\n",
    "common_cols = set.intersection(*col_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID1'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see what's common between the dfs\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! There's only one column that is common between all of the dataframes. Let's dig in a little more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CountyNumb', 'RouteTypeN', 'RouteType1', 'RouteNumbe', 'MeterMileP',\n",
      "       'BeginMileP', 'EndMilePoi', 'StationNum', 'Termini', 'FactoredAA',\n",
      "       'FactoredA1', 'MapLRS', 'Status1', 'ID1', 'RouteAuxil', 'CountyName',\n",
      "       'Long', 'Lat'],\n",
      "      dtype='object') 18\n",
      "Index(['Station_Nu', 'Route_LRS', 'County_ID', 'Route_Type', 'Route_Numb',\n",
      "       'Route_Auxi', 'Descriptio', 'Count', 'Year', 'ID1'],\n",
      "      dtype='object') 10\n",
      "Index(['STATION_NU', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'ROUTE_TYPE', 'ROUTE_NUMB', 'ROUTE_AUX',\n",
      "       'COUNT', 'YEAR', 'DESCRIPTIO', 'ID1', 'GMRotation'],\n",
      "      dtype='object') 15\n",
      "Index(['CountyName', 'RouteTypeN', 'RouteNumbe', 'RouteAuxil', 'MeterMileP',\n",
      "       'BegiNMileP', 'EndMilePoi', 'StationNum', 'Termini', 'FactoredAA',\n",
      "       'FactoredA1', 'MapLRS', 'Status1', 'ID1', 'Latitude', 'Longitude'],\n",
      "      dtype='object') 16\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'ATR_NUM', 'MAP', 'RouteNum', 'termini', 'Count', 'Year',\n",
      "       'County', 'RouteType', 'AUX', 'GMRotation'],\n",
      "      dtype='object') 17\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'ATR_NUM', 'County', 'Station_Nu',\n",
      "       'Route_Type', 'Route_Numb', 'AUX', 'Count', 'Year', 'Descriptio',\n",
      "       'GMRotation'],\n",
      "      dtype='object') 18\n",
      "Index(['Route_Type', 'Route_Numb', 'Route_Auxi', 'Meter_Mile', 'Begin_Mile',\n",
      "       'End_MilePo', 'Station_Nu', 'Termini', 'Factored_A', 'Factored_1',\n",
      "       'RouteLRS', 'ID1', 'County_Nam'],\n",
      "      dtype='object') 13\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'county', 'F2', 'station1', 'rtetype',\n",
      "       'rtenumb', 'rteaux', 'bmp', 'emp', 'termini', 'rtelrs', 'CONNN', 'aadt',\n",
      "       'aadtyr', 'GMRotation'],\n",
      "      dtype='object') 22\n",
      "Index(['STATION_NU', 'COUNT', 'DESCRIPTIO', 'YEAR', 'ROUTE_TYPE', 'ROUTE_NUMB',\n",
      "       'ROUTE_AUX', 'MILE_POINT', 'ROUTE_LRS', 'COUNTY_ID', 'MAP_TYPE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ID1', 'GMRotation'],\n",
      "      dtype='object') 15\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'CountyName', 'RouteType', 'rtenum', 'AUX', 'ATR_NUM',\n",
      "       'MAP', 'termini', 'Year', 'Count', 'ID2', 'GMRotation'],\n",
      "      dtype='object') 18\n"
     ]
    }
   ],
   "source": [
    "# Let's check to see what the actual columns are named and how many there are\n",
    "for df in shp_dfs.values():\n",
    "    print(df.columns, len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see that we have different numbers of columns per year, and that most of the columns are all named differently. We'll try to address that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we'll get better results if we do some simple string formatting first\n",
    "for df in shp_dfs.values():\n",
    "    df.columns = [c.replace('_', '').lower().strip() for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id1'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check set intersection again\n",
    "col_sets = list(map(lambda x: set(x.columns), shp_dfs.values()))\n",
    "set.intersection(*col_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still only one column that's the same! Time to do some brute-force mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 Index(['countynumb', 'routetypen', 'routetype1', 'routenumbe', 'metermilep',\n",
      "       'beginmilep', 'endmilepoi', 'stationnum', 'termini', 'factoredaa',\n",
      "       'factoreda1', 'maplrs', 'status1', 'id1', 'routeauxil', 'countyname',\n",
      "       'long', 'lat'],\n",
      "      dtype='object') 18\n",
      "2013 Index(['stationnu', 'routelrs', 'countyid', 'routetype', 'routenumb',\n",
      "       'routeauxi', 'descriptio', 'count', 'year', 'id1'],\n",
      "      dtype='object') 10\n",
      "2010 Index(['stationnu', 'milepoint', 'routelrs', 'maptype', 'latitude',\n",
      "       'longitude', 'countyid', 'routetype', 'routenumb', 'routeaux', 'count',\n",
      "       'year', 'descriptio', 'id1', 'gmrotation'],\n",
      "      dtype='object') 15\n",
      "2016 Index(['countyname', 'routetypen', 'routenumbe', 'routeauxil', 'metermilep',\n",
      "       'beginmilep', 'endmilepoi', 'stationnum', 'termini', 'factoredaa',\n",
      "       'factoreda1', 'maplrs', 'status1', 'id1', 'latitude', 'longitude'],\n",
      "      dtype='object') 16\n",
      "2015 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'atrnum', 'map', 'routenum', 'termini', 'count', 'year',\n",
      "       'county', 'routetype', 'aux', 'gmrotation'],\n",
      "      dtype='object') 17\n",
      "2009 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyid', 'atrnum', 'county', 'stationnu', 'routetype',\n",
      "       'routenumb', 'aux', 'count', 'year', 'descriptio', 'gmrotation'],\n",
      "      dtype='object') 18\n",
      "2017 Index(['routetype', 'routenumb', 'routeauxi', 'metermile', 'beginmile',\n",
      "       'endmilepo', 'stationnu', 'termini', 'factoreda', 'factored1',\n",
      "       'routelrs', 'id1', 'countynam'],\n",
      "      dtype='object') 13\n",
      "2012 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyid', 'county', 'f2', 'station1', 'rtetype',\n",
      "       'rtenumb', 'rteaux', 'bmp', 'emp', 'termini', 'rtelrs', 'connn', 'aadt',\n",
      "       'aadtyr', 'gmrotation'],\n",
      "      dtype='object') 22\n",
      "2011 Index(['stationnu', 'count', 'descriptio', 'year', 'routetype', 'routenumb',\n",
      "       'routeaux', 'milepoint', 'routelrs', 'countyid', 'maptype', 'latitude',\n",
      "       'longitude', 'id1', 'gmrotation'],\n",
      "      dtype='object') 15\n",
      "2014 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyname', 'routetype', 'rtenum', 'aux', 'atrnum',\n",
      "       'map', 'termini', 'year', 'count', 'id2', 'gmrotation'],\n",
      "      dtype='object') 18\n"
     ]
    }
   ],
   "source": [
    "# eye all the column names\n",
    "for year, df in shp_dfs.items():\n",
    "    print(year, df.columns, len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that will allow us to rename columns from key to value.\n",
    "# we won't map every column - only keep a subset\n",
    "col_mapping_dict = {\n",
    "    **dict.fromkeys(['station', 'stationnu', 'stationnum'], 'station_id'),\n",
    "    **dict.fromkeys(['milepoint', 'metermile', 'metermilep'], 'route_mile_point'),\n",
    "    **dict.fromkeys(['latitude', 'lat'], 'latitude'),\n",
    "    **dict.fromkeys(['longitude', 'long'], 'longitude'), \n",
    "    **dict.fromkeys(['aadtyr', 'year', 'factored1', 'factoreda1'], 'year'),\n",
    "    **dict.fromkeys(['routelrs', 'maplrs'], 'route_identifier'),\n",
    "    **dict.fromkeys(['termini', 'descriptio'], 'route_leg_descrip'),\n",
    "    **dict.fromkeys(['beginmilep', 'beginmile'], 'route_leg_beginmile'),\n",
    "    **dict.fromkeys(['endmilepo', 'endmilepoi'], 'route_leg_endmile'),\n",
    "    **dict.fromkeys(['routetype', 'rtetype', 'routetypen', 'routetype1'], 'route_type'),   # has to be a numeric column as well, some collision here\n",
    "    **dict.fromkeys(['rtenum', 'rtenumb', 'routenumb', 'routenum', 'routenumbe'], 'route_number'),\n",
    "    **dict.fromkeys(['county', 'countyname', 'countynam'], 'county_name'),\n",
    "    **dict.fromkeys(['countyid', 'countynumb'], 'county_id'),\n",
    "    **dict.fromkeys(['aadt', 'factoreda', 'count', 'factoredaa'], 'average_daily_traffic'),\n",
    "    **dict.fromkeys(['id1'], 'row_number')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns as per mapping dict\n",
    "shp_dfs_renamed = {year: df.rename(columns=col_mapping_dict) for year, df in shp_dfs.items()}\n",
    "# drop columns not mapped\n",
    "#shp_dfs_renamed = {year: df.drop([c for c in df.columns if c not in col_mapping_dict.values()], axis=1) for year, df in shp_dfs_renamed.items()}\n",
    "# drop any duplicated columns\n",
    "shp_dfs_renamed = {year: df.loc[:, ~df.columns.duplicated()] for year, df in shp_dfs_renamed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still some collision - column name can mean different things in different years.\n",
    "# drop some columns that still aren't right\n",
    "shp_dfs_renamed['2009'].drop(['county_name', 'route_type'], axis=1, inplace=True)\n",
    "shp_dfs_renamed['2012'].drop(['county_name', 'route_type'], axis=1, inplace=True)\n",
    "shp_dfs_renamed['2013'].drop('route_type', axis=1, inplace=True)\n",
    "shp_dfs_renamed['2017'].drop('county_name', axis=1, inplace=True)\n",
    "shp_dfs_renamed['2018'].drop('route_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - columns should now all be correctly named across years. We also dropped a subset of the columns, only keeping a subset.\n",
    "Let's now overwrite invalid route_types in the dfs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 0\n",
      "2016 0\n",
      "2015 0\n",
      "2017 0\n",
      "2011 0\n",
      "2014 0\n"
     ]
    }
   ],
   "source": [
    "# check to see how many NaN route types there are\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    if 'route_type' in df.columns:\n",
    "        print(year, df.route_type.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 route_type\n",
      "L-    620\n",
      "dtype: int64\n",
      "2016 route_type\n",
      "L-    735\n",
      "dtype: int64\n",
      "2015 route_type\n",
      "L-    607\n",
      "dtype: int64\n",
      "2017 route_type\n",
      "L    656\n",
      "dtype: int64\n",
      "2011 route_type\n",
      "L-    1356\n",
      "dtype: int64\n",
      "2014 route_type\n",
      "L-    707\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# eyeball it first\n",
    "# from data dictionary supplied by SC DOT\n",
    "possible_route_types = ['I',\n",
    "    'US',\n",
    "    'SC',\n",
    "    'S',\n",
    "    'D',\n",
    "    'R',\n",
    "    'RS'\n",
    "]\n",
    "\n",
    "# check what the invalids are\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    if 'route_type' in df.columns:\n",
    "        print(year, df.loc[~df.route_type.str.replace('-','').isin(possible_route_types)].groupby('route_type').size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace invalids with np.nan\n",
    "# then, fill the nans by group\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    if 'route_type' in df.columns:\n",
    "        df.loc[~df.route_type.str.replace('-','').isin(possible_route_types), 'route_type'] = np.nan\n",
    "        df['route_type'] = df.groupby(['station_id', 'route_identifier', 'route_number']).route_type.ffill().bfill()\n",
    "\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    if 'route_type' in df.columns and 'latitude' in df.columns:\n",
    "        df.loc[~df.route_type.str.replace('-','').isin(possible_route_types), 'route_type'] = np.nan\n",
    "        df['route_type'] = df.groupby(['station_id', 'route_identifier', 'latitude', 'longitude']).route_type.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010 0\n",
      "2016 25\n",
      "2015 0\n",
      "2017 656\n",
      "2011 0\n",
      "2014 0\n"
     ]
    }
   ],
   "source": [
    "# check to see how many NaN route types there are\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    if 'route_type' in df.columns:\n",
    "        print(year, df.route_type.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated rows in dataframes\n",
    "# some rows are only unique based on row_number (id1) and id2 fields\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df = df.drop('row_number', axis=1)\n",
    "    if 'id2' in df.columns:\n",
    "        df = df.drop('id2', axis=1)\n",
    "    df = df.drop_duplicates()\n",
    "    shp_dfs_renamed[year] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the columns previously, we could see that we don't have latitude or longitude data fields in the 2017 and 2013 dataframes. This will cause us problems later on, so we'll address it by filling those missing columns in with data from other dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take care of the 2017 dataframe first.\n",
    "# update the 2017 dataframe with data from the 2018 dataframe\n",
    "temp = shp_dfs_renamed['2018']. \\\n",
    "    set_index([\n",
    "        'route_identifier',\n",
    "        'station_id',\n",
    "        'route_number',\n",
    "        'route_leg_beginmile',\n",
    "        'route_leg_endmile']\n",
    "    )\n",
    "\n",
    "twentyseventeen = shp_dfs_renamed['2017']. \\\n",
    "    set_index([\n",
    "        'route_identifier',\n",
    "        'station_id',\n",
    "        'route_number',\n",
    "        'route_leg_beginmile',\n",
    "        'route_leg_endmile']\n",
    "    )\n",
    "\n",
    "twentyseventeen['latitude'] = np.nan\n",
    "twentyseventeen['longitude'] = np.nan\n",
    "twentyseventeen['county_name'] = np.nan\n",
    "\n",
    "# use pandas update method, which uses the index to determine which rows to update. Overwrite=True means all values \n",
    "# will be overwritten in specified columns, not just nans.\n",
    "twentyseventeen.update(temp[['latitude', 'longitude', 'route_leg_descrip', 'county_name']], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in any remaining gaps in 2017 data we can by updating with 2016 dataframe, not overwriting non-nans this time.\n",
    "temp = shp_dfs_renamed['2016']. \\\n",
    "    set_index([\n",
    "        'route_identifier',\n",
    "        'station_id',\n",
    "        'route_number',\n",
    "        'route_leg_beginmile',\n",
    "        'route_leg_endmile'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "twentyseventeen.update(temp[['latitude', 'longitude', 'route_leg_descrip', 'county_name']], overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign back\n",
    "shp_dfs_renamed['2017'] = twentyseventeen.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2017 df is now updated (as best as possible) with Latitude and Longitude points - this will allow us to effectively plot and calculate what we want to see later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, on to the 2013 dataframe.\n",
    "This dataframe presents a unique challenge because it lacks many of the distinguishing fields that would make filling in missing data easy. For example, we are missing the route_leg beginning and end mile points that we used to update the 2017 df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>county_id</th>\n",
       "      <th>route_number</th>\n",
       "      <th>routeauxi</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>County Line - ANDERSON TO SC 20</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>County Line - ANDERSON TO S- 166</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S- 166 TO SC 184</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>105.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC 184 TO County Line - GREENWOOD</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>01090002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC 72 TO SC 20, SC 203</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>109.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC 203, L- 20, L- 980 TO SC 71</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>111.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC 71 TO L- 938</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>113.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>L- 938 TO S- 32</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>115.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S- 32 TO S- 215</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>117.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S- 215 TO S- 182</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>119.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S- 182 TO SC 201</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>121.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC 201 TO S- 51</td>\n",
       "      <td>2400.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>123.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S- 51 TO SC 185</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>125.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SC 185 TO S- 227</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>127.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>S- 227 TO SC 184</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    station_id route_identifier  county_id  route_number  routeauxi  \\\n",
       "0        100.0     01040018500N        1.0         185.0        0.0   \n",
       "1        101.0     01020017800E        1.0         178.0        0.0   \n",
       "2        103.0     01020017800E        1.0         178.0        0.0   \n",
       "3        105.0     01020017800E        1.0         178.0        0.0   \n",
       "4        107.0     01090002000E        1.0          20.0        0.0   \n",
       "5        109.0     01040002000E        1.0          20.0        0.0   \n",
       "6        111.0     01040002000E        1.0          20.0        0.0   \n",
       "7        113.0     01040002000E        1.0          20.0        0.0   \n",
       "8        115.0     01040002000E        1.0          20.0        0.0   \n",
       "9        117.0     01040002000E        1.0          20.0        0.0   \n",
       "10       119.0     01040002000E        1.0          20.0        0.0   \n",
       "11       121.0     01040002000E        1.0          20.0        0.0   \n",
       "12       123.0     01040002000E        1.0          20.0        0.0   \n",
       "13       125.0     01040002000E        1.0          20.0        0.0   \n",
       "14       127.0     01040002000E        1.0          20.0        0.0   \n",
       "\n",
       "                    route_leg_descrip  average_daily_traffic    year  \n",
       "0     County Line - ANDERSON TO SC 20                 1050.0  2013.0  \n",
       "1    County Line - ANDERSON TO S- 166                 4600.0  2013.0  \n",
       "2                    S- 166 TO SC 184                 4800.0  2013.0  \n",
       "3   SC 184 TO County Line - GREENWOOD                 3500.0  2013.0  \n",
       "4              SC 72 TO SC 20, SC 203                 5100.0  2013.0  \n",
       "5      SC 203, L- 20, L- 980 TO SC 71                 6200.0  2013.0  \n",
       "6                     SC 71 TO L- 938                 2300.0  2013.0  \n",
       "7                     L- 938 TO S- 32                 2200.0  2013.0  \n",
       "8                     S- 32 TO S- 215                 2100.0  2013.0  \n",
       "9                    S- 215 TO S- 182                 2200.0  2013.0  \n",
       "10                   S- 182 TO SC 201                 3700.0  2013.0  \n",
       "11                    SC 201 TO S- 51                 2400.0  2013.0  \n",
       "12                    S- 51 TO SC 185                 1550.0  2013.0  \n",
       "13                   SC 185 TO S- 227                 1500.0  2013.0  \n",
       "14                   S- 227 TO SC 184                 1800.0  2013.0  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_dfs_renamed['2013'].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, it would appear that the 2014 and 2013 dataframes have a similar naming convention for route_leg_descrip. Combined with station_id, route_identifier, and route_number, we should be able to get a pretty good match for data filling.\n",
    "We'll check to see if we have any groups larger than 1 within that grouping schema. If we do, we'll have to take care of those, as the pandas update method cannot handle duplicate multi-index entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station_id  route_identifier  route_number  route_leg_descrip           \n",
      "331.0       11070020900N      209.0         County Line - YORK TO S- 121    2\n",
      "433.0       23070000500N      5.0           SC 20 TO L- 10                  2\n",
      "451.0       10070001300N      13.0          US 52 TO AIR FORCE BASE ROAD    2\n",
      "469.0       43090036400E      364.0         S- 537, L- 215 TO SC 441        2\n",
      "749.0       39070010000E      100.0         L- 1512 TO S- 143               2\n",
      "dtype: int64\n",
      "station_id  route_identifier  route_number  route_leg_descrip\n",
      "553.0       42070064500N      645.0         S- 736 TO S- 60      2\n",
      "633.0       23090032600E      326.0         I- 85 TO S- 1164     2\n",
      "923.0       42070176700N      1767.0        SC 296 TO US 176     2\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>county_id</th>\n",
       "      <th>route_number</th>\n",
       "      <th>routeauxi</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4842</td>\n",
       "      <td>633.0</td>\n",
       "      <td>23090032600E</td>\n",
       "      <td>23.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I- 85 TO S- 1164</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4843</td>\n",
       "      <td>633.0</td>\n",
       "      <td>23090032600E</td>\n",
       "      <td>23.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I- 85 TO S- 1164</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id route_identifier  county_id  route_number  routeauxi  \\\n",
       "4842       633.0     23090032600E       23.0         326.0        0.0   \n",
       "4843       633.0     23090032600E       23.0         326.0        0.0   \n",
       "\n",
       "     route_leg_descrip  average_daily_traffic    year  \n",
       "4842  I- 85 TO S- 1164                 4300.0  2013.0  \n",
       "4843  I- 85 TO S- 1164                 4100.0  2013.0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = shp_dfs_renamed['2014'].groupby([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]).size()\n",
    "\n",
    "ss = shp_dfs_renamed['2013'].groupby([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]).size()\n",
    "\n",
    "# check where the size of the groups > 1\n",
    "print(s[s>1])\n",
    "print(ss[ss>1])\n",
    "\n",
    "# eyeball the data\n",
    "shp_dfs_renamed['2013'].loc[shp_dfs_renamed['2013'].route_leg_descrip == 'I- 85 TO S- 1164']\n",
    "#shp_dfs_renamed['2012'].loc[shp_dfs_renamed['2012'].route_leg_descrip == 'County Line - YORK TO S- 121']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after eyeballing the 3 duplicates present in the 2013 data, the average daily traffic numbers are very close. Since \n",
    "# there are no other distinguishing features in the 2013 dataset, we will eliminate these 3 duplicated by averaging the \n",
    "# average daily traffic numbers across the grouping schema\n",
    "\n",
    "twentythirteen = shp_dfs_renamed['2013'].copy(deep=True)\n",
    "twentythirteen['average_daily_traffic'] = twentythirteen.\\\n",
    "    groupby([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]\n",
    "    ). \\\n",
    "    average_daily_traffic. \\\n",
    "    transform('mean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the duplicates now that average daily traffic is the same across the group\n",
    "twentythirteen = twentythirteen.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "station_id  route_identifier  route_number  route_leg_descrip           \n",
      "331.0       11070020900N      209.0         County Line - YORK TO S- 121    2\n",
      "433.0       23070000500N      5.0           SC 20 TO L- 10                  2\n",
      "451.0       10070001300N      13.0          US 52 TO AIR FORCE BASE ROAD    2\n",
      "469.0       43090036400E      364.0         S- 537, L- 215 TO SC 441        2\n",
      "749.0       39070010000E      100.0         L- 1512 TO S- 143               2\n",
      "dtype: int64\n",
      "Series([], dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>county_id</th>\n",
       "      <th>route_number</th>\n",
       "      <th>routeauxi</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4842</td>\n",
       "      <td>633.0</td>\n",
       "      <td>23090032600E</td>\n",
       "      <td>23.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I- 85 TO S- 1164</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>2013.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id route_identifier  county_id  route_number  routeauxi  \\\n",
       "4842       633.0     23090032600E       23.0         326.0        0.0   \n",
       "\n",
       "     route_leg_descrip  average_daily_traffic    year  \n",
       "4842  I- 85 TO S- 1164                 4200.0  2013.0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check group sizes again\n",
    "s = shp_dfs_renamed['2014'].groupby([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]).size()\n",
    "\n",
    "ss = twentythirteen.groupby([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]).size()\n",
    "\n",
    "print(s[s>1])\n",
    "print(ss[ss>1])\n",
    "\n",
    "# check to see if the average daily traffic was averaged\n",
    "twentythirteen.loc[twentythirteen.route_leg_descrip == 'I- 85 TO S- 1164']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_mile_point</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>maptype</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>county_name</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>aux</th>\n",
       "      <th>atrnum</th>\n",
       "      <th>map</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>gmrotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2376</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>11070020900N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>35:2:59.839</td>\n",
       "      <td>-81:28:48.254</td>\n",
       "      <td>Cherokee</td>\n",
       "      <td>S-</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>County Line - YORK TO S- 121</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2377</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.566</td>\n",
       "      <td>11070020900N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>35:3:0.868</td>\n",
       "      <td>-81:28:48.957</td>\n",
       "      <td>Cherokee</td>\n",
       "      <td>S-</td>\n",
       "      <td>209.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>County Line - YORK TO S- 121</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id  route_mile_point route_identifier maptype     latitude  \\\n",
       "2376       331.0             0.543     11070020900N  COUNTY  35:2:59.839   \n",
       "2377       331.0             0.566     11070020900N  COUNTY   35:3:0.868   \n",
       "\n",
       "          longitude county_name route_type  route_number  aux  atrnum map  \\\n",
       "2376  -81:28:48.254    Cherokee         S-         209.0  NaN     NaN   Y   \n",
       "2377  -81:28:48.957    Cherokee         S-         209.0  NaN     NaN   Y   \n",
       "\n",
       "                 route_leg_descrip    year  average_daily_traffic  gmrotation  \n",
       "2376  County Line - YORK TO S- 121  2014.0                    225    0.000002  \n",
       "2377  County Line - YORK TO S- 121  2014.0                    225    0.000002  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eyeball a 2014 dupe\n",
    "shp_dfs_renamed['2014'].loc[shp_dfs_renamed['2014'].route_leg_descrip == 'County Line - YORK TO S- 121']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our update df (2014), we will eliminate the 5 duplicate sets by taking the first row from each set - the reasoning\n",
    "here is that the duplicates in the 2014 dataset on route_leg_descrip arise from different mile markers along\n",
    "the same route_leg. The lat/long datapoints for two points along the same route_leg_descrip should be very close.\n",
    "Therefore, we will choose one of the lat/long datapoints arbitrarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# take the first row from each group\n",
    "update_temp = shp_dfs_renamed['2014'].groupby([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]).head(1)\n",
    "\n",
    "# verify that we have no dupes\n",
    "s = update_temp.groupby([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]).size()\n",
    "\n",
    "print(s[s>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the twentythirteen dataframe with the 2014 update dataframe\n",
    "update_temp = update_temp. \\\n",
    "    set_index([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip' \n",
    "        ]\n",
    "    )\n",
    "\n",
    "twentythirteen = twentythirteen .\\\n",
    "    set_index([\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'route_leg_descrip'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "twentythirteen['longitude'] = np.nan\n",
    "twentythirteen['latitude'] = np.nan\n",
    "\n",
    "twentythirteen.update(update_temp[['latitude', 'longitude']], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11286 entries, 0 to 11285\n",
      "Data columns (total 10 columns):\n",
      "station_id               11286 non-null float64\n",
      "route_identifier         11286 non-null object\n",
      "route_number             11286 non-null float64\n",
      "route_leg_descrip        11286 non-null object\n",
      "county_id                11286 non-null float64\n",
      "routeauxi                11286 non-null float64\n",
      "average_daily_traffic    11286 non-null float64\n",
      "year                     11286 non-null float64\n",
      "longitude                10877 non-null object\n",
      "latitude                 10877 non-null object\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 881.8+ KB\n"
     ]
    }
   ],
   "source": [
    "twentythirteen.reset_index().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully filled in lat/long points for 10877 rows in the 2013 df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassign back\n",
    "shp_dfs_renamed['2013'] = twentythirteen.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that some dataframes have the lat/long as colon-separate strings, while other dataframes have them as floats.\n",
    "We'll have to convert strings to floats for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lat_long(series):\n",
    "    \"\"\"Convert a series of lat or long strings into floating point representation.\n",
    "    \n",
    "    Args:\n",
    "        series (pandas Series): a series of strings of lat/long, delimited by a colon.\n",
    "    Returns:\n",
    "        converted (pandas Series): a series of floating points of lat/long, rounded to 5 decimal places\n",
    "    \n",
    "    \"\"\"\n",
    "    # expand=True turns the delimited series into a dataframe with multiple columns (rather than list of splits)\n",
    "    split = series.str.split(':', expand=True)\n",
    "    # compute the floating point representation\n",
    "    converted = split[0].astype('float') + split[1].astype('float') / 60 + split[2].astype('float') / (60*60)\n",
    "    \n",
    "    return converted.round(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_dfs_renamed['2013'].latitude.dtype\n",
    "\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    if df.latitude.dtype == 'O' and df.latitude.str.contains(':').any():\n",
    "        df['latitude'] = convert_lat_long(df.latitude)\n",
    "        df['longitude'] = convert_lat_long(df.longitude)\n",
    "    else:\n",
    "        df['latitude'] = df.latitude.astype('float')\n",
    "        df['longitude'] = df.longitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude  longitude  station_id  route_identifier  route_number  route_mile_point  route_leg_descrip           \n",
       "32.90     -79.98     451.0       10070001300N      13.0          3.229             US 52 TO AIR FORCE BASE ROAD    2\n",
       "33.99     -79.53     469.0       43090036400E      364.0         2.877             S- 537, L- 215 TO SC 441        2\n",
       "34.83     -81.59     433.0       23070000500N      5.0           2.669             SC 20 TO L- 10                  2\n",
       "34.97     -81.13     749.0       39070010000E      100.0         3.390             L- 1512 TO S- 143               2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = shp_dfs_renamed['2014'].groupby([\n",
    "    shp_dfs_renamed['2014'].latitude.round(2),\n",
    "    shp_dfs_renamed['2014'].longitude.round(2),\n",
    " 'station_id', 'route_identifier', 'route_number', 'route_mile_point', 'route_leg_descrip']).size()\n",
    "s[s>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>milepoint</th>\n",
       "      <th>routelrs</th>\n",
       "      <th>maptype</th>\n",
       "      <th>id1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>countyname</th>\n",
       "      <th>routetype</th>\n",
       "      <th>rtenum</th>\n",
       "      <th>aux</th>\n",
       "      <th>atrnum</th>\n",
       "      <th>map</th>\n",
       "      <th>termini</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>id2</th>\n",
       "      <th>gmrotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8934</td>\n",
       "      <td>749.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>39070010000E</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>2532</td>\n",
       "      <td>34:57:57.006</td>\n",
       "      <td>-82:52:4.314</td>\n",
       "      <td>Pickens</td>\n",
       "      <td>S-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>L- 1512 TO S- 143</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>550</td>\n",
       "      <td>8935</td>\n",
       "      <td>8.004128e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8935</td>\n",
       "      <td>749.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>39070010000E</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>2532</td>\n",
       "      <td>34:57:57.006</td>\n",
       "      <td>-82:52:4.314</td>\n",
       "      <td>Pickens</td>\n",
       "      <td>L-</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>L- 1512 TO S- 143</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>600</td>\n",
       "      <td>8936</td>\n",
       "      <td>8.004128e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station  milepoint      routelrs maptype   id1      latitude  \\\n",
       "8934    749.0       3.39  39070010000E  COUNTY  2532  34:57:57.006   \n",
       "8935    749.0       3.39  39070010000E  COUNTY  2532  34:57:57.006   \n",
       "\n",
       "         longitude countyname routetype  rtenum  aux  atrnum map  \\\n",
       "8934  -82:52:4.314    Pickens        S-   100.0  NaN     NaN   Y   \n",
       "8935  -82:52:4.314    Pickens        L-   100.0  NaN     NaN   Y   \n",
       "\n",
       "                termini    year  count   id2    gmrotation  \n",
       "8934  L- 1512 TO S- 143  2014.0    550  8935  8.004128e-07  \n",
       "8935  L- 1512 TO S- 143  2014.0    600  8936  8.004128e-07  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_dfs_renamed['2014'][shp_dfs_renamed['2014'].route_leg_descrip == 'L- 1512 TO S- 143']\n",
    "shp_dfs['2014'].iloc[8934:8936]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11275 entries, 0 to 11274\n",
      "Data columns (total 19 columns):\n",
      "station_id               11275 non-null float64\n",
      "route_mile_point         11261 non-null float64\n",
      "route_identifier         11275 non-null object\n",
      "maptype                  11273 non-null object\n",
      "latitude                 11265 non-null float64\n",
      "longitude                11265 non-null float64\n",
      "county_id                11275 non-null int64\n",
      "f2                       11275 non-null object\n",
      "station1                 11275 non-null float64\n",
      "route_number             11275 non-null float64\n",
      "rteaux                   11275 non-null float64\n",
      "bmp                      11275 non-null float64\n",
      "emp                      11275 non-null float64\n",
      "route_leg_descrip        11275 non-null object\n",
      "rtelrs                   11275 non-null object\n",
      "connn                    11275 non-null object\n",
      "average_daily_traffic    11275 non-null int64\n",
      "year                     11275 non-null int64\n",
      "gmrotation               11275 non-null float64\n",
      "dtypes: float64(10), int64(3), object(6)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "shp_dfs_renamed['2012'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11672 entries, 0 to 11671\n",
      "Data columns (total 30 columns):\n",
      "county_id                  11672 non-null float64\n",
      "route_number_x             11672 non-null float64\n",
      "route_mile_point_x         11671 non-null float64\n",
      "route_leg_beginmile        11672 non-null float64\n",
      "route_leg_endmile          11672 non-null float64\n",
      "station_id_x               11672 non-null float64\n",
      "route_leg_descrip_x        11672 non-null object\n",
      "average_daily_traffic_x    11603 non-null float64\n",
      "year_x                     11656 non-null float64\n",
      "route_identifier_x         11672 non-null object\n",
      "status1                    183 non-null object\n",
      "routeauxil                 335 non-null object\n",
      "county_name_x              11487 non-null object\n",
      "longitude_x                11489 non-null object\n",
      "latitude                   11489 non-null object\n",
      "station_id_y               0 non-null float64\n",
      "route_mile_point_y         0 non-null float64\n",
      "route_identifier_y         0 non-null object\n",
      "maptype                    0 non-null object\n",
      "longitude_y                0 non-null object\n",
      "county_name_y              0 non-null object\n",
      "route_type                 0 non-null object\n",
      "route_number_y             0 non-null float64\n",
      "aux                        0 non-null object\n",
      "atrnum                     0 non-null float64\n",
      "map                        0 non-null object\n",
      "route_leg_descrip_y        0 non-null object\n",
      "year_y                     0 non-null float64\n",
      "average_daily_traffic_y    0 non-null float64\n",
      "gmrotation                 0 non-null float64\n",
      "dtypes: float64(15), object(15)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "shp_dfs_renamed['2018'].merge(shp_dfs_renamed['2014'], how='left', on='latitude').info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id  route_identifier  route_number\n",
       "426.0       04090713500N      7135.0          2\n",
       "553.0       42070064500N      645.0           2\n",
       "633.0       23090032600E      326.0           2\n",
       "923.0       42070176700N      1767.0          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[s>1]\n",
    "#twentythirteen = shp_dfs_renamed['2013'].drop('row_number', axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id  route_identifier  route_number\n",
       "426.0       04090713500N      7135.0          2\n",
       "553.0       42070064500N      645.0           2\n",
       "633.0       23090032600E      326.0           2\n",
       "923.0       42070176700N      1767.0          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = twentythirteen.groupby(['station_id', 'route_identifier', 'route_number']).size() \n",
    "g[g>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df = df.drop_duplicates()\n",
    "    shp_dfs_renamed[year] = df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       32020000100N      1.0             2\n",
      "321.0       21070013200E      132.0           2\n",
      "dtype: int64\n",
      "2013 \n",
      " station_id  route_identifier  route_number\n",
      "426.0       04090713500N      7135.0          2\n",
      "553.0       42070064500N      645.0           2\n",
      "633.0       23090032600E      326.0           2\n",
      "923.0       42070176700N      1767.0          2\n",
      "dtype: int64\n",
      "2010 \n",
      " station_id  route_identifier  route_number\n",
      "169.0       04040002400E      24.0            2\n",
      "170.0       40020007600E      76.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "2601.0      02010052000E      520.0           2\n",
      "dtype: int64\n",
      "2016 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       32020000100N      1.0             2\n",
      "dtype: int64\n",
      "2015 \n",
      " Series([], dtype: int64)\n",
      "2009 \n",
      " station_id  route_identifier  route_number\n",
      "331.0       11070020900N      209.0           2\n",
      "dtype: int64\n",
      "2017 \n",
      " Series([], dtype: int64)\n",
      "2012 \n",
      " station_id  route_identifier  route_number\n",
      "170.0       40020007600E      76.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "384.0       42070006400E      64.0            3\n",
      "dtype: int64\n",
      "2011 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       32020000100N      1.0             2\n",
      "169.0       04040002400E      24.0            2\n",
      "170.0       40020007600E      76.0            2\n",
      "193.0       41070002500N      25.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "553.0       42070064500N      645.0           2\n",
      "795.0       40070202700N      2027.0          2\n",
      "913.0       42070098900N      989.0           2\n",
      "2601.0      02010052000E      520.0           2\n",
      "dtype: int64\n",
      "2014 \n",
      " station_id  route_identifier  route_number\n",
      "331.0       11070020900N      209.0           2\n",
      "433.0       23070000500N      5.0             2\n",
      "451.0       10070001300N      13.0            2\n",
      "469.0       43090036400E      364.0           2\n",
      "749.0       39070010000E      100.0           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# records should be unique across station_id, route_identifier, and route_number - do some verification\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).size()\n",
    "    # print rows where the size of the group is > 1 (duplicates)\n",
    "    print(year,'\\n', temp_df.loc[temp_df > 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that we have some duplicates, or we think we have duplicates. We'll define a quick function to spot check some records and get a sense of why rows are duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>county_name</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2054</td>\n",
       "      <td>451.0</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>S-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>19500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2055</td>\n",
       "      <td>451.0</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>S-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>18200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id route_identifier      latitude     longitude county_name  \\\n",
       "2054       451.0     10070001300N  32:53:53.404  -80:1:10.830  Charleston   \n",
       "2055       451.0     10070001300N  32:53:53.404  -80:1:10.830  Charleston   \n",
       "\n",
       "     route_type  route_number             route_leg_descrip    year  \\\n",
       "2054         S-          13.0  US 52 TO AIR FORCE BASE ROAD  2014.0   \n",
       "2055         S-          13.0  US 52 TO AIR FORCE BASE ROAD  2014.0   \n",
       "\n",
       "      average_daily_traffic  \n",
       "2054                  19500  \n",
       "2055                  18200  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can spot check some of these to see what's up with the records\n",
    "def check_records(year, station_id, route_identifier):\n",
    "    mask = (shp_dfs_renamed[year]['station_id'] == station_id) & (shp_dfs_renamed[year]['route_identifier'] == route_identifier)\n",
    "    return shp_dfs_renamed[year].loc[mask]\n",
    "\n",
    "check_records('2014', 451.0, '10070001300N') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>milepoint</th>\n",
       "      <th>routelrs</th>\n",
       "      <th>maptype</th>\n",
       "      <th>id1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>countyname</th>\n",
       "      <th>routetype</th>\n",
       "      <th>rtenum</th>\n",
       "      <th>aux</th>\n",
       "      <th>atrnum</th>\n",
       "      <th>map</th>\n",
       "      <th>termini</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>id2</th>\n",
       "      <th>gmrotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2054</td>\n",
       "      <td>451.0</td>\n",
       "      <td>3.229</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>CHARLESTON</td>\n",
       "      <td>5653</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>S-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>19500</td>\n",
       "      <td>2055</td>\n",
       "      <td>8.170881e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2055</td>\n",
       "      <td>451.0</td>\n",
       "      <td>3.229</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>CHARLESTON</td>\n",
       "      <td>5653</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>L-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>18200</td>\n",
       "      <td>2056</td>\n",
       "      <td>8.170881e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station  milepoint      routelrs     maptype   id1      latitude  \\\n",
       "2054    451.0      3.229  10070001300N  CHARLESTON  5653  32:53:53.404   \n",
       "2055    451.0      3.229  10070001300N  CHARLESTON  5653  32:53:53.404   \n",
       "\n",
       "         longitude  countyname routetype  rtenum  aux  atrnum map  \\\n",
       "2054  -80:1:10.830  Charleston        S-    13.0  NaN     NaN   Y   \n",
       "2055  -80:1:10.830  Charleston        L-    13.0  NaN     NaN   Y   \n",
       "\n",
       "                           termini    year  count   id2    gmrotation  \n",
       "2054  US 52 TO AIR FORCE BASE ROAD  2014.0  19500  2055  8.170881e-07  \n",
       "2055  US 52 TO AIR FORCE BASE ROAD  2014.0  18200  2056  8.170881e-07  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the underlying data\n",
    "shp_dfs['2014'].loc[(shp_dfs['2014'].station == 451.0) & (shp_dfs['2014'].routelrs == '10070001300N')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above two rows differ based on id2 and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>year</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2297</td>\n",
       "      <td>331.0</td>\n",
       "      <td>11070020900N</td>\n",
       "      <td>35:03:00.0546</td>\n",
       "      <td>-81:28:47.765</td>\n",
       "      <td>209.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>York County Line TO S-121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2298</td>\n",
       "      <td>331.0</td>\n",
       "      <td>11070020900N</td>\n",
       "      <td>35:03:00.8678</td>\n",
       "      <td>-81:28:48.9568</td>\n",
       "      <td>209.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>York County Line TO S-121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id route_identifier       latitude       longitude  \\\n",
       "2297       331.0     11070020900N  35:03:00.0546   -81:28:47.765   \n",
       "2298       331.0     11070020900N  35:03:00.8678  -81:28:48.9568   \n",
       "\n",
       "      route_number  average_daily_traffic    year          route_leg_descrip  \n",
       "2297         209.0                  250.0  2009.0  York County Line TO S-121  \n",
       "2298         209.0                  250.0  2009.0  York County Line TO S-121  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_records('2009', 331.0, '11070020900N')\n",
    "#shp_dfs['2010'].loc[4407:4408]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>milepoint</th>\n",
       "      <th>routelrs</th>\n",
       "      <th>maptype</th>\n",
       "      <th>id1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>countyid</th>\n",
       "      <th>atrnum</th>\n",
       "      <th>county</th>\n",
       "      <th>stationnu</th>\n",
       "      <th>routetype</th>\n",
       "      <th>routenumb</th>\n",
       "      <th>aux</th>\n",
       "      <th>count</th>\n",
       "      <th>year</th>\n",
       "      <th>descriptio</th>\n",
       "      <th>gmrotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2297</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.566</td>\n",
       "      <td>11070020900N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>4444</td>\n",
       "      <td>35:03:00.0546</td>\n",
       "      <td>-81:28:47.765</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>York County Line TO S-121</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2298</td>\n",
       "      <td>331.0</td>\n",
       "      <td>0.566</td>\n",
       "      <td>11070020900N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>7134</td>\n",
       "      <td>35:03:00.8678</td>\n",
       "      <td>-81:28:48.9568</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>York County Line TO S-121</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station  milepoint      routelrs maptype   id1       latitude  \\\n",
       "2297    331.0      0.566  11070020900N  COUNTY  4444  35:03:00.0546   \n",
       "2298    331.0      0.566  11070020900N  COUNTY  7134  35:03:00.8678   \n",
       "\n",
       "           longitude  countyid  atrnum  county  stationnu  routetype  \\\n",
       "2297   -81:28:47.765        11     NaN    11.0      331.0        7.0   \n",
       "2298  -81:28:48.9568        11     NaN    11.0      331.0        7.0   \n",
       "\n",
       "      routenumb  aux  count    year                 descriptio  gmrotation  \n",
       "2297      209.0  0.0  250.0  2009.0  York County Line TO S-121    0.000002  \n",
       "2298      209.0  0.0  250.0  2009.0  York County Line TO S-121    0.000002  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_dfs['2009'].loc[(shp_dfs['2009'].station == 331.0) & (shp_dfs['2009'].routelrs == '11070020900N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>year</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6377</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>County Line - SALUDA TO S- 50 (N RIDGELL ST)</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>32020000100N</td>\n",
       "      <td>33.8975758564561</td>\n",
       "      <td>-81.5616927735785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6396</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>US 378 (MEETING ST) (LEXINGTON)  TO US 21 (HUG...</td>\n",
       "      <td>27900.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>32020000100N</td>\n",
       "      <td>33.8981999185585</td>\n",
       "      <td>-81.5602154592896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_name route_type  route_number  station_id  \\\n",
       "6377   LEXINGTON         US           1.0       101.0   \n",
       "6396   LEXINGTON         US           1.0       101.0   \n",
       "\n",
       "                                      route_leg_descrip  \\\n",
       "6377       County Line - SALUDA TO S- 50 (N RIDGELL ST)   \n",
       "6396  US 378 (MEETING ST) (LEXINGTON)  TO US 21 (HUG...   \n",
       "\n",
       "      average_daily_traffic    year route_identifier          latitude  \\\n",
       "6377                 2700.0  2016.0     32020000100N  33.8975758564561   \n",
       "6396                27900.0  2016.0     32020000100N  33.8981999185585   \n",
       "\n",
       "              longitude  \n",
       "6377  -81.5616927735785  \n",
       "6396  -81.5602154592896  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_records('2016', 101.0, '32020000100N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>countyname</th>\n",
       "      <th>routetypen</th>\n",
       "      <th>routenumbe</th>\n",
       "      <th>routeauxil</th>\n",
       "      <th>metermilep</th>\n",
       "      <th>beginmilep</th>\n",
       "      <th>endmilepoi</th>\n",
       "      <th>stationnum</th>\n",
       "      <th>termini</th>\n",
       "      <th>factoredaa</th>\n",
       "      <th>factoreda1</th>\n",
       "      <th>maplrs</th>\n",
       "      <th>status1</th>\n",
       "      <th>id1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6377</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>101.0</td>\n",
       "      <td>County Line - SALUDA TO S- 50 (N RIDGELL ST)</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>32020000100N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6378</td>\n",
       "      <td>33.8975758564561</td>\n",
       "      <td>-81.5616927735785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6396</td>\n",
       "      <td>LEXINGTON</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148</td>\n",
       "      <td>31.22</td>\n",
       "      <td>31.40</td>\n",
       "      <td>101.0</td>\n",
       "      <td>US 378 (MEETING ST) (LEXINGTON)  TO US 21 (HUG...</td>\n",
       "      <td>27900.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>32020000100N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6397</td>\n",
       "      <td>33.8981999185585</td>\n",
       "      <td>-81.5602154592896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     countyname routetypen  routenumbe routeauxil  metermilep  beginmilep  \\\n",
       "6377  LEXINGTON         US         1.0        NaN       0.047        0.00   \n",
       "6396  LEXINGTON         US         1.0        NaN       0.148       31.22   \n",
       "\n",
       "      endmilepoi  stationnum  \\\n",
       "6377        0.72       101.0   \n",
       "6396       31.40       101.0   \n",
       "\n",
       "                                                termini  factoredaa  \\\n",
       "6377       County Line - SALUDA TO S- 50 (N RIDGELL ST)      2700.0   \n",
       "6396  US 378 (MEETING ST) (LEXINGTON)  TO US 21 (HUG...     27900.0   \n",
       "\n",
       "      factoreda1        maplrs status1   id1          latitude  \\\n",
       "6377      2016.0  32020000100N     NaN  6378  33.8975758564561   \n",
       "6396      2016.0  32020000100N     NaN  6397  33.8981999185585   \n",
       "\n",
       "              longitude  \n",
       "6377  -81.5616927735785  \n",
       "6396  -81.5602154592896  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_dfs['2016'].loc[(shp_dfs['2016'].stationnum == 101.0) & (shp_dfs['2016'].maplrs == '32020000100N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeballing the records reveals that they are duplicated rows. we'll take the first from every group\n",
    "# head(1) will return the first row per group\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).head(1)\n",
    "    shp_dfs_renamed[year] = temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing a few sets of records leads me to believe that we are in fact dealing with duplicate rows. Most are only unique based on the row number. We'll drop our duplicates to make sure they don't sully the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 \n",
      " Series([], dtype: int64)\n",
      "2013 \n",
      " Series([], dtype: int64)\n",
      "2010 \n",
      " Series([], dtype: int64)\n",
      "2016 \n",
      " Series([], dtype: int64)\n",
      "2015 \n",
      " Series([], dtype: int64)\n",
      "2009 \n",
      " Series([], dtype: int64)\n",
      "2017 \n",
      " Series([], dtype: int64)\n",
      "2012 \n",
      " Series([], dtype: int64)\n",
      "2011 \n",
      " Series([], dtype: int64)\n",
      "2014 \n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#check for dupes again\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).size()\n",
    "    print(year,'\\n', temp_df.loc[temp_df > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>53400.0</td>\n",
       "      <td>SEVEN FARMS RD TO S- 97 (CHARLESTON)</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>I-</td>\n",
       "      <td>526.0</td>\n",
       "      <td>08010052600E</td>\n",
       "      <td>32:51:39.5474</td>\n",
       "      <td>-79:53:52.4178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id  average_daily_traffic                     route_leg_descrip  \\\n",
       "1675      2520.0                53400.0  SEVEN FARMS RD TO S- 97 (CHARLESTON)   \n",
       "\n",
       "        year route_type  route_number route_identifier       latitude  \\\n",
       "1675  2011.0         I-         526.0     08010052600E  32:51:39.5474   \n",
       "\n",
       "           longitude  \n",
       "1675  -79:53:52.4178  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify we took the first row in the duplicated group, and that we only have one row returning.\n",
    "check_records('2011', 2520.0, '08010052600E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we've realized that the data can very quite widely from year to year. In order to clean the data up a little bit more, we will try to standardize the data across years. To accomplish this we'll use pandas' update method - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.update.html - and overwrite the values in every year with our standardized values. Because the 2017 and 2018 dataframes don't have all the columns that we're interested in looking at, we'll use the 2016 dataframe to update/overwrite values in a specific subset of columns across all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index of all dfs to the unique identifiers\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.set_index(['station_id', 'route_identifier', 'route_number'])\n",
    "    shp_dfs_renamed[year] = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing year value in any dfs\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df['year'] = df.year.fillna(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county_name                0\n",
       "route_type               726\n",
       "route_leg_descrip          0\n",
       "average_daily_traffic      0\n",
       "year                       0\n",
       "latitude                 179\n",
       "longitude                179\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2018 and 2017 dfs don't have all the columns, so use the 2016 df to standardize fields\n",
    "# check how many nas in each columns in the 2016 df\n",
    "shp_dfs_renamed['2016'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have some NaNs for lat/long in the 2016 df, so we'll try and reduce those as much as we can.\n",
    "# update 2016 latitudes/longitudes with 2018 latitudes/longitudes where stationid, route_id, and route_number match (index of each df)\n",
    "\n",
    "shp_dfs_renamed['2016'].update(shp_dfs_renamed['2018'][['latitude', 'longitude']], overwrite=False)\n",
    "\n",
    "# still some nulls - try the 2015 df\n",
    "shp_dfs_renamed['2016'].update(shp_dfs_renamed['2015'][['latitude', 'longitude']], overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county_name                0\n",
       "route_type               726\n",
       "route_leg_descrip          0\n",
       "average_daily_traffic      0\n",
       "year                       0\n",
       "latitude                 153\n",
       "longitude                153\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nas again\n",
    "shp_dfs_renamed['2016'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 and 2017 dfs don't have all the columns, so use the 2016 df to standardize fields\n",
    "# we're standardizing data across the five following columns - DON'T want to overwrite AADT.\n",
    "cols_to_update = ['route_type', 'route_leg_descrip', 'latitude', 'longitude', 'county_name']\n",
    "update_df = shp_dfs_renamed['2016'][cols_to_update]\n",
    "\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df.update(update_df, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we should be ready to combine all the dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all the data frames together\n",
    "traffic_df = pd.concat(shp_dfs_renamed.values(), sort=True, axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.41979</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.38344</td>\n",
       "      <td>-82.35325</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.37099</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>SC 184 (N MAIN ST) TO County Line - GREENWOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.17888</td>\n",
       "      <td>-82.38016</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.18359</td>\n",
       "      <td>-82.38115</td>\n",
       "      <td>SC 71 TO L- 170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "0       101.0     01020017800E         178.0                 4300.0   \n",
       "1       103.0     01020017800E         178.0                 4600.0   \n",
       "2       105.0     01020017800E         178.0                 3600.0   \n",
       "3       109.0     01040002000E          20.0                 4900.0   \n",
       "4       111.0     01040002000E          20.0                 2200.0   \n",
       "\n",
       "  county_name  latitude  longitude  \\\n",
       "0   ABBEVILLE  34.41979  -82.38521   \n",
       "1   ABBEVILLE  34.38344  -82.35325   \n",
       "2   ABBEVILLE  34.37099  -82.33765   \n",
       "3   ABBEVILLE  34.17888  -82.38016   \n",
       "4   ABBEVILLE  34.18359  -82.38115   \n",
       "\n",
       "                                route_leg_descrip route_type  year  \n",
       "0     County Line - ANDERSON TO S- 166 (DRAKE RD)        NaN  2018  \n",
       "1         S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)        NaN  2018  \n",
       "2   SC 184 (N MAIN ST) TO County Line - GREENWOOD        NaN  2018  \n",
       "3  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71        NaN  2018  \n",
       "4                                 SC 71 TO L- 170        NaN  2018  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eyeball the data \n",
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the head indicates that there are STILL NaNs in the data - the index of our update df (stationid, routeid, routenumber) did not overlap every possible combination in the data across the years. We can handle these NaNs with a similar operation - grouping the data by our unique identifers and then filling within groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fill in cols that are still na by unique id - NOT the average traffic column (main data we care about)\n",
    "# fill nas by group\n",
    "cols_to_fill = ['county_name', 'latitude', 'longitude', 'route_leg_descrip', 'route_type']\n",
    "for col in cols_to_fill:\n",
    "    traffic_df[col] = traffic_df.groupby(['station_id', 'route_identifier', 'route_number'])[col].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id                0\n",
       "route_identifier          0\n",
       "route_number              0\n",
       "average_daily_traffic    69\n",
       "county_name               0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "route_leg_descrip         0\n",
       "route_type                0\n",
       "year                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any nas remaining\n",
    "traffic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop remaining nas - no data!\n",
    "traffic_df = traffic_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fe158579610>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x7fe1857d8320> (for post_execute):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# ignore the tracking, just draw and close all figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# safely show traceback if in IPython, else raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/ipykernel/pylab/backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</home/james/.local/lib/python3.7/site-packages/decorator.py:decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2058\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2060\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2061\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2366\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2367\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2368\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2369\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# go back to just this axis's tick labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_label_position\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   2012\u001b[0m         \u001b[0;31m# get bounding boxes for this axis and any siblings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0;31m# that have been set by `fig.align_xlabels()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2014\u001b[0;31m         \u001b[0mbboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_boxes_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2016\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_boxes_siblings\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_siblings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m             \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m             \u001b[0mtlb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtlb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick_bboxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticks_to_draw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m             \u001b[0mbboxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0mbboxes2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1150\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1151\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1152\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Return lists of bboxes for ticks' label1's and label2's.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         return ([tick.label1.get_window_extent(renderer)\n\u001b[0;32m-> 1150\u001b[0;31m                  for tick in ticks if tick.label1.get_visible()],\n\u001b[0m\u001b[1;32m   1151\u001b[0m                 [tick.label2.get_window_extent(renderer)\n\u001b[1;32m   1152\u001b[0m                  for tick in ticks if tick.label2.get_visible()])\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unitless_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m         \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdpi\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdpi_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generalprojects/lib/python3.7/site-packages/matplotlib/transforms.py\u001b[0m in \u001b[0;36mtranslated\u001b[0;34m(self, tx, ty)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;34m\"\"\"Construct a `Bbox` by translating this one by *tx* and *ty*.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_points\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# do some test plotting\n",
    "test_plot = traffic_df.loc[traffic_df.year == 2018].sample(1000)\n",
    "x_plot = test_plot.longitude.values\n",
    "y_plot = test_plot.latitude.values\n",
    "cmap = plt.get_cmap('jet')\n",
    "c = np.log(test_plot.average_daily_traffic)\n",
    "s = np.log(test_plot.average_daily_traffic)\n",
    "\n",
    "# plt.scatter(x_plot, y_plot, alpha=0.15, s=s, c=c, cmap=cmap)\n",
    "plt.scatter(x_plot, y_plot)\n",
    "#plt.scatter([1,2,3], [2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1547</td>\n",
       "      <td>285.0</td>\n",
       "      <td>08070009700N</td>\n",
       "      <td>97.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>33.23964</td>\n",
       "      <td>-79.89429</td>\n",
       "      <td>US 17 ALT (N HWY 17A) TO SC 402 (HWY 402)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>861</td>\n",
       "      <td>539.0</td>\n",
       "      <td>04070024600E</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>34.51393</td>\n",
       "      <td>-82.57251</td>\n",
       "      <td>S- 245 (BLUE RIDGE AV) TO US 29 (HIGHWAY 29  N)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11325</td>\n",
       "      <td>696.0</td>\n",
       "      <td>39090002400E</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6400.0</td>\n",
       "      <td>PICKENS</td>\n",
       "      <td>34.67119</td>\n",
       "      <td>-82.83522</td>\n",
       "      <td>L- 320 (PERIMETER RD) TO US 76 (ANDERSON HWY)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2399</td>\n",
       "      <td>209.0</td>\n",
       "      <td>12040000907S</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>CHESTER</td>\n",
       "      <td>34.70476</td>\n",
       "      <td>-81.20483</td>\n",
       "      <td>US 321 BUS (COLUMBIA ST) TO S- 103 (HARRIS ST)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4501</td>\n",
       "      <td>273.0</td>\n",
       "      <td>23040041400E</td>\n",
       "      <td>414.0</td>\n",
       "      <td>2500.0</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>35.04325</td>\n",
       "      <td>-82.43646</td>\n",
       "      <td>US 276 (GEER HWY) TO US 25 (N 25 HWY)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8677</td>\n",
       "      <td>105.0</td>\n",
       "      <td>40020000100N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26400.0</td>\n",
       "      <td>RICHLAND</td>\n",
       "      <td>34.04057</td>\n",
       "      <td>-80.99772</td>\n",
       "      <td>SC 16 (N BELTLINE BLVD) TO S- 289 CON (PINE BE...</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9257</td>\n",
       "      <td>2309.0</td>\n",
       "      <td>42010008500N</td>\n",
       "      <td>85.0</td>\n",
       "      <td>96500.0</td>\n",
       "      <td>SPARTANBURG</td>\n",
       "      <td>34.90371</td>\n",
       "      <td>-82.12373</td>\n",
       "      <td>SC 101 (HIGHWAY 101 S) TO SC 290 (E MAIN ST)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1896</td>\n",
       "      <td>314.0</td>\n",
       "      <td>10070005100N</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13600.0</td>\n",
       "      <td>CHARLESTON</td>\n",
       "      <td>32.82748</td>\n",
       "      <td>-79.81605</td>\n",
       "      <td>SC 517 (ISLE OF PALMS CONNECTOR) TO S- 921 (SI...</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4186</td>\n",
       "      <td>505.0</td>\n",
       "      <td>21070092500N</td>\n",
       "      <td>925.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>FLORENCE</td>\n",
       "      <td>34.21543</td>\n",
       "      <td>-79.70426</td>\n",
       "      <td>S- 24 TO S- 13 (MOORE ST)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7738</td>\n",
       "      <td>549.0</td>\n",
       "      <td>37070043700N</td>\n",
       "      <td>437.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>OCONEE</td>\n",
       "      <td>34.56908</td>\n",
       "      <td>-83.12687</td>\n",
       "      <td>S- 20 (DR JOHNS RD) TO LAKE HARTWELL</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "1547        285.0     08070009700N          97.0                  225.0   \n",
       "861         539.0     04070024600E         246.0                 1400.0   \n",
       "11325       696.0     39090002400E          24.0                 6400.0   \n",
       "2399        209.0     12040000907S           9.0                 7300.0   \n",
       "4501        273.0     23040041400E         414.0                 2500.0   \n",
       "...           ...              ...           ...                    ...   \n",
       "8677        105.0     40020000100N           1.0                26400.0   \n",
       "9257       2309.0     42010008500N          85.0                96500.0   \n",
       "1896        314.0     10070005100N          51.0                13600.0   \n",
       "4186        505.0     21070092500N         925.0                 3000.0   \n",
       "7738        549.0     37070043700N         437.0                  125.0   \n",
       "\n",
       "       county_name  latitude  longitude  \\\n",
       "1547      BERKELEY  33.23964  -79.89429   \n",
       "861       ANDERSON  34.51393  -82.57251   \n",
       "11325      PICKENS  34.67119  -82.83522   \n",
       "2399       CHESTER  34.70476  -81.20483   \n",
       "4501    GREENVILLE  35.04325  -82.43646   \n",
       "...            ...       ...        ...   \n",
       "8677      RICHLAND  34.04057  -80.99772   \n",
       "9257   SPARTANBURG  34.90371  -82.12373   \n",
       "1896    CHARLESTON  32.82748  -79.81605   \n",
       "4186      FLORENCE  34.21543  -79.70426   \n",
       "7738        OCONEE  34.56908  -83.12687   \n",
       "\n",
       "                                       route_leg_descrip route_type  year  \n",
       "1547           US 17 ALT (N HWY 17A) TO SC 402 (HWY 402)         SC  2018  \n",
       "861      S- 245 (BLUE RIDGE AV) TO US 29 (HIGHWAY 29  N)         SC  2018  \n",
       "11325      L- 320 (PERIMETER RD) TO US 76 (ANDERSON HWY)         SC  2018  \n",
       "2399      US 321 BUS (COLUMBIA ST) TO S- 103 (HARRIS ST)         SC  2018  \n",
       "4501               US 276 (GEER HWY) TO US 25 (N 25 HWY)         SC  2018  \n",
       "...                                                  ...        ...   ...  \n",
       "8677   SC 16 (N BELTLINE BLVD) TO S- 289 CON (PINE BE...         SC  2018  \n",
       "9257        SC 101 (HIGHWAY 101 S) TO SC 290 (E MAIN ST)         SC  2018  \n",
       "1896   SC 517 (ISLE OF PALMS CONNECTOR) TO S- 921 (SI...         SC  2018  \n",
       "4186                           S- 24 TO S- 13 (MOORE ST)         SC  2018  \n",
       "7738                S- 20 (DR JOHNS RD) TO LAKE HARTWELL         SC  2018  \n",
       "\n",
       "[165 rows x 10 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can't plot all lats and longs because the lats/longs are strings.\n",
    "test_plot.tail(165)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 0\n",
      "2010 404\n",
      "2016 0\n",
      "2015 0\n",
      "2009 442\n",
      "2012 359\n",
      "2011 371\n",
      "2014 163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year, df in shp_dfs_renamed.items():\n",
    "    try:\n",
    "        print(year, df.latitude.str.contains(':').sum())\n",
    "    except:\n",
    "        pass\n",
    "update_df.latitude.str.contains(':').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22931</td>\n",
       "      <td>107.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:10:30.277</td>\n",
       "      <td>-82:22:34.9755</td>\n",
       "      <td>S.C. 72 TO Pickens Street</td>\n",
       "      <td>SC</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22962</td>\n",
       "      <td>170.0</td>\n",
       "      <td>01040007200E</td>\n",
       "      <td>579.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:05:28.4781</td>\n",
       "      <td>-82:35:57.0661</td>\n",
       "      <td>SC-72 to SC-72</td>\n",
       "      <td>S-</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22964</td>\n",
       "      <td>173.0</td>\n",
       "      <td>01070024000E</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:07:42.3243</td>\n",
       "      <td>-82:26:00.7028</td>\n",
       "      <td>S-185 TO S.C. 28</td>\n",
       "      <td>SC</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23019</td>\n",
       "      <td>262.0</td>\n",
       "      <td>01070007300N</td>\n",
       "      <td>73.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:27:19.8048</td>\n",
       "      <td>-82:21:05.8571</td>\n",
       "      <td>Anderson County Line to SC-252</td>\n",
       "      <td>S-</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23046</td>\n",
       "      <td>315.0</td>\n",
       "      <td>01070014700N</td>\n",
       "      <td>147.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:22:54.3097</td>\n",
       "      <td>-82:25:16.6313</td>\n",
       "      <td>S-89 TO S-321</td>\n",
       "      <td>S-</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112437</td>\n",
       "      <td>469.0</td>\n",
       "      <td>43090036400E</td>\n",
       "      <td>364.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>Sumter</td>\n",
       "      <td>33:59:10.318</td>\n",
       "      <td>-80:28:20.795</td>\n",
       "      <td>S- 537, L- 215 TO SC 441</td>\n",
       "      <td>S-</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112462</td>\n",
       "      <td>515.0</td>\n",
       "      <td>43070103400E</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Sumter</td>\n",
       "      <td>33:57:29.149</td>\n",
       "      <td>-80:22:42.384</td>\n",
       "      <td>US 521 TO S- 269</td>\n",
       "      <td>S-</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112599</td>\n",
       "      <td>743.0</td>\n",
       "      <td>43070014500N</td>\n",
       "      <td>586.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>Sumter</td>\n",
       "      <td>33:55:59.163</td>\n",
       "      <td>-80:20:2.554</td>\n",
       "      <td>S- 234 TO S- 123, L- 585</td>\n",
       "      <td>S-</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112649</td>\n",
       "      <td>158.0</td>\n",
       "      <td>44040005600W</td>\n",
       "      <td>56.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Union</td>\n",
       "      <td>34:36:0.780</td>\n",
       "      <td>-81:50:58.284</td>\n",
       "      <td>County Line - LAURENS TO County Line - SPARTAN...</td>\n",
       "      <td>SC</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113022</td>\n",
       "      <td>263.0</td>\n",
       "      <td>46040016100N</td>\n",
       "      <td>161.0</td>\n",
       "      <td>27100.0</td>\n",
       "      <td>York</td>\n",
       "      <td>34:58:52.552</td>\n",
       "      <td>-81:5:16.716</td>\n",
       "      <td>SC 274, S- 81 TO S- 1115</td>\n",
       "      <td>SC</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "22931        107.0     01040002000E          20.0                 5800.0   \n",
       "22962        170.0     01040007200E         579.0                 1750.0   \n",
       "22964        173.0     01070024000E          72.0                 3400.0   \n",
       "23019        262.0     01070007300N          73.0                  400.0   \n",
       "23046        315.0     01070014700N         147.0                  100.0   \n",
       "...            ...              ...           ...                    ...   \n",
       "112437       469.0     43090036400E         364.0                 5500.0   \n",
       "112462       515.0     43070103400E        1428.0                 4000.0   \n",
       "112599       743.0     43070014500N         586.0                 1450.0   \n",
       "112649       158.0     44040005600W          56.0                  800.0   \n",
       "113022       263.0     46040016100N         161.0                27100.0   \n",
       "\n",
       "       county_name       latitude       longitude  \\\n",
       "22931    ABBEVILLE   34:10:30.277  -82:22:34.9755   \n",
       "22962    ABBEVILLE  34:05:28.4781  -82:35:57.0661   \n",
       "22964    ABBEVILLE  34:07:42.3243  -82:26:00.7028   \n",
       "23019    ABBEVILLE  34:27:19.8048  -82:21:05.8571   \n",
       "23046    ABBEVILLE  34:22:54.3097  -82:25:16.6313   \n",
       "...            ...            ...             ...   \n",
       "112437      Sumter   33:59:10.318   -80:28:20.795   \n",
       "112462      Sumter   33:57:29.149   -80:22:42.384   \n",
       "112599      Sumter   33:55:59.163    -80:20:2.554   \n",
       "112649       Union    34:36:0.780   -81:50:58.284   \n",
       "113022        York   34:58:52.552    -81:5:16.716   \n",
       "\n",
       "                                        route_leg_descrip route_type  year  \n",
       "22931                           S.C. 72 TO Pickens Street         SC  2010  \n",
       "22962                                      SC-72 to SC-72         S-  2010  \n",
       "22964                                    S-185 TO S.C. 28         SC  2010  \n",
       "23019                      Anderson County Line to SC-252         S-  2010  \n",
       "23046                                       S-89 TO S-321         S-  2010  \n",
       "...                                                   ...        ...   ...  \n",
       "112437                           S- 537, L- 215 TO SC 441         S-  2014  \n",
       "112462                                   US 521 TO S- 269         S-  2014  \n",
       "112599                           S- 234 TO S- 123, L- 585         S-  2014  \n",
       "112649  County Line - LAURENS TO County Line - SPARTAN...         SC  2014  \n",
       "113022                           SC 274, S- 81 TO S- 1115         SC  2014  \n",
       "\n",
       "[1749 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.loc[traffic_df.latitude.str.contains(':')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.loc[traffic_df.latitude.str.contains(':'), 'latitude'] = traffic_df.loc[traffic_df.latitude.str.contains(':'), 'latitude'].apply(convert_lat_long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.loc[traffic_df.longitude.str.contains(':'), 'longitude'] = traffic_df.loc[traffic_df.longitude.str.contains(':'), 'longitude'].apply(convert_lat_long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df['latitude'] = traffic_df.latitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df['longitude'] = traffic_df.longitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pct change year over year for average daily traffic\n",
    "traffic_df['traffic_yearly_pct_change'] = traffic_df \\\n",
    "    .sort_values(['station_id', 'route_identifier', 'route_number', 'year']) \\\n",
    "    .groupby(['station_id', 'route_identifier', 'route_number']) \\\n",
    "    .average_daily_traffic \\\n",
    "    .pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = traffic_df.sort_values(['station_id', 'route_identifier', 'route_number', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "      <th>traffic_yearly_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46302</td>\n",
       "      <td>100.0</td>\n",
       "      <td>04020002900N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>34.35590</td>\n",
       "      <td>-82.81412</td>\n",
       "      <td>State Line - GEORGIA TO SC 187 (HIGHWAY 187  S)</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>08020001702N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>53100.0</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>33.03701</td>\n",
       "      <td>-80.15366</td>\n",
       "      <td>County Line - DORCHESTER TO I- 26</td>\n",
       "      <td>US</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.288835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107867</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28040001200E</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>KERSHAW</td>\n",
       "      <td>34.11999</td>\n",
       "      <td>-80.77968</td>\n",
       "      <td>County Line - RICHLAND TO S- 47 (FORT JACKSON RD)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46303</td>\n",
       "      <td>101.0</td>\n",
       "      <td>04020002900N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>34.40918</td>\n",
       "      <td>-82.79075</td>\n",
       "      <td>SC 187 (HIGHWAY 187  S) TO US 29 BUS (HIGHWAY ...</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35410</td>\n",
       "      <td>101.0</td>\n",
       "      <td>07020001700N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>32.64004</td>\n",
       "      <td>-80.85637</td>\n",
       "      <td>County Line - JASPER TO US 17 ALT (CASTLE HALL...</td>\n",
       "      <td>US</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.441860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50675</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>23010018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>34.77331</td>\n",
       "      <td>-82.44549</td>\n",
       "      <td>SC 153 (153 HWY) TO I- 85</td>\n",
       "      <td>I-</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95757</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>23010018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>16700.0</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>34.80352</td>\n",
       "      <td>-82.42446</td>\n",
       "      <td>US 25 (WHITE HORSE RD) TO  , SC 20</td>\n",
       "      <td>I-</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.590476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9271</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>42010058500S</td>\n",
       "      <td>585.0</td>\n",
       "      <td>32200.0</td>\n",
       "      <td>SPARTANBURG</td>\n",
       "      <td>34.97494</td>\n",
       "      <td>-81.94188</td>\n",
       "      <td>US 176 CO2 (N CHURCH ST), SC 9 TO US 221 (WHIT...</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.201493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9272</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>42010058500S</td>\n",
       "      <td>585.0</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>SPARTANBURG</td>\n",
       "      <td>34.97158</td>\n",
       "      <td>-81.93761</td>\n",
       "      <td>US 221 (WHITNEY RD) TO US 176 (N PINE ST)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.214008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46224</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>AIKEN</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>US 25 CON (US 25 CONNECTOR) TO I- 20</td>\n",
       "      <td>I-</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.202381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6200 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "46302        100.0     04020002900N          29.0                 4000.0   \n",
       "69660        100.0     08020001702N          17.0                53100.0   \n",
       "107867       100.0     28040001200E          12.0                 4100.0   \n",
       "46303        101.0     04020002900N          29.0                 2100.0   \n",
       "35410        101.0     07020001700N          17.0                12400.0   \n",
       "...            ...              ...           ...                    ...   \n",
       "50675       2435.0     23010018500N         185.0                 5000.0   \n",
       "95757       2439.0     23010018500N         185.0                16700.0   \n",
       "9271        2489.0     42010058500S         585.0                32200.0   \n",
       "9272        2491.0     42010058500S         585.0                31200.0   \n",
       "46224       2607.0     02010052000E         520.0                10100.0   \n",
       "\n",
       "        county_name  latitude  longitude  \\\n",
       "46302      ANDERSON  34.35590  -82.81412   \n",
       "69660      BERKELEY  33.03701  -80.15366   \n",
       "107867      KERSHAW  34.11999  -80.77968   \n",
       "46303      ANDERSON  34.40918  -82.79075   \n",
       "35410      BEAUFORT  32.64004  -80.85637   \n",
       "...             ...       ...        ...   \n",
       "50675    GREENVILLE  34.77331  -82.44549   \n",
       "95757    GREENVILLE  34.80352  -82.42446   \n",
       "9271    SPARTANBURG  34.97494  -81.94188   \n",
       "9272    SPARTANBURG  34.97158  -81.93761   \n",
       "46224         AIKEN  33.56019  -81.92848   \n",
       "\n",
       "                                        route_leg_descrip route_type  year  \\\n",
       "46302     State Line - GEORGIA TO SC 187 (HIGHWAY 187  S)         US  2015   \n",
       "69660                   County Line - DORCHESTER TO I- 26         US  2017   \n",
       "107867  County Line - RICHLAND TO S- 47 (FORT JACKSON RD)         SC  2014   \n",
       "46303   SC 187 (HIGHWAY 187  S) TO US 29 BUS (HIGHWAY ...         US  2015   \n",
       "35410   County Line - JASPER TO US 17 ALT (CASTLE HALL...         US  2016   \n",
       "...                                                   ...        ...   ...   \n",
       "50675                           SC 153 (153 HWY) TO I- 85         I-  2015   \n",
       "95757                  US 25 (WHITE HORSE RD) TO  , SC 20         I-  2011   \n",
       "9271    US 176 CO2 (N CHURCH ST), SC 9 TO US 221 (WHIT...         SC  2018   \n",
       "9272            US 221 (WHITNEY RD) TO US 176 (N PINE ST)         SC  2018   \n",
       "46224                US 25 CON (US 25 CONNECTOR) TO I- 20         I-  2015   \n",
       "\n",
       "        traffic_yearly_pct_change  \n",
       "46302                    0.290323  \n",
       "69660                    0.288835  \n",
       "107867                   0.413793  \n",
       "46303                    0.312500  \n",
       "35410                    0.441860  \n",
       "...                           ...  \n",
       "50675                    0.250000  \n",
       "95757                    0.590476  \n",
       "9271                     0.201493  \n",
       "9272                     0.214008  \n",
       "46224                    0.202381  \n",
       "\n",
       "[6200 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df[traffic_df['traffic_yearly_pct_change'] > 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zillow Sales data by Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate up\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>StateName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>2008-03</th>\n",
       "      <th>2008-04</th>\n",
       "      <th>2008-05</th>\n",
       "      <th>2008-06</th>\n",
       "      <th>2008-07</th>\n",
       "      <th>2008-08</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>seasAdj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61639</td>\n",
       "      <td>10025</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>61637</td>\n",
       "      <td>10023</td>\n",
       "      <td>New York</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Texas</td>\n",
       "      <td>4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  RegionName StateName  SizeRank  2008-03  2008-04  2008-05  \\\n",
       "0     61639       10025  New York         1      NaN      NaN      NaN   \n",
       "1     84654       60657  Illinois         2      NaN      NaN      NaN   \n",
       "2     61637       10023  New York         3      NaN      NaN      NaN   \n",
       "3     91982       77494     Texas         4     56.0     71.0     84.0   \n",
       "4     84616       60614  Illinois         5      NaN      NaN      NaN   \n",
       "\n",
       "   2008-06  2008-07  2008-08  ...  2019-01  2019-02  2019-03  2019-04  \\\n",
       "0      NaN      NaN      NaN  ...     76.0     33.0     47.0     56.0   \n",
       "1      NaN      NaN      NaN  ...     91.0     77.0    113.0    157.0   \n",
       "2      NaN      NaN      NaN  ...     80.0     45.0     63.0     45.0   \n",
       "3     95.0    116.0     86.0  ...     86.0    112.0    186.0    218.0   \n",
       "4      NaN      NaN      NaN  ...     75.0     85.0    144.0    163.0   \n",
       "\n",
       "   2019-05  2019-06  2019-07  2019-08  2019-09  seasAdj  \n",
       "0     35.0     70.0     78.0     66.0     63.0        0  \n",
       "1    189.0    165.0    186.0    141.0    152.0        0  \n",
       "2     66.0     85.0     79.0     90.0     95.0        0  \n",
       "3    200.0    204.0    245.0    226.0      NaN        0  \n",
       "4    219.0    209.0    204.0    196.0    173.0        0  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "sales_df = pd.read_csv('Sale_Counts_Zip.csv')\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very wide - sales are recording in columns. Our steps for prepping this data will be to:\n",
    "1) Filter down to only South Carolina Zip Codes\n",
    "\n",
    "2) Drop columns we don't care about\n",
    "\n",
    "3) Convert records from wide to tall format\n",
    "\n",
    "4) Get the sum of sales per zipcode per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only SC\n",
    "sales_df = sales_df.loc[sales_df.StateName == 'South Carolina']\n",
    "\n",
    "# drop columns we don't care about and rename columns\n",
    "sales_df = sales_df.drop(['RegionID', 'StateName', 'seasAdj'], axis=1)\n",
    "sales_df.rename(columns={'RegionName': 'ZipCode'}, inplace=True)\n",
    "sales_df = sales_df.set_index(['ZipCode', 'SizeRank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>2008-03</th>\n",
       "      <th>2008-04</th>\n",
       "      <th>2008-05</th>\n",
       "      <th>2008-06</th>\n",
       "      <th>2008-07</th>\n",
       "      <th>2008-08</th>\n",
       "      <th>2008-09</th>\n",
       "      <th>2008-10</th>\n",
       "      <th>2008-11</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-12</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZipCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29072</td>\n",
       "      <td>227</td>\n",
       "      <td>63.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29730</td>\n",
       "      <td>287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29464</td>\n",
       "      <td>291</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29681</td>\n",
       "      <td>350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SizeRank  2008-03  2008-04  2008-05  2008-06  2008-07  2008-08  \\\n",
       "ZipCode                                                                   \n",
       "29732         180      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "29072         227     63.0     89.0     75.0     70.0     76.0     65.0   \n",
       "29730         287      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "29464         291     58.0     78.0     73.0     88.0     81.0     73.0   \n",
       "29681         350      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "         2008-09  2008-10  2008-11  ...  2018-12  2019-01  2019-02  2019-03  \\\n",
       "ZipCode                             ...                                       \n",
       "29732        NaN      NaN      NaN  ...    127.0     75.0     75.0    134.0   \n",
       "29072       68.0     47.0     42.0  ...    165.0     88.0     88.0    126.0   \n",
       "29730        NaN      NaN      NaN  ...    119.0     71.0     60.0     91.0   \n",
       "29464       57.0     69.0     49.0  ...     76.0     63.0     91.0     94.0   \n",
       "29681        NaN      NaN      NaN  ...    100.0     99.0    118.0    150.0   \n",
       "\n",
       "         2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  \n",
       "ZipCode                                                        \n",
       "29732      140.0    125.0    136.0    128.0    138.0    151.0  \n",
       "29072      132.0    192.0    156.0    180.0    169.0    142.0  \n",
       "29730       95.0    116.0    111.0     87.0    100.0    107.0  \n",
       "29464      138.0    116.0    135.0    146.0    141.0      NaN  \n",
       "29681      129.0    165.0    136.0    151.0    150.0    161.0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51258</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51259</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51260</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51261</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51262</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51263 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZipCode  SizeRank YearMonth  Sales\n",
       "0        29732       180   2014-08  127.0\n",
       "1        29732       180   2014-09  145.0\n",
       "2        29732       180   2014-10  124.0\n",
       "3        29732       180   2014-11  121.0\n",
       "4        29732       180   2014-12  124.0\n",
       "...        ...       ...       ...    ...\n",
       "51258      820     31089   2019-05    0.0\n",
       "51259      820     31089   2019-06    0.0\n",
       "51260      820     31089   2019-07    0.0\n",
       "51261      820     31089   2019-08    0.0\n",
       "51262      820     31089   2019-09    0.0\n",
       "\n",
       "[51263 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack all sales into one column\n",
    "sales_df = sales_df.stack().reset_index()\n",
    "sales_df.columns = ['ZipCode', 'SizeRank', 'YearMonth', 'Sales']\n",
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ZipCode  SizeRank YearMonth  Sales  Year\n",
       "0    29732       180   2014-08  127.0  2014\n",
       "1    29732       180   2014-09  145.0  2014\n",
       "2    29732       180   2014-10  124.0  2014\n",
       "3    29732       180   2014-11  121.0  2014\n",
       "4    29732       180   2014-12  124.0  2014"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the year out of the Sales record\n",
    "sales_df['Year'] = sales_df['YearMonth'].str.split('-').str[0]\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipCode  SizeRank  Year\n",
       "29944    13111     2017    42.0\n",
       "                   2018    28.0\n",
       "                   2019     3.0\n",
       "29945    12932     2008    22.0\n",
       "                   2009    20.0\n",
       "                   2010    20.0\n",
       "                   2011    25.0\n",
       "                   2012    30.0\n",
       "                   2013    23.0\n",
       "                   2014    23.0\n",
       "                   2015    26.0\n",
       "                   2016    14.0\n",
       "                   2017    23.0\n",
       "                   2018    17.0\n",
       "                   2019     3.0\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yearly sales calculated - sum over ZipCode and year\n",
    "yearly_sales = sales_df.groupby(['ZipCode', 'SizeRank', 'Year']).Sales.sum()\n",
    "yearly_sales.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip to Lat/Long xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "zip_xref = pd.read_csv('sc-zip-code-latitude-and-longitude.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Daylight savings time flag</th>\n",
       "      <th>geopoint</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29607</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29164</td>\n",
       "      <td>Wagener</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29325</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29520</td>\n",
       "      <td>Cheraw</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29615</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Zip        City State   Latitude  Longitude  Timezone  \\\n",
       "0  29607  Greenville    SC  34.825592  -82.34099        -5   \n",
       "1  29164     Wagener    SC  33.659078  -81.40845        -5   \n",
       "2  29325     Clinton    SC  34.470115  -81.86761        -5   \n",
       "3  29520      Cheraw    SC  34.688620  -79.92315        -5   \n",
       "4  29615  Greenville    SC  34.866801  -82.31739        -5   \n",
       "\n",
       "   Daylight savings time flag   geopoint  Unnamed: 8  \n",
       "0                           1  34.825592   -82.34099  \n",
       "1                           1  33.659078   -81.40845  \n",
       "2                           1  34.470115   -81.86761  \n",
       "3                           1  34.688620   -79.92315  \n",
       "4                           1  34.866801   -82.31739  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_xref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the zip code to lat/long xref to the yearly sales data\n",
    "merged_sales = yearly_sales.reset_index().merge(zip_xref, how='left', left_on='ZipCode', right_on='Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop zip codes that have a length less than 5\n",
    "merged_sales = merged_sales.loc[merged_sales.ZipCode.apply(lambda x: len(str(x)) >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns i don't care about\n",
    "merged_sales = merged_sales.drop(['Zip','Timezone', 'Daylight savings time flag', 'geopoint', 'Unnamed: 8'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2014</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2017</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2018</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2012</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2013</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2018</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>29006</td>\n",
       "      <td>9409</td>\n",
       "      <td>2008</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Batesburg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.872503</td>\n",
       "      <td>-81.55245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ZipCode  SizeRank  Year  Sales       City State   Latitude  Longitude\n",
       "12    29001     17838  2008   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "13    29001     17838  2009   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "14    29001     17838  2010   11.0     Alcolu    SC  33.769930  -80.17278\n",
       "15    29001     17838  2011    8.0     Alcolu    SC  33.769930  -80.17278\n",
       "16    29001     17838  2012    9.0     Alcolu    SC  33.769930  -80.17278\n",
       "17    29001     17838  2013   12.0     Alcolu    SC  33.769930  -80.17278\n",
       "18    29001     17838  2014   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "19    29001     17838  2015    3.0     Alcolu    SC  33.769930  -80.17278\n",
       "20    29001     17838  2016   14.0     Alcolu    SC  33.769930  -80.17278\n",
       "21    29001     17838  2017   12.0     Alcolu    SC  33.769930  -80.17278\n",
       "22    29001     17838  2018   19.0     Alcolu    SC  33.769930  -80.17278\n",
       "23    29001     17838  2019    4.0     Alcolu    SC  33.769930  -80.17278\n",
       "24    29003     11324  2008    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "25    29003     11324  2009    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "26    29003     11324  2010    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "27    29003     11324  2011    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "28    29003     11324  2012   19.0    Bamberg    SC  33.272026  -81.03203\n",
       "29    29003     11324  2013   26.0    Bamberg    SC  33.272026  -81.03203\n",
       "30    29003     11324  2014    3.0    Bamberg    SC  33.272026  -81.03203\n",
       "31    29003     11324  2015    1.0    Bamberg    SC  33.272026  -81.03203\n",
       "32    29003     11324  2016    7.0    Bamberg    SC  33.272026  -81.03203\n",
       "33    29003     11324  2017    2.0    Bamberg    SC  33.272026  -81.03203\n",
       "34    29003     11324  2018    9.0    Bamberg    SC  33.272026  -81.03203\n",
       "35    29003     11324  2019    3.0    Bamberg    SC  33.272026  -81.03203\n",
       "36    29006      9409  2008   93.0  Batesburg    SC  33.872503  -81.55245"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_sales.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I'd like to calculate how far each Zip Code is from each station. \n",
    "I searched online for a way to calculate the as-the-crow-flies distance between two lat/long points.\n",
    "The first reference I found referred to the \"haversine\" formula, detailed here - https://www.movable-type.co.uk/scripts/latlong.html. \n",
    "I found a nice numpy implmentation on Stack Overflow here: https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas from derricw.\n",
    "\n",
    "In order to calculate the distance between each possible combination of points, I will be taking all unique lat/long points from traffic data and crossjoining with all unique lat/long points from zip code data. Then, I will apply the haversine formula to get the linear distance between each pair of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique zip to lat/long\n",
    "zip_xref['Latitude'] = zip_xref.Latitude.astype('float')\n",
    "zip_xref['Longitude'] = zip_xref.Longitude.astype('float')\n",
    "unique_zip = zip_xref.loc[:, ['Zip', 'Latitude', 'Longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zip   Latitude  Longitude\n",
       "0    29607  34.825592  -82.34099\n",
       "1    29164  33.659078  -81.40845\n",
       "2    29325  34.470115  -81.86761\n",
       "3    29520  34.688620  -79.92315\n",
       "4    29615  34.866801  -82.31739\n",
       "..     ...        ...        ...\n",
       "549  29592  34.283207  -79.47272\n",
       "550  29646  34.169781  -82.15474\n",
       "551  29142  33.462378  -80.50903\n",
       "552  29449  32.715745  -80.26738\n",
       "553  29564  33.493553  -79.87402\n",
       "\n",
       "[554 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique station/routeid/route number lat/long\n",
    "unique_station = traffic_df \\\n",
    "    .loc[:, ['station_id', 'route_identifier', 'route_number', 'latitude', 'longitude']] \\\n",
    "    .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_long</th>\n",
       "      <th>Zip</th>\n",
       "      <th>zip_lat</th>\n",
       "      <th>zip_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061833</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061834</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061835</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061836</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061837</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7061838 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_id route_identifier  route_number  station_lat  station_long  \\\n",
       "0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "...             ...              ...           ...          ...           ...   \n",
       "7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "\n",
       "           Zip    zip_lat  zip_long  \n",
       "0        29607  34.825592 -82.34099  \n",
       "1        29164  33.659078 -81.40845  \n",
       "2        29325  34.470115 -81.86761  \n",
       "3        29520  34.688620 -79.92315  \n",
       "4        29615  34.866801 -82.31739  \n",
       "...        ...        ...       ...  \n",
       "7061833  29592  34.283207 -79.47272  \n",
       "7061834  29646  34.169781 -82.15474  \n",
       "7061835  29142  33.462378 -80.50903  \n",
       "7061836  29449  32.715745 -80.26738  \n",
       "7061837  29564  33.493553 -79.87402  \n",
       "\n",
       "[7061838 rows x 8 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the cartesian product/crossjoin by merging on a uniform key\n",
    "unique_zip['key'] = 0\n",
    "unique_station['key'] = 0\n",
    "\n",
    "station_zip_xref = unique_station.merge(unique_zip, on='key').drop('key', axis=1)\n",
    "station_zip_xref.columns = [\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'station_lat',\n",
    "        'station_long',\n",
    "        'Zip',\n",
    "        'zip_lat',\n",
    "        'zip_long'\n",
    "    ]\n",
    "\n",
    "station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_zip_xref['distance_km'] = haversine_np(\n",
    "    station_zip_xref.station_long.values,\n",
    "    station_zip_xref.station_lat.values,\n",
    "    station_zip_xref.zip_long.values,\n",
    "    station_zip_xref.zip_lat.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_long</th>\n",
       "      <th>Zip</th>\n",
       "      <th>zip_lat</th>\n",
       "      <th>zip_long</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "      <td>50.578796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "      <td>124.877525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "      <td>54.263882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "      <td>233.784632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "      <td>55.504933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061833</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "      <td>240.272498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061834</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "      <td>70.885076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061835</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "      <td>131.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061836</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "      <td>180.818763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061837</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "      <td>190.459639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7061838 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_id route_identifier  route_number  station_lat  station_long  \\\n",
       "0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "...             ...              ...           ...          ...           ...   \n",
       "7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "\n",
       "           Zip    zip_lat  zip_long  distance_km  \n",
       "0        29607  34.825592 -82.34099    50.578796  \n",
       "1        29164  33.659078 -81.40845   124.877525  \n",
       "2        29325  34.470115 -81.86761    54.263882  \n",
       "3        29520  34.688620 -79.92315   233.784632  \n",
       "4        29615  34.866801 -82.31739    55.504933  \n",
       "...        ...        ...       ...          ...  \n",
       "7061833  29592  34.283207 -79.47272   240.272498  \n",
       "7061834  29646  34.169781 -82.15474    70.885076  \n",
       "7061835  29142  33.462378 -80.50903   131.964450  \n",
       "7061836  29449  32.715745 -80.26738   180.818763  \n",
       "7061837  29564  33.493553 -79.87402   190.459639  \n",
       "\n",
       "[7061838 rows x 9 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'station_zip_xref' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4c0c70bdf1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstation_zip_xref\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstation_zip_xref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_km\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distance_km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'station_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_sales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZipCode'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Zip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZipCode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mSales\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'station_zip_xref' is not defined"
     ]
    }
   ],
   "source": [
    "station_zip_xref \\\n",
    "    .loc[station_zip_xref.distance_km <= 50, ['Zip', 'distance_km', 'station_id', 'route_identifier', 'route_number']] \\\n",
    "    .merge(merged_sales[['ZipCode', 'Year', 'Sales']], left_on=['Zip'], right_on=['ZipCode']) \\\n",
    "    .groupby(['station_id', 'route_identifier', 'route_number', 'Year']) \\\n",
    "    .Sales \\\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I can calculate the home sales within a certain radius of a station for the current year or previous year and see if that has any bearing on traffic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29001</td>\n",
       "      <td>2008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29001</td>\n",
       "      <td>2009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>29001</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>29001</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>29001</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4507</td>\n",
       "      <td>29945</td>\n",
       "      <td>2015</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4508</td>\n",
       "      <td>29945</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4509</td>\n",
       "      <td>29945</td>\n",
       "      <td>2017</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4510</td>\n",
       "      <td>29945</td>\n",
       "      <td>2018</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4511</td>\n",
       "      <td>29945</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ZipCode  Year  Sales      City State   Latitude  Longitude\n",
       "12      29001  2008   10.0    Alcolu    SC  33.769930  -80.17278\n",
       "13      29001  2009   10.0    Alcolu    SC  33.769930  -80.17278\n",
       "14      29001  2010   11.0    Alcolu    SC  33.769930  -80.17278\n",
       "15      29001  2011    8.0    Alcolu    SC  33.769930  -80.17278\n",
       "16      29001  2012    9.0    Alcolu    SC  33.769930  -80.17278\n",
       "...       ...   ...    ...       ...   ...        ...        ...\n",
       "4507    29945  2015   26.0  Yemassee    SC  32.681058  -80.83348\n",
       "4508    29945  2016   14.0  Yemassee    SC  32.681058  -80.83348\n",
       "4509    29945  2017   23.0  Yemassee    SC  32.681058  -80.83348\n",
       "4510    29945  2018   17.0  Yemassee    SC  32.681058  -80.83348\n",
       "4511    29945  2019    3.0  Yemassee    SC  32.681058  -80.83348\n",
       "\n",
       "[4500 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_home_sales(traffic_df, sales_df, zip_xref, radius_cutoff, curr_or_prev='curr'):\n",
    "    filtered_zips = zip_xref.loc[zip_xref.distance_km <= radius_cutoff]\n",
    "    sales_modified = sales_df.copy(deep=True)\n",
    "    sales_modified['next_year'] = sales_modified.Year + 1\n",
    "    sales_per_station = zip_xref.merge(sales_modified, how='left', left_on='Zip', right_on='ZipCode')\n",
    "    sales_per_station = sales_per_station.groupby(['station_id', 'route_identifier', 'route_number'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      ZipCode  Year  Sales      City State   Latitude  Longitude\n",
       " 12      29001  2008   10.0    Alcolu    SC  33.769930  -80.17278\n",
       " 13      29001  2009   10.0    Alcolu    SC  33.769930  -80.17278\n",
       " 14      29001  2010   11.0    Alcolu    SC  33.769930  -80.17278\n",
       " 15      29001  2011    8.0    Alcolu    SC  33.769930  -80.17278\n",
       " 16      29001  2012    9.0    Alcolu    SC  33.769930  -80.17278\n",
       " ...       ...   ...    ...       ...   ...        ...        ...\n",
       " 4507    29945  2015   26.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4508    29945  2016   14.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4509    29945  2017   23.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4510    29945  2018   17.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4511    29945  2019    3.0  Yemassee    SC  32.681058  -80.83348\n",
       " \n",
       " [4500 rows x 7 columns],\n",
       "          station_id route_identifier  route_number  station_lat  station_long  \\\n",
       " 0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " ...             ...              ...           ...          ...           ...   \n",
       " 7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " \n",
       "            Zip    zip_lat  zip_long  distance_km  \n",
       " 0        29607  34.825592 -82.34099    50.578796  \n",
       " 1        29164  33.659078 -81.40845   124.877525  \n",
       " 2        29325  34.470115 -81.86761    54.263882  \n",
       " 3        29520  34.688620 -79.92315   233.784632  \n",
       " 4        29615  34.866801 -82.31739    55.504933  \n",
       " ...        ...        ...       ...          ...  \n",
       " 7061833  29592  34.283207 -79.47272   240.272498  \n",
       " 7061834  29646  34.169781 -82.15474    70.885076  \n",
       " 7061835  29142  33.462378 -80.50903   131.964450  \n",
       " 7061836  29449  32.715745 -80.26738   180.818763  \n",
       " 7061837  29564  33.493553 -79.87402   190.459639  \n",
       " \n",
       " [7061838 rows x 9 columns])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_sales, station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalprojects",
   "language": "python",
   "name": "generalprojects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
