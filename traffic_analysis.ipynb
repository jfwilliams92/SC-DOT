{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SC DOT Data and Zillow Home Sales - How has traffic in South Carolina changed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of my least favorite parts of the day is my daily commute. Anecdotally, I feel as if traffic has worsened/increased in South Carolina since I moved here in 2007, and it's worsening at an increasing rate every year.\n",
    "I stumbled across some data on the SC-DOT GIS page that I thought might help confirm or deny my suspicion.\n",
    "Here's where the data can be downloaded - https://www.scdot.org/travel/travel-mappinggis.aspx.\n",
    "The data in question that I'm examining are Annual Average Daily Traffic counts from the years 2009 - 2018.\n",
    "These data are recorded at the level of StationID and RouteIdentifier with additional information as well, including Latitude and Longitude of the recording Station.\n",
    "I downloaded the .zip files for each separately and then renamed them and put them into one folder - shp_files.\n",
    "The data come in both .shp and .dbf (Xbase) format.\n",
    "More about these file types here:\n",
    "TODO\n",
    "\n",
    "SCDOT has some interactive ArcGIS maps with these data points plotted already - http://scdot.maps.arcgis.com/apps/MinimalGallery/index.html?appid=7420aa1f39d84400a6d7e8cdaacc89cd\n",
    "\n",
    "However, these plots don't fully convey (to me) the true amount of traffic in SC, as all station points are plotted as little cars with no information about AADT, nor the change in traffic patterns year over year.\n",
    "Nor do they address any underlying causes of what may be driving potential traffic pattern changes.\n",
    "\n",
    "Tangentially, SCDOT does provide a wealth of other data for citizens to browse, some of which look quite interesting.\n",
    "http://scdot.maps.arcgis.com/apps/MinimalGallery/index.html?appid=e8ace63de0e6423394d04c9c091e893b#\n",
    "I am particularly interested in how the \"South Carolina Roads by Pavement Status\" dataset folds into the questions at hand here, but that goes beyond the scope of this post. Perhaps to be addressed later.\n",
    "\n",
    "Getting back on topic, one of the most intuitive drivers of change in traffic patterns could be popluation growth/decline in the areas nearby. I chose to use a data set from Zillow - https://www.zillow.com/research/data/ - that details Monthly Home Sales by ZipCode as a proxy to population growth per Zip Code.\n",
    "\n",
    "Finally, I also downloaded a data set from OpenDataSoft - https://public.opendatasoft.com/explore/dataset/us-zip-code-latitude-and-longitude/table/ - that cross references ZipCode to latitude and longitude. I only downloaded data for South Carolina.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions to Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) What do the data look like and what does it take to get them in a unified format?\n",
    "\n",
    "2) Has overall traffic increased in SC over the past 10 years?\n",
    "\n",
    "3) Are there are any areas in SC that show more aggressive traffic growth?\n",
    "\n",
    "4) Does number of home sales in Zip Codes within a certain radius of a station (e.g. 50 km) have any bearing on traffic numbers the next or same year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTables is not installed. No support for HDF output.\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simpledbf import Dbf5\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read GIS dbf data into dataframes, one file for each year between 2009 and 2018\n",
    "shp_dfs = {}\n",
    "for root, dirs, files in os.walk(\"./shp_files\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".dbf\"):\n",
    "            # print(file.split('.')[0])\n",
    "            dbf = Dbf5(os.path.join(root, file))\n",
    "            df = dbf.to_dataframe()\n",
    "            shp_dfs[file.split('.')[0]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountyNumb</th>\n",
       "      <th>RouteTypeN</th>\n",
       "      <th>RouteType1</th>\n",
       "      <th>RouteNumbe</th>\n",
       "      <th>MeterMileP</th>\n",
       "      <th>BeginMileP</th>\n",
       "      <th>EndMilePoi</th>\n",
       "      <th>StationNum</th>\n",
       "      <th>Termini</th>\n",
       "      <th>FactoredAA</th>\n",
       "      <th>FactoredA1</th>\n",
       "      <th>MapLRS</th>\n",
       "      <th>Status1</th>\n",
       "      <th>ID1</th>\n",
       "      <th>RouteAuxil</th>\n",
       "      <th>CountyName</th>\n",
       "      <th>Long</th>\n",
       "      <th>Lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.82</td>\n",
       "      <td>101.0</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>34.41979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4.345</td>\n",
       "      <td>3.82</td>\n",
       "      <td>4.91</td>\n",
       "      <td>103.0</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (MAIN ST W)</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.35324</td>\n",
       "      <td>34.38344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>5.633</td>\n",
       "      <td>4.91</td>\n",
       "      <td>7.28</td>\n",
       "      <td>105.0</td>\n",
       "      <td>SC 184 (MAIN ST W) TO County Line - GREENWOOD</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>34.37099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>109.0</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71...</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38017</td>\n",
       "      <td>34.17889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>SC</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>111.0</td>\n",
       "      <td>SC 71 (N MAIN ST) TO L- 170 (RICHEY ST)</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>-82.38114</td>\n",
       "      <td>34.18369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CountyNumb  RouteTypeN RouteType1  RouteNumbe  MeterMileP  BeginMileP  \\\n",
       "0         1.0         2.0         US       178.0       1.196        0.00   \n",
       "1         1.0         2.0         US       178.0       4.345        3.82   \n",
       "2         1.0         2.0         US       178.0       5.633        4.91   \n",
       "3         1.0         4.0         SC        20.0       0.074        0.00   \n",
       "4         1.0         4.0         SC        20.0       0.439        0.18   \n",
       "\n",
       "   EndMilePoi  StationNum                                            Termini  \\\n",
       "0        3.82       101.0        County Line - ANDERSON TO S- 166 (DRAKE RD)   \n",
       "1        4.91       103.0            S- 166 (DRAKE RD) TO SC 184 (MAIN ST W)   \n",
       "2        7.28       105.0      SC 184 (MAIN ST W) TO County Line - GREENWOOD   \n",
       "3        0.18       109.0  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71...   \n",
       "4        0.45       111.0            SC 71 (N MAIN ST) TO L- 170 (RICHEY ST)   \n",
       "\n",
       "   FactoredAA  FactoredA1        MapLRS Status1  ID1 RouteAuxil CountyName  \\\n",
       "0      4300.0      2018.0  01020017800E     NaN    1        NaN  ABBEVILLE   \n",
       "1      4600.0      2018.0  01020017800E     NaN    2        NaN  ABBEVILLE   \n",
       "2      3600.0      2018.0  01020017800E     NaN    3        NaN  ABBEVILLE   \n",
       "3      4900.0      2018.0  01040002000E     NaN    4        NaN  ABBEVILLE   \n",
       "4      2200.0      2018.0  01040002000E     NaN    5        NaN  ABBEVILLE   \n",
       "\n",
       "        Long       Lat  \n",
       "0  -82.38521  34.41979  \n",
       "1  -82.35324  34.38344  \n",
       "2  -82.33765  34.37099  \n",
       "3  -82.38017  34.17889  \n",
       "4  -82.38114  34.18369  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give an ol look see at the most recent year\n",
    "shp_dfs['2018'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by eyeballing, it can be surmised what each field name means, along with the helpful data dictionary supplied by SCDOT.\n",
    "For example \"FactorerA1\" is clearly the year of this particular dataset, while \"Long\" and \"Lat\" hold the longitude and latitude of the datapoint.\n",
    "\n",
    "Next, we'll check to see if the column names match across all the dataframes we have, one for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the columns in the dfs match - per df, convert columns to sets. Check the intersection of all sets.\n",
    "col_sets = map(lambda x: set(x.columns), shp_dfs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the list of column sets into set.intersection, which returns common elements in set\n",
    "common_cols = set.intersection(*col_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID1'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check to see what's common between the dfs\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh! There's only one column that is common between all of the dataframes. Let's dig in a little more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CountyNumb', 'RouteTypeN', 'RouteType1', 'RouteNumbe', 'MeterMileP',\n",
      "       'BeginMileP', 'EndMilePoi', 'StationNum', 'Termini', 'FactoredAA',\n",
      "       'FactoredA1', 'MapLRS', 'Status1', 'ID1', 'RouteAuxil', 'CountyName',\n",
      "       'Long', 'Lat'],\n",
      "      dtype='object') 18\n",
      "Index(['Station_Nu', 'Route_LRS', 'County_ID', 'Route_Type', 'Route_Numb',\n",
      "       'Route_Auxi', 'Descriptio', 'Count', 'Year', 'ID1'],\n",
      "      dtype='object') 10\n",
      "Index(['STATION_NU', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'ROUTE_TYPE', 'ROUTE_NUMB', 'ROUTE_AUX',\n",
      "       'COUNT', 'YEAR', 'DESCRIPTIO', 'ID1', 'GMRotation'],\n",
      "      dtype='object') 15\n",
      "Index(['CountyName', 'RouteTypeN', 'RouteNumbe', 'RouteAuxil', 'MeterMileP',\n",
      "       'BegiNMileP', 'EndMilePoi', 'StationNum', 'Termini', 'FactoredAA',\n",
      "       'FactoredA1', 'MapLRS', 'Status1', 'ID1', 'Latitude', 'Longitude'],\n",
      "      dtype='object') 16\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'ATR_NUM', 'MAP', 'RouteNum', 'termini', 'Count', 'Year',\n",
      "       'County', 'RouteType', 'AUX', 'GMRotation'],\n",
      "      dtype='object') 17\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'ATR_NUM', 'County', 'Station_Nu',\n",
      "       'Route_Type', 'Route_Numb', 'AUX', 'Count', 'Year', 'Descriptio',\n",
      "       'GMRotation'],\n",
      "      dtype='object') 18\n",
      "Index(['Route_Type', 'Route_Numb', 'Route_Auxi', 'Meter_Mile', 'Begin_Mile',\n",
      "       'End_MilePo', 'Station_Nu', 'Termini', 'Factored_A', 'Factored_1',\n",
      "       'RouteLRS', 'ID1', 'County_Nam'],\n",
      "      dtype='object') 13\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'COUNTY_ID', 'county', 'F2', 'station1', 'rtetype',\n",
      "       'rtenumb', 'rteaux', 'bmp', 'emp', 'termini', 'rtelrs', 'CONNN', 'aadt',\n",
      "       'aadtyr', 'GMRotation'],\n",
      "      dtype='object') 22\n",
      "Index(['STATION_NU', 'COUNT', 'DESCRIPTIO', 'YEAR', 'ROUTE_TYPE', 'ROUTE_NUMB',\n",
      "       'ROUTE_AUX', 'MILE_POINT', 'ROUTE_LRS', 'COUNTY_ID', 'MAP_TYPE',\n",
      "       'LATITUDE', 'LONGITUDE', 'ID1', 'GMRotation'],\n",
      "      dtype='object') 15\n",
      "Index(['STATION', 'MILE_POINT', 'ROUTE_LRS', 'MAP_TYPE', 'ID1', 'LATITUDE',\n",
      "       'LONGITUDE', 'CountyName', 'RouteType', 'rtenum', 'AUX', 'ATR_NUM',\n",
      "       'MAP', 'termini', 'Year', 'Count', 'ID2', 'GMRotation'],\n",
      "      dtype='object') 18\n"
     ]
    }
   ],
   "source": [
    "# Let's check to see what the actual columns are named and how many there are\n",
    "for df in shp_dfs.values():\n",
    "    print(df.columns, len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see that we have different numbers of columns per year, and that most of the columns are all named differently. We'll try to address that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we'll get better results if we do some simple string formatting first\n",
    "for df in shp_dfs.values():\n",
    "    df.columns = [c.replace('_', '').lower().strip() for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id1'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check set intersection again\n",
    "col_sets = list(map(lambda x: set(x.columns), shp_dfs.values()))\n",
    "set.intersection(*col_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still only one column that's the same! Time to do some brute-force mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 Index(['countynumb', 'routetypen', 'routetype1', 'routenumbe', 'metermilep',\n",
      "       'beginmilep', 'endmilepoi', 'stationnum', 'termini', 'factoredaa',\n",
      "       'factoreda1', 'maplrs', 'status1', 'id1', 'routeauxil', 'countyname',\n",
      "       'long', 'lat'],\n",
      "      dtype='object') 18\n",
      "2013 Index(['stationnu', 'routelrs', 'countyid', 'routetype', 'routenumb',\n",
      "       'routeauxi', 'descriptio', 'count', 'year', 'id1'],\n",
      "      dtype='object') 10\n",
      "2010 Index(['stationnu', 'milepoint', 'routelrs', 'maptype', 'latitude',\n",
      "       'longitude', 'countyid', 'routetype', 'routenumb', 'routeaux', 'count',\n",
      "       'year', 'descriptio', 'id1', 'gmrotation'],\n",
      "      dtype='object') 15\n",
      "2016 Index(['countyname', 'routetypen', 'routenumbe', 'routeauxil', 'metermilep',\n",
      "       'beginmilep', 'endmilepoi', 'stationnum', 'termini', 'factoredaa',\n",
      "       'factoreda1', 'maplrs', 'status1', 'id1', 'latitude', 'longitude'],\n",
      "      dtype='object') 16\n",
      "2015 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'atrnum', 'map', 'routenum', 'termini', 'count', 'year',\n",
      "       'county', 'routetype', 'aux', 'gmrotation'],\n",
      "      dtype='object') 17\n",
      "2009 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyid', 'atrnum', 'county', 'stationnu', 'routetype',\n",
      "       'routenumb', 'aux', 'count', 'year', 'descriptio', 'gmrotation'],\n",
      "      dtype='object') 18\n",
      "2017 Index(['routetype', 'routenumb', 'routeauxi', 'metermile', 'beginmile',\n",
      "       'endmilepo', 'stationnu', 'termini', 'factoreda', 'factored1',\n",
      "       'routelrs', 'id1', 'countynam'],\n",
      "      dtype='object') 13\n",
      "2012 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyid', 'county', 'f2', 'station1', 'rtetype',\n",
      "       'rtenumb', 'rteaux', 'bmp', 'emp', 'termini', 'rtelrs', 'connn', 'aadt',\n",
      "       'aadtyr', 'gmrotation'],\n",
      "      dtype='object') 22\n",
      "2011 Index(['stationnu', 'count', 'descriptio', 'year', 'routetype', 'routenumb',\n",
      "       'routeaux', 'milepoint', 'routelrs', 'countyid', 'maptype', 'latitude',\n",
      "       'longitude', 'id1', 'gmrotation'],\n",
      "      dtype='object') 15\n",
      "2014 Index(['station', 'milepoint', 'routelrs', 'maptype', 'id1', 'latitude',\n",
      "       'longitude', 'countyname', 'routetype', 'rtenum', 'aux', 'atrnum',\n",
      "       'map', 'termini', 'year', 'count', 'id2', 'gmrotation'],\n",
      "      dtype='object') 18\n"
     ]
    }
   ],
   "source": [
    "for year, df in shp_dfs.items():\n",
    "    print(year, df.columns, len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary that will allow us to rename columns from key to value.\n",
    "# we won't map every column - only keep a subset\n",
    "col_mapping_dict = {\n",
    "    **dict.fromkeys(['station', 'stationnu', 'stationnum'], 'station_id'),\n",
    "    **dict.fromkeys(['latitude', 'lat'], 'latitude'),\n",
    "    **dict.fromkeys(['longitude', 'long'], 'longitude'), \n",
    "    **dict.fromkeys(['aadtyr', 'year', 'factored1', 'factoreda1'], 'year'),\n",
    "    **dict.fromkeys(['routelrs', 'maplrs'], 'route_identifier'),\n",
    "    **dict.fromkeys(['termini', 'descriptio'], 'route_leg_descrip'),\n",
    "    # **dict.fromkeys(['beginmilep', 'beginmile'], 'route_leg_beginmile'),\n",
    "    # **dict.fromkeys(['endmilepo', 'endmilepoi'], 'route_leg_endmile'),\n",
    "    **dict.fromkeys(['routetype', 'rtetype', 'routetypen'], 'route_type'),   # has to be a numeric column as well, some collision here\n",
    "    **dict.fromkeys(['rtenum', 'rtenumb', 'routenumb', 'routenum', 'routenumbe'], 'route_number'),\n",
    "    **dict.fromkeys(['county', 'countyname', 'countynam'], 'county_name'),\n",
    "    # **dict.fromkeys(['countyid', 'countynumb'], 'county_id'),\n",
    "    **dict.fromkeys(['aadt', 'factoreda', 'count', 'factoredaa'], 'average_daily_traffic')\n",
    "    # **dict.fromkeys(['id1'], 'row_number')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns as per mapping dict\n",
    "shp_dfs_renamed = {year: df.rename(columns=col_mapping_dict) for year, df in shp_dfs.items()}\n",
    "# drop columns not mapped\n",
    "shp_dfs_renamed = {year: df.drop([c for c in df.columns if c not in col_mapping_dict.values()], axis=1) for year, df in shp_dfs_renamed.items()}\n",
    "# drop any duplicated columns\n",
    "shp_dfs_renamed = {year: df.loc[:, ~df.columns.duplicated()] for year, df in shp_dfs_renamed.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# still some collision - column name can mean different things in different years.\n",
    "# drop some columns that still aren't right\n",
    "shp_dfs_renamed['2009'].drop(['county_name', 'route_type'], axis=1, inplace=True)\n",
    "shp_dfs_renamed['2012'].drop(['county_name', 'route_type'], axis=1, inplace=True)\n",
    "shp_dfs_renamed['2013'].drop('route_type', axis=1, inplace=True)\n",
    "shp_dfs_renamed['2017'].drop('county_name', axis=1, inplace=True)\n",
    "shp_dfs_renamed['2018'].drop('route_type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK - columns should now all be corrently named across years. We also dropped a subset of the columns, only keeping a subset.\n",
    "Let's check now to make sure that the records we have are unique where they're supposed to be - namely, we should only have one row per year for a stationid/routeid/routenumber combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicated rows in dataframes\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df = df.drop_duplicates()\n",
    "    shp_dfs_renamed[year] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Drop rows that are unique only on route_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from data dictionary\n",
    "possible_route_types = ['I',\n",
    "    'US',\n",
    "    'SC',\n",
    "    'S',\n",
    "    'D',\n",
    "    'R',\n",
    "    'RS'\n",
    "]\n",
    "\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    if 'route_type' in df.columns:\n",
    "        df.loc[~df.route_type.str.replace('-','').isin(possible_route_types), 'route_type'] = np.nan\n",
    "        df['route_type'] = df.groupby(['station_id', 'route_identifier', 'route_number']).route_type.ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year, df in shp_dfs_renamed.items():\n",
    "    df = df.drop_duplicates()\n",
    "    shp_dfs_renamed[year] = df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       32020000100N      1.0             2\n",
      "321.0       21070013200E      132.0           2\n",
      "dtype: int64\n",
      "2013 \n",
      " station_id  route_identifier  route_number\n",
      "426.0       04090713500N      7135.0          2\n",
      "553.0       42070064500N      645.0           2\n",
      "633.0       23090032600E      326.0           2\n",
      "923.0       42070176700N      1767.0          2\n",
      "dtype: int64\n",
      "2010 \n",
      " station_id  route_identifier  route_number\n",
      "169.0       04040002400E      24.0            2\n",
      "170.0       40020007600E      76.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "2601.0      02010052000E      520.0           2\n",
      "dtype: int64\n",
      "2016 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       32020000100N      1.0             2\n",
      "dtype: int64\n",
      "2015 \n",
      " Series([], dtype: int64)\n",
      "2009 \n",
      " station_id  route_identifier  route_number\n",
      "331.0       11070020900N      209.0           2\n",
      "dtype: int64\n",
      "2017 \n",
      " Series([], dtype: int64)\n",
      "2012 \n",
      " station_id  route_identifier  route_number\n",
      "170.0       40020007600E      76.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "384.0       42070006400E      64.0            3\n",
      "dtype: int64\n",
      "2011 \n",
      " station_id  route_identifier  route_number\n",
      "101.0       32020000100N      1.0             2\n",
      "169.0       04040002400E      24.0            2\n",
      "170.0       40020007600E      76.0            2\n",
      "193.0       41070002500N      25.0            2\n",
      "329.0       22070039100N      391.0           2\n",
      "331.0       11070020900N      209.0           2\n",
      "333.0       22070039100N      878.0           2\n",
      "553.0       42070064500N      645.0           2\n",
      "795.0       40070202700N      2027.0          2\n",
      "913.0       42070098900N      989.0           2\n",
      "2601.0      02010052000E      520.0           2\n",
      "dtype: int64\n",
      "2014 \n",
      " station_id  route_identifier  route_number\n",
      "331.0       11070020900N      209.0           2\n",
      "433.0       23070000500N      5.0             2\n",
      "451.0       10070001300N      13.0            2\n",
      "469.0       43090036400E      364.0           2\n",
      "749.0       39070010000E      100.0           2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# records should be unique across station_id, route_identifier, and route_number - do some verification\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).size()\n",
    "    # print rows where the size of the group is > 1 (duplicates)\n",
    "    print(year,'\\n', temp_df.loc[temp_df > 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would appear that we have some duplicates, or we think we have duplicates. We'll define a quick function to spot check some records and get a sense of why rows are duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>milepoint</th>\n",
       "      <th>routelrs</th>\n",
       "      <th>maptype</th>\n",
       "      <th>id1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>countyname</th>\n",
       "      <th>routetype</th>\n",
       "      <th>rtenum</th>\n",
       "      <th>aux</th>\n",
       "      <th>atrnum</th>\n",
       "      <th>map</th>\n",
       "      <th>termini</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>id2</th>\n",
       "      <th>gmrotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2054</td>\n",
       "      <td>451.0</td>\n",
       "      <td>3.229</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>CHARLESTON</td>\n",
       "      <td>5653</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>S-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>19500</td>\n",
       "      <td>2055</td>\n",
       "      <td>8.170881e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2055</td>\n",
       "      <td>451.0</td>\n",
       "      <td>3.229</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>CHARLESTON</td>\n",
       "      <td>5653</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>L-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>18200</td>\n",
       "      <td>2056</td>\n",
       "      <td>8.170881e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station  milepoint      routelrs     maptype   id1      latitude  \\\n",
       "2054    451.0      3.229  10070001300N  CHARLESTON  5653  32:53:53.404   \n",
       "2055    451.0      3.229  10070001300N  CHARLESTON  5653  32:53:53.404   \n",
       "\n",
       "         longitude  countyname routetype  rtenum  aux  atrnum map  \\\n",
       "2054  -80:1:10.830  Charleston        S-    13.0  NaN     NaN   Y   \n",
       "2055  -80:1:10.830  Charleston        L-    13.0  NaN     NaN   Y   \n",
       "\n",
       "                           termini    year  count   id2    gmrotation  \n",
       "2054  US 52 TO AIR FORCE BASE ROAD  2014.0  19500  2055  8.170881e-07  \n",
       "2055  US 52 TO AIR FORCE BASE ROAD  2014.0  18200  2056  8.170881e-07  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can spot check some of these to see what's up with the records\n",
    "def check_records(year, station_id, route_identifier):\n",
    "    mask = (shp_dfs_renamed[year]['station_id'] == station_id) & (shp_dfs_renamed[year]['route_identifier'] == route_identifier)\n",
    "    return shp_dfs_renamed[year].loc[mask]\n",
    "\n",
    "check_records('2014', 451.0, '10070001300N')\n",
    "\n",
    "shp_dfs['2014'].loc[(shp_dfs['2014'].station == 451.0) & (shp_dfs['2014'].routelrs == '10070001300N')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>county_name</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2054</td>\n",
       "      <td>451.0</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>S-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>19500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2055</td>\n",
       "      <td>451.0</td>\n",
       "      <td>10070001300N</td>\n",
       "      <td>32:53:53.404</td>\n",
       "      <td>-80:1:10.830</td>\n",
       "      <td>Charleston</td>\n",
       "      <td>S-</td>\n",
       "      <td>13.0</td>\n",
       "      <td>US 52 TO AIR FORCE BASE ROAD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>18200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id route_identifier      latitude     longitude county_name  \\\n",
       "2054       451.0     10070001300N  32:53:53.404  -80:1:10.830  Charleston   \n",
       "2055       451.0     10070001300N  32:53:53.404  -80:1:10.830  Charleston   \n",
       "\n",
       "     route_type  route_number             route_leg_descrip    year  \\\n",
       "2054         S-          13.0  US 52 TO AIR FORCE BASE ROAD  2014.0   \n",
       "2055         S-          13.0  US 52 TO AIR FORCE BASE ROAD  2014.0   \n",
       "\n",
       "      average_daily_traffic  \n",
       "2054                  19500  \n",
       "2055                  18200  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_records('2014', 451.0, '10070001300N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>milepoint</th>\n",
       "      <th>routelrs</th>\n",
       "      <th>maptype</th>\n",
       "      <th>id1</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>countyname</th>\n",
       "      <th>routetype</th>\n",
       "      <th>rtenum</th>\n",
       "      <th>aux</th>\n",
       "      <th>atrnum</th>\n",
       "      <th>map</th>\n",
       "      <th>termini</th>\n",
       "      <th>year</th>\n",
       "      <th>count</th>\n",
       "      <th>id2</th>\n",
       "      <th>gmrotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.098</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>11046</td>\n",
       "      <td>34:22:45.314</td>\n",
       "      <td>-82:26:57.323</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>SC</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>County Line - ANDERSON TO SC 20</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1150</td>\n",
       "      <td>1</td>\n",
       "      <td>8.337633e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.196</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>9354</td>\n",
       "      <td>34:25:11.248</td>\n",
       "      <td>-82:23:6.771</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>County Line - ANDERSON TO S- 166</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>4700</td>\n",
       "      <td>2</td>\n",
       "      <td>1.765016e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>4.345</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>3379</td>\n",
       "      <td>34:23:0.398</td>\n",
       "      <td>-82:21:11.692</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>S- 166 TO SC 184</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5100</td>\n",
       "      <td>3</td>\n",
       "      <td>1.081977e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>105.0</td>\n",
       "      <td>5.633</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>9353</td>\n",
       "      <td>34:22:15.563</td>\n",
       "      <td>-82:20:15.542</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>US</td>\n",
       "      <td>178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>SC 184 TO County Line - GREENWOOD</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>3700</td>\n",
       "      <td>4</td>\n",
       "      <td>4.884340e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.146</td>\n",
       "      <td>01090002000E</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>8994</td>\n",
       "      <td>34:10:30.277</td>\n",
       "      <td>-82:22:34.976</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>L-</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>SC 72 TO SC 20, SC 203</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5700</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11422</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>82.915</td>\n",
       "      <td>46010007700N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>7355</td>\n",
       "      <td>34:59:40.444</td>\n",
       "      <td>-80:58:42.512</td>\n",
       "      <td>York</td>\n",
       "      <td>I-</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>SC 161 TO S- 49</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>106100</td>\n",
       "      <td>11423</td>\n",
       "      <td>3.600000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11423</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>84.325</td>\n",
       "      <td>46010007700N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>7068</td>\n",
       "      <td>35:0:45.353</td>\n",
       "      <td>-80:58:11.893</td>\n",
       "      <td>York</td>\n",
       "      <td>I-</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>S- 49 TO SC 160</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>103400</td>\n",
       "      <td>11424</td>\n",
       "      <td>3.600000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11424</td>\n",
       "      <td>2255.0</td>\n",
       "      <td>86.281</td>\n",
       "      <td>46010007700N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>9981</td>\n",
       "      <td>35:2:24.978</td>\n",
       "      <td>-80:57:35.736</td>\n",
       "      <td>York</td>\n",
       "      <td>I-</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>SC 160 TO SC 460</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>103400</td>\n",
       "      <td>11425</td>\n",
       "      <td>1.634176e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11425</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>88.764</td>\n",
       "      <td>46010007700N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>8351</td>\n",
       "      <td>35:4:24.749</td>\n",
       "      <td>-80:56:49.120</td>\n",
       "      <td>York</td>\n",
       "      <td>I-</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>SC 460 TO S- 1441</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>110800</td>\n",
       "      <td>11426</td>\n",
       "      <td>1.600826e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11426</td>\n",
       "      <td>2259.0</td>\n",
       "      <td>91.040</td>\n",
       "      <td>46010007700N</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>6745</td>\n",
       "      <td>35:6:11.051</td>\n",
       "      <td>-80:55:51.948</td>\n",
       "      <td>York</td>\n",
       "      <td>I-</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>S- 1441 TO State Line - NORTH CAROLINA</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>140400</td>\n",
       "      <td>11427</td>\n",
       "      <td>3.600000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11427 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       station  milepoint      routelrs    maptype    id1      latitude  \\\n",
       "0        100.0      1.098  01040018500N     COUNTY  11046  34:22:45.314   \n",
       "1        101.0      1.196  01020017800E     COUNTY   9354  34:25:11.248   \n",
       "2        103.0      4.345  01020017800E     COUNTY   3379   34:23:0.398   \n",
       "3        105.0      5.633  01020017800E     COUNTY   9353  34:22:15.563   \n",
       "4        107.0      0.146  01090002000E  ABBEVILLE   8994  34:10:30.277   \n",
       "...        ...        ...           ...        ...    ...           ...   \n",
       "11422   2251.0     82.915  46010007700N     COUNTY   7355  34:59:40.444   \n",
       "11423   2253.0     84.325  46010007700N     COUNTY   7068   35:0:45.353   \n",
       "11424   2255.0     86.281  46010007700N     COUNTY   9981   35:2:24.978   \n",
       "11425   2257.0     88.764  46010007700N     COUNTY   8351   35:4:24.749   \n",
       "11426   2259.0     91.040  46010007700N     COUNTY   6745   35:6:11.051   \n",
       "\n",
       "           longitude countyname routetype  rtenum  aux  atrnum map  \\\n",
       "0      -82:26:57.323  Abbeville        SC   185.0  NaN     NaN   Y   \n",
       "1       -82:23:6.771  Abbeville        US   178.0  NaN     NaN   Y   \n",
       "2      -82:21:11.692  Abbeville        US   178.0  NaN     NaN   Y   \n",
       "3      -82:20:15.542  Abbeville        US   178.0  NaN     NaN   Y   \n",
       "4      -82:22:34.976  Abbeville        L-    20.0  NaN     NaN   Y   \n",
       "...              ...        ...       ...     ...  ...     ...  ..   \n",
       "11422  -80:58:42.512       York        I-    77.0  NaN     NaN   Y   \n",
       "11423  -80:58:11.893       York        I-    77.0  NaN     NaN   Y   \n",
       "11424  -80:57:35.736       York        I-    77.0  NaN     NaN   Y   \n",
       "11425  -80:56:49.120       York        I-    77.0  NaN    25.0   Y   \n",
       "11426  -80:55:51.948       York        I-    77.0  NaN     NaN   Y   \n",
       "\n",
       "                                      termini    year   count    id2  \\\n",
       "0             County Line - ANDERSON TO SC 20  2014.0    1150      1   \n",
       "1            County Line - ANDERSON TO S- 166  2014.0    4700      2   \n",
       "2                            S- 166 TO SC 184  2014.0    5100      3   \n",
       "3           SC 184 TO County Line - GREENWOOD  2014.0    3700      4   \n",
       "4                      SC 72 TO SC 20, SC 203  2014.0    5700      5   \n",
       "...                                       ...     ...     ...    ...   \n",
       "11422                         SC 161 TO S- 49  2014.0  106100  11423   \n",
       "11423                         S- 49 TO SC 160  2014.0  103400  11424   \n",
       "11424                        SC 160 TO SC 460  2014.0  103400  11425   \n",
       "11425                       SC 460 TO S- 1441  2014.0  110800  11426   \n",
       "11426  S- 1441 TO State Line - NORTH CAROLINA  2014.0  140400  11427   \n",
       "\n",
       "         gmrotation  \n",
       "0      8.337633e-07  \n",
       "1      1.765016e-05  \n",
       "2      1.081977e-05  \n",
       "3      4.884340e-06  \n",
       "4      0.000000e+00  \n",
       "...             ...  \n",
       "11422  3.600000e+02  \n",
       "11423  3.600000e+02  \n",
       "11424  1.634176e-06  \n",
       "11425  1.600826e-06  \n",
       "11426  3.600000e+02  \n",
       "\n",
       "[11427 rows x 18 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp_dfs['2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10123</td>\n",
       "      <td>956.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>DEAD END TO S- 63</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>S-</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>42070102400E</td>\n",
       "      <td>34:53:05.5364</td>\n",
       "      <td>-82:11:04.7505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_id  average_daily_traffic  route_leg_descrip    year  \\\n",
       "10123       956.0                  200.0  DEAD END TO S- 63  2011.0   \n",
       "\n",
       "      route_type  route_number route_identifier       latitude       longitude  \n",
       "10123         S-        1024.0     42070102400E  34:53:05.5364  -82:11:04.7505  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_records('2011', 956.0, '42070102400E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing a few sets of records leads me to believe that we are in fact dealing with duplicate rows. Most are only unique based on the row number. We'll drop our duplicates to make sure they don't sully the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyeballing the records reveals that they are duplicated rows. we'll take the first from every group\n",
    "# head(1) will return the first row per group\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).head(1)\n",
    "    shp_dfs_renamed[year] = temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 \n",
      " Series([], dtype: int64)\n",
      "2013 \n",
      " Series([], dtype: int64)\n",
      "2010 \n",
      " Series([], dtype: int64)\n",
      "2016 \n",
      " Series([], dtype: int64)\n",
      "2015 \n",
      " Series([], dtype: int64)\n",
      "2009 \n",
      " Series([], dtype: int64)\n",
      "2017 \n",
      " Series([], dtype: int64)\n",
      "2012 \n",
      " Series([], dtype: int64)\n",
      "2011 \n",
      " Series([], dtype: int64)\n",
      "2014 \n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "#check for dupes again\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.groupby(['station_id', 'route_identifier', 'route_number']).size()\n",
    "    print(year,'\\n', temp_df.loc[temp_df > 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>year</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_number</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>row_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1675</td>\n",
       "      <td>2520.0</td>\n",
       "      <td>53400.0</td>\n",
       "      <td>SEVEN FARMS RD TO S- 97 (CHARLESTON)</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>I-</td>\n",
       "      <td>526.0</td>\n",
       "      <td>08010052600E</td>\n",
       "      <td>32:51:39.5474</td>\n",
       "      <td>-79:53:52.4178</td>\n",
       "      <td>1676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      station_id  average_daily_traffic                     route_leg_descrip  \\\n",
       "1675      2520.0                53400.0  SEVEN FARMS RD TO S- 97 (CHARLESTON)   \n",
       "\n",
       "        year route_type  route_number route_identifier       latitude  \\\n",
       "1675  2011.0         I-         526.0     08010052600E  32:51:39.5474   \n",
       "\n",
       "           longitude  row_number  \n",
       "1675  -79:53:52.4178        1676  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify we took the first row in the duplicated group, and that we only have one row returning.\n",
    "check_records('2011', 2520.0, '08010052600E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we've realized that the data can very quite widely from year to year. In order to clean the data up a little bit more, we will try to standardize the data across years. To accomplish this we'll use pandas' update method - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.update.html - and overwrite the values in every year with our standardized values. Because the 2017 and 2018 dataframes don't have all the columns that we're interested in looking at, we'll use the 2016 dataframe to update/overwrite values in a specific subset of columns across all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set index of all dfs to the unique identifiers\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    temp_df = df.set_index(['station_id', 'route_identifier', 'route_number'])\n",
    "    shp_dfs_renamed[year] = temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing year value in any dfs\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df['year'] = df.year.fillna(year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county_name                0\n",
       "route_type                 0\n",
       "route_leg_descrip          0\n",
       "average_daily_traffic      0\n",
       "year                       0\n",
       "row_number                 0\n",
       "latitude                 179\n",
       "longitude                179\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2018 and 2017 dfs don't have all the columns, so use the 2016 df to standardize fields\n",
    "# check how many nas in each columns in the 2016 df\n",
    "shp_dfs_renamed['2016'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have some NaNs for lat/long in the 2016 df, so we'll try and reduce those as much as we can.\n",
    "# update 2016 latitudes/longitudes with 2018 latitudes/longitudes where stationid, route_id, and route_number match (index of each df)\n",
    "\n",
    "shp_dfs_renamed['2016'].update(shp_dfs_renamed['2018'][['latitude', 'longitude']])\n",
    "\n",
    "# still some nulls - try the 2015 df\n",
    "shp_dfs_renamed['2016'].update(shp_dfs_renamed['2015'][['latitude', 'longitude']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "county_name                0\n",
       "route_type                 0\n",
       "route_leg_descrip          0\n",
       "average_daily_traffic      0\n",
       "year                       0\n",
       "row_number                 0\n",
       "latitude                 153\n",
       "longitude                153\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check nas again\n",
    "shp_dfs_renamed['2016'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2018 and 2017 dfs don't have all the columns, so use the 2016 df to standardize fields\n",
    "# we're standardizing data across the five following columns - DON'T want to overwrite AADT.\n",
    "cols_to_update = ['route_type', 'route_leg_descrip', 'latitude', 'longitude', 'county_name']\n",
    "update_df = shp_dfs_renamed['2016'][cols_to_update]\n",
    "\n",
    "for year, df in shp_dfs_renamed.items():\n",
    "    df.update(update_df, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we should be ready to combine all the dataframes together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all the data frames together\n",
    "traffic_df = pd.concat(shp_dfs_renamed.values(), sort=True, axis=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_id</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>route_type_id</th>\n",
       "      <th>row_number</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.41979</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.38344</td>\n",
       "      <td>-82.35325</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.37099</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>SC 184 (N MAIN ST) TO County Line - GREENWOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.17888</td>\n",
       "      <td>-82.38016</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.18359</td>\n",
       "      <td>-82.38115</td>\n",
       "      <td>SC 71 TO L- 170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "0       101.0     01020017800E         178.0                 4300.0   \n",
       "1       103.0     01020017800E         178.0                 4600.0   \n",
       "2       105.0     01020017800E         178.0                 3600.0   \n",
       "3       109.0     01040002000E          20.0                 4900.0   \n",
       "4       111.0     01040002000E          20.0                 2200.0   \n",
       "\n",
       "   county_id county_name  latitude  longitude  \\\n",
       "0        NaN   ABBEVILLE  34.41979  -82.38521   \n",
       "1        NaN   ABBEVILLE  34.38344  -82.35325   \n",
       "2        NaN   ABBEVILLE  34.37099  -82.33765   \n",
       "3        NaN   ABBEVILLE  34.17888  -82.38016   \n",
       "4        NaN   ABBEVILLE  34.18359  -82.38115   \n",
       "\n",
       "                                route_leg_descrip route_type  route_type_id  \\\n",
       "0     County Line - ANDERSON TO S- 166 (DRAKE RD)        NaN            2.0   \n",
       "1         S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)        NaN            2.0   \n",
       "2   SC 184 (N MAIN ST) TO County Line - GREENWOOD        NaN            2.0   \n",
       "3  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71        NaN            4.0   \n",
       "4                                 SC 71 TO L- 170        NaN            4.0   \n",
       "\n",
       "   row_number  year  \n",
       "0           1  2018  \n",
       "1           2  2018  \n",
       "2           3  2018  \n",
       "3           4  2018  \n",
       "4           5  2018  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eyeball the data \n",
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns I actually don't want\n",
    "traffic_df = traffic_df.drop(['county_id', 'route_type_id', 'row_number'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4300.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.41979</td>\n",
       "      <td>-82.38521</td>\n",
       "      <td>County Line - ANDERSON TO S- 166 (DRAKE RD)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>103.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>4600.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.38344</td>\n",
       "      <td>-82.35325</td>\n",
       "      <td>S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>01020017800E</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.37099</td>\n",
       "      <td>-82.33765</td>\n",
       "      <td>SC 184 (N MAIN ST) TO County Line - GREENWOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>109.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.17888</td>\n",
       "      <td>-82.38016</td>\n",
       "      <td>SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>111.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34.18359</td>\n",
       "      <td>-82.38115</td>\n",
       "      <td>SC 71 TO L- 170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "0       101.0     01020017800E         178.0                 4300.0   \n",
       "1       103.0     01020017800E         178.0                 4600.0   \n",
       "2       105.0     01020017800E         178.0                 3600.0   \n",
       "3       109.0     01040002000E          20.0                 4900.0   \n",
       "4       111.0     01040002000E          20.0                 2200.0   \n",
       "\n",
       "  county_name  latitude  longitude  \\\n",
       "0   ABBEVILLE  34.41979  -82.38521   \n",
       "1   ABBEVILLE  34.38344  -82.35325   \n",
       "2   ABBEVILLE  34.37099  -82.33765   \n",
       "3   ABBEVILLE  34.17888  -82.38016   \n",
       "4   ABBEVILLE  34.18359  -82.38115   \n",
       "\n",
       "                                route_leg_descrip route_type  year  \n",
       "0     County Line - ANDERSON TO S- 166 (DRAKE RD)        NaN  2018  \n",
       "1         S- 166 (DRAKE RD) TO SC 184 (N MAIN ST)        NaN  2018  \n",
       "2   SC 184 (N MAIN ST) TO County Line - GREENWOOD        NaN  2018  \n",
       "3  SC 203 (WASHINGTON ST), L- 20, L- 980 TO SC 71        NaN  2018  \n",
       "4                                 SC 71 TO L- 170        NaN  2018  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eyeballing the head indicates that there are STILL NaNs in the data - the index of our update df (stationid, routeid, routenumber) did not overlap every possible combination in the data across the years. We can handle these NaNs with a similar operation - grouping the data by our unique identifers and then filling within groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now fill in cols that are still na by unique id - NOT the average traffic column (main data we care about)\n",
    "# fill nas by group\n",
    "cols_to_fill = ['county_name', 'latitude', 'longitude', 'route_leg_descrip', 'route_type']\n",
    "for col in cols_to_fill:\n",
    "    traffic_df[col] = traffic_df.groupby(['station_id', 'route_identifier', 'route_number'])[col].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station_id                0\n",
       "route_identifier          0\n",
       "route_number              0\n",
       "average_daily_traffic    69\n",
       "county_name               0\n",
       "latitude                  0\n",
       "longitude                 0\n",
       "route_leg_descrip         0\n",
       "route_type                0\n",
       "year                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for any nas remaining\n",
    "traffic_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop remaining nas - no data!\n",
    "traffic_df = traffic_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some plotting on pct changes etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can't plot all lats and longs because the lats/longs are strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 0\n",
      "2010 404\n",
      "2016 0\n",
      "2015 0\n",
      "2009 442\n",
      "2012 359\n",
      "2011 371\n",
      "2014 163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year, df in shp_dfs_renamed.items():\n",
    "    try:\n",
    "        print(year, df.latitude.str.contains(':').sum())\n",
    "    except:\n",
    "        pass\n",
    "update_df.latitude.str.contains(':').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>22931</td>\n",
       "      <td>107.0</td>\n",
       "      <td>01040002000E</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:10:30.277</td>\n",
       "      <td>-82:22:34.9755</td>\n",
       "      <td>S.C. 72 TO Pickens Street</td>\n",
       "      <td>SC</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22962</td>\n",
       "      <td>170.0</td>\n",
       "      <td>01040007200E</td>\n",
       "      <td>579.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:05:28.4781</td>\n",
       "      <td>-82:35:57.0661</td>\n",
       "      <td>SC-72 to SC-72</td>\n",
       "      <td>S-</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22964</td>\n",
       "      <td>173.0</td>\n",
       "      <td>01070024000E</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3400.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:07:42.3243</td>\n",
       "      <td>-82:26:00.7028</td>\n",
       "      <td>S-185 TO S.C. 28</td>\n",
       "      <td>SC</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23019</td>\n",
       "      <td>262.0</td>\n",
       "      <td>01070007300N</td>\n",
       "      <td>73.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:27:19.8048</td>\n",
       "      <td>-82:21:05.8571</td>\n",
       "      <td>Anderson County Line to SC-252</td>\n",
       "      <td>S-</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23046</td>\n",
       "      <td>315.0</td>\n",
       "      <td>01070014700N</td>\n",
       "      <td>147.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>ABBEVILLE</td>\n",
       "      <td>34:22:54.3097</td>\n",
       "      <td>-82:25:16.6313</td>\n",
       "      <td>S-89 TO S-321</td>\n",
       "      <td>S-</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112437</td>\n",
       "      <td>469.0</td>\n",
       "      <td>43090036400E</td>\n",
       "      <td>364.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>Sumter</td>\n",
       "      <td>33:59:10.318</td>\n",
       "      <td>-80:28:20.795</td>\n",
       "      <td>S- 537, L- 215 TO SC 441</td>\n",
       "      <td>S-</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112462</td>\n",
       "      <td>515.0</td>\n",
       "      <td>43070103400E</td>\n",
       "      <td>1428.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>Sumter</td>\n",
       "      <td>33:57:29.149</td>\n",
       "      <td>-80:22:42.384</td>\n",
       "      <td>US 521 TO S- 269</td>\n",
       "      <td>S-</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112599</td>\n",
       "      <td>743.0</td>\n",
       "      <td>43070014500N</td>\n",
       "      <td>586.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>Sumter</td>\n",
       "      <td>33:55:59.163</td>\n",
       "      <td>-80:20:2.554</td>\n",
       "      <td>S- 234 TO S- 123, L- 585</td>\n",
       "      <td>S-</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112649</td>\n",
       "      <td>158.0</td>\n",
       "      <td>44040005600W</td>\n",
       "      <td>56.0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>Union</td>\n",
       "      <td>34:36:0.780</td>\n",
       "      <td>-81:50:58.284</td>\n",
       "      <td>County Line - LAURENS TO County Line - SPARTAN...</td>\n",
       "      <td>SC</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113022</td>\n",
       "      <td>263.0</td>\n",
       "      <td>46040016100N</td>\n",
       "      <td>161.0</td>\n",
       "      <td>27100.0</td>\n",
       "      <td>York</td>\n",
       "      <td>34:58:52.552</td>\n",
       "      <td>-81:5:16.716</td>\n",
       "      <td>SC 274, S- 81 TO S- 1115</td>\n",
       "      <td>SC</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1749 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "22931        107.0     01040002000E          20.0                 5800.0   \n",
       "22962        170.0     01040007200E         579.0                 1750.0   \n",
       "22964        173.0     01070024000E          72.0                 3400.0   \n",
       "23019        262.0     01070007300N          73.0                  400.0   \n",
       "23046        315.0     01070014700N         147.0                  100.0   \n",
       "...            ...              ...           ...                    ...   \n",
       "112437       469.0     43090036400E         364.0                 5500.0   \n",
       "112462       515.0     43070103400E        1428.0                 4000.0   \n",
       "112599       743.0     43070014500N         586.0                 1450.0   \n",
       "112649       158.0     44040005600W          56.0                  800.0   \n",
       "113022       263.0     46040016100N         161.0                27100.0   \n",
       "\n",
       "       county_name       latitude       longitude  \\\n",
       "22931    ABBEVILLE   34:10:30.277  -82:22:34.9755   \n",
       "22962    ABBEVILLE  34:05:28.4781  -82:35:57.0661   \n",
       "22964    ABBEVILLE  34:07:42.3243  -82:26:00.7028   \n",
       "23019    ABBEVILLE  34:27:19.8048  -82:21:05.8571   \n",
       "23046    ABBEVILLE  34:22:54.3097  -82:25:16.6313   \n",
       "...            ...            ...             ...   \n",
       "112437      Sumter   33:59:10.318   -80:28:20.795   \n",
       "112462      Sumter   33:57:29.149   -80:22:42.384   \n",
       "112599      Sumter   33:55:59.163    -80:20:2.554   \n",
       "112649       Union    34:36:0.780   -81:50:58.284   \n",
       "113022        York   34:58:52.552    -81:5:16.716   \n",
       "\n",
       "                                        route_leg_descrip route_type  year  \n",
       "22931                           S.C. 72 TO Pickens Street         SC  2010  \n",
       "22962                                      SC-72 to SC-72         S-  2010  \n",
       "22964                                    S-185 TO S.C. 28         SC  2010  \n",
       "23019                      Anderson County Line to SC-252         S-  2010  \n",
       "23046                                       S-89 TO S-321         S-  2010  \n",
       "...                                                   ...        ...   ...  \n",
       "112437                           S- 537, L- 215 TO SC 441         S-  2014  \n",
       "112462                                   US 521 TO S- 269         S-  2014  \n",
       "112599                           S- 234 TO S- 123, L- 585         S-  2014  \n",
       "112649  County Line - LAURENS TO County Line - SPARTAN...         SC  2014  \n",
       "113022                           SC 274, S- 81 TO S- 1115         SC  2014  \n",
       "\n",
       "[1749 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.loc[traffic_df.latitude.str.contains(':')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.037171388888886"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_lat_long(string):\n",
    "    split = string.split(':')\n",
    "   \n",
    "    converted = float(split[0]) + float(split[1])/60 + float(split[2])/(60*60)\n",
    "    \n",
    "    return converted\n",
    "\n",
    "test = '33:2:13.817'\n",
    "\n",
    "convert_lat_long(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.loc[traffic_df.latitude.str.contains(':'), 'latitude'] = traffic_df.loc[traffic_df.latitude.str.contains(':'), 'latitude'].apply(convert_lat_long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df.loc[traffic_df.longitude.str.contains(':'), 'longitude'] = traffic_df.loc[traffic_df.longitude.str.contains(':'), 'longitude'].apply(convert_lat_long) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df['latitude'] = traffic_df.latitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df['longitude'] = traffic_df.longitude.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the pct change year over year for average daily traffic\n",
    "traffic_df['traffic_yearly_pct_change'] = traffic_df \\\n",
    "    .sort_values(['station_id', 'route_identifier', 'route_number', 'year']) \\\n",
    "    .groupby(['station_id', 'route_identifier', 'route_number']) \\\n",
    "    .average_daily_traffic \\\n",
    "    .pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_df = traffic_df.sort_values(['station_id', 'route_identifier', 'route_number', 'year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>average_daily_traffic</th>\n",
       "      <th>county_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>route_leg_descrip</th>\n",
       "      <th>route_type</th>\n",
       "      <th>year</th>\n",
       "      <th>traffic_yearly_pct_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46302</td>\n",
       "      <td>100.0</td>\n",
       "      <td>04020002900N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>34.35590</td>\n",
       "      <td>-82.81412</td>\n",
       "      <td>State Line - GEORGIA TO SC 187 (HIGHWAY 187  S)</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.290323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69660</td>\n",
       "      <td>100.0</td>\n",
       "      <td>08020001702N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>53100.0</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>33.03701</td>\n",
       "      <td>-80.15366</td>\n",
       "      <td>County Line - DORCHESTER TO I- 26</td>\n",
       "      <td>US</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.288835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107867</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28040001200E</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>KERSHAW</td>\n",
       "      <td>34.11999</td>\n",
       "      <td>-80.77968</td>\n",
       "      <td>County Line - RICHLAND TO S- 47 (FORT JACKSON RD)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46303</td>\n",
       "      <td>101.0</td>\n",
       "      <td>04020002900N</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2100.0</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>34.40918</td>\n",
       "      <td>-82.79075</td>\n",
       "      <td>SC 187 (HIGHWAY 187  S) TO US 29 BUS (HIGHWAY ...</td>\n",
       "      <td>US</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35410</td>\n",
       "      <td>101.0</td>\n",
       "      <td>07020001700N</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12400.0</td>\n",
       "      <td>BEAUFORT</td>\n",
       "      <td>32.64004</td>\n",
       "      <td>-80.85637</td>\n",
       "      <td>County Line - JASPER TO US 17 ALT (CASTLE HALL...</td>\n",
       "      <td>US</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.441860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50675</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>23010018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>34.77331</td>\n",
       "      <td>-82.44549</td>\n",
       "      <td>SC 153 (153 HWY) TO I- 85</td>\n",
       "      <td>I-</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95757</td>\n",
       "      <td>2439.0</td>\n",
       "      <td>23010018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>16700.0</td>\n",
       "      <td>GREENVILLE</td>\n",
       "      <td>34.80352</td>\n",
       "      <td>-82.42446</td>\n",
       "      <td>US 25 (WHITE HORSE RD) TO  , SC 20</td>\n",
       "      <td>I-</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.590476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9271</td>\n",
       "      <td>2489.0</td>\n",
       "      <td>42010058500S</td>\n",
       "      <td>585.0</td>\n",
       "      <td>32200.0</td>\n",
       "      <td>SPARTANBURG</td>\n",
       "      <td>34.97494</td>\n",
       "      <td>-81.94188</td>\n",
       "      <td>US 176 CO2 (N CHURCH ST), SC 9 TO US 221 (WHIT...</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.201493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9272</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>42010058500S</td>\n",
       "      <td>585.0</td>\n",
       "      <td>31200.0</td>\n",
       "      <td>SPARTANBURG</td>\n",
       "      <td>34.97158</td>\n",
       "      <td>-81.93761</td>\n",
       "      <td>US 221 (WHITNEY RD) TO US 176 (N PINE ST)</td>\n",
       "      <td>SC</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.214008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46224</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>10100.0</td>\n",
       "      <td>AIKEN</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>US 25 CON (US 25 CONNECTOR) TO I- 20</td>\n",
       "      <td>I-</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.202381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6200 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id route_identifier  route_number  average_daily_traffic  \\\n",
       "46302        100.0     04020002900N          29.0                 4000.0   \n",
       "69660        100.0     08020001702N          17.0                53100.0   \n",
       "107867       100.0     28040001200E          12.0                 4100.0   \n",
       "46303        101.0     04020002900N          29.0                 2100.0   \n",
       "35410        101.0     07020001700N          17.0                12400.0   \n",
       "...            ...              ...           ...                    ...   \n",
       "50675       2435.0     23010018500N         185.0                 5000.0   \n",
       "95757       2439.0     23010018500N         185.0                16700.0   \n",
       "9271        2489.0     42010058500S         585.0                32200.0   \n",
       "9272        2491.0     42010058500S         585.0                31200.0   \n",
       "46224       2607.0     02010052000E         520.0                10100.0   \n",
       "\n",
       "        county_name  latitude  longitude  \\\n",
       "46302      ANDERSON  34.35590  -82.81412   \n",
       "69660      BERKELEY  33.03701  -80.15366   \n",
       "107867      KERSHAW  34.11999  -80.77968   \n",
       "46303      ANDERSON  34.40918  -82.79075   \n",
       "35410      BEAUFORT  32.64004  -80.85637   \n",
       "...             ...       ...        ...   \n",
       "50675    GREENVILLE  34.77331  -82.44549   \n",
       "95757    GREENVILLE  34.80352  -82.42446   \n",
       "9271    SPARTANBURG  34.97494  -81.94188   \n",
       "9272    SPARTANBURG  34.97158  -81.93761   \n",
       "46224         AIKEN  33.56019  -81.92848   \n",
       "\n",
       "                                        route_leg_descrip route_type  year  \\\n",
       "46302     State Line - GEORGIA TO SC 187 (HIGHWAY 187  S)         US  2015   \n",
       "69660                   County Line - DORCHESTER TO I- 26         US  2017   \n",
       "107867  County Line - RICHLAND TO S- 47 (FORT JACKSON RD)         SC  2014   \n",
       "46303   SC 187 (HIGHWAY 187  S) TO US 29 BUS (HIGHWAY ...         US  2015   \n",
       "35410   County Line - JASPER TO US 17 ALT (CASTLE HALL...         US  2016   \n",
       "...                                                   ...        ...   ...   \n",
       "50675                           SC 153 (153 HWY) TO I- 85         I-  2015   \n",
       "95757                  US 25 (WHITE HORSE RD) TO  , SC 20         I-  2011   \n",
       "9271    US 176 CO2 (N CHURCH ST), SC 9 TO US 221 (WHIT...         SC  2018   \n",
       "9272            US 221 (WHITNEY RD) TO US 176 (N PINE ST)         SC  2018   \n",
       "46224                US 25 CON (US 25 CONNECTOR) TO I- 20         I-  2015   \n",
       "\n",
       "        traffic_yearly_pct_change  \n",
       "46302                    0.290323  \n",
       "69660                    0.288835  \n",
       "107867                   0.413793  \n",
       "46303                    0.312500  \n",
       "35410                    0.441860  \n",
       "...                           ...  \n",
       "50675                    0.250000  \n",
       "95757                    0.590476  \n",
       "9271                     0.201493  \n",
       "9272                     0.214008  \n",
       "46224                    0.202381  \n",
       "\n",
       "[6200 rows x 11 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df[traffic_df['traffic_yearly_pct_change'] > 0.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zillow Sales data by Zip Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# navigate up\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>StateName</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>2008-03</th>\n",
       "      <th>2008-04</th>\n",
       "      <th>2008-05</th>\n",
       "      <th>2008-06</th>\n",
       "      <th>2008-07</th>\n",
       "      <th>2008-08</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "      <th>seasAdj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>61639</td>\n",
       "      <td>10025</td>\n",
       "      <td>New York</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>84654</td>\n",
       "      <td>60657</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>91.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>61637</td>\n",
       "      <td>10023</td>\n",
       "      <td>New York</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>91982</td>\n",
       "      <td>77494</td>\n",
       "      <td>Texas</td>\n",
       "      <td>4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>86.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>84616</td>\n",
       "      <td>60614</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  RegionName StateName  SizeRank  2008-03  2008-04  2008-05  \\\n",
       "0     61639       10025  New York         1      NaN      NaN      NaN   \n",
       "1     84654       60657  Illinois         2      NaN      NaN      NaN   \n",
       "2     61637       10023  New York         3      NaN      NaN      NaN   \n",
       "3     91982       77494     Texas         4     56.0     71.0     84.0   \n",
       "4     84616       60614  Illinois         5      NaN      NaN      NaN   \n",
       "\n",
       "   2008-06  2008-07  2008-08  ...  2019-01  2019-02  2019-03  2019-04  \\\n",
       "0      NaN      NaN      NaN  ...     76.0     33.0     47.0     56.0   \n",
       "1      NaN      NaN      NaN  ...     91.0     77.0    113.0    157.0   \n",
       "2      NaN      NaN      NaN  ...     80.0     45.0     63.0     45.0   \n",
       "3     95.0    116.0     86.0  ...     86.0    112.0    186.0    218.0   \n",
       "4      NaN      NaN      NaN  ...     75.0     85.0    144.0    163.0   \n",
       "\n",
       "   2019-05  2019-06  2019-07  2019-08  2019-09  seasAdj  \n",
       "0     35.0     70.0     78.0     66.0     63.0        0  \n",
       "1    189.0    165.0    186.0    141.0    152.0        0  \n",
       "2     66.0     85.0     79.0     90.0     95.0        0  \n",
       "3    200.0    204.0    245.0    226.0      NaN        0  \n",
       "4    219.0    209.0    204.0    196.0    173.0        0  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "sales_df = pd.read_csv('Sale_Counts_Zip.csv')\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very wide - sales are recording in columns. Our steps for prepping this data will be to:\n",
    "1) Filter down to only South Carolina Zip Codes\n",
    "\n",
    "2) Drop columns we don't care about\n",
    "\n",
    "3) Convert records from wide to tall format\n",
    "\n",
    "4) Get the sum of sales per zipcode per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only SC\n",
    "sales_df = sales_df.loc[sales_df.StateName == 'South Carolina']\n",
    "\n",
    "# drop columns we don't care about and rename columns\n",
    "sales_df = sales_df.drop(['RegionID', 'StateName', 'seasAdj'], axis=1)\n",
    "sales_df.rename(columns={'RegionName': 'ZipCode'}, inplace=True)\n",
    "sales_df = sales_df.set_index(['ZipCode', 'SizeRank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>2008-03</th>\n",
       "      <th>2008-04</th>\n",
       "      <th>2008-05</th>\n",
       "      <th>2008-06</th>\n",
       "      <th>2008-07</th>\n",
       "      <th>2008-08</th>\n",
       "      <th>2008-09</th>\n",
       "      <th>2008-10</th>\n",
       "      <th>2008-11</th>\n",
       "      <th>...</th>\n",
       "      <th>2018-12</th>\n",
       "      <th>2019-01</th>\n",
       "      <th>2019-02</th>\n",
       "      <th>2019-03</th>\n",
       "      <th>2019-04</th>\n",
       "      <th>2019-05</th>\n",
       "      <th>2019-06</th>\n",
       "      <th>2019-07</th>\n",
       "      <th>2019-08</th>\n",
       "      <th>2019-09</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZipCode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29072</td>\n",
       "      <td>227</td>\n",
       "      <td>63.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29730</td>\n",
       "      <td>287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29464</td>\n",
       "      <td>291</td>\n",
       "      <td>58.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>76.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29681</td>\n",
       "      <td>350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         SizeRank  2008-03  2008-04  2008-05  2008-06  2008-07  2008-08  \\\n",
       "ZipCode                                                                   \n",
       "29732         180      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "29072         227     63.0     89.0     75.0     70.0     76.0     65.0   \n",
       "29730         287      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "29464         291     58.0     78.0     73.0     88.0     81.0     73.0   \n",
       "29681         350      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "         2008-09  2008-10  2008-11  ...  2018-12  2019-01  2019-02  2019-03  \\\n",
       "ZipCode                             ...                                       \n",
       "29732        NaN      NaN      NaN  ...    127.0     75.0     75.0    134.0   \n",
       "29072       68.0     47.0     42.0  ...    165.0     88.0     88.0    126.0   \n",
       "29730        NaN      NaN      NaN  ...    119.0     71.0     60.0     91.0   \n",
       "29464       57.0     69.0     49.0  ...     76.0     63.0     91.0     94.0   \n",
       "29681        NaN      NaN      NaN  ...    100.0     99.0    118.0    150.0   \n",
       "\n",
       "         2019-04  2019-05  2019-06  2019-07  2019-08  2019-09  \n",
       "ZipCode                                                        \n",
       "29732      140.0    125.0    136.0    128.0    138.0    151.0  \n",
       "29072      132.0    192.0    156.0    180.0    169.0    142.0  \n",
       "29730       95.0    116.0    111.0     87.0    100.0    107.0  \n",
       "29464      138.0    116.0    135.0    146.0    141.0      NaN  \n",
       "29681      129.0    165.0    136.0    151.0    150.0    161.0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51258</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51259</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51260</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-07</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51261</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-08</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51262</td>\n",
       "      <td>820</td>\n",
       "      <td>31089</td>\n",
       "      <td>2019-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51263 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZipCode  SizeRank YearMonth  Sales\n",
       "0        29732       180   2014-08  127.0\n",
       "1        29732       180   2014-09  145.0\n",
       "2        29732       180   2014-10  124.0\n",
       "3        29732       180   2014-11  121.0\n",
       "4        29732       180   2014-12  124.0\n",
       "...        ...       ...       ...    ...\n",
       "51258      820     31089   2019-05    0.0\n",
       "51259      820     31089   2019-06    0.0\n",
       "51260      820     31089   2019-07    0.0\n",
       "51261      820     31089   2019-08    0.0\n",
       "51262      820     31089   2019-09    0.0\n",
       "\n",
       "[51263 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack all sales into one column\n",
    "sales_df = sales_df.stack().reset_index()\n",
    "sales_df.columns = ['ZipCode', 'SizeRank', 'YearMonth', 'Sales']\n",
    "sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>YearMonth</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-08</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-09</td>\n",
       "      <td>145.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-10</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-11</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29732</td>\n",
       "      <td>180</td>\n",
       "      <td>2014-12</td>\n",
       "      <td>124.0</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ZipCode  SizeRank YearMonth  Sales  Year\n",
       "0    29732       180   2014-08  127.0  2014\n",
       "1    29732       180   2014-09  145.0  2014\n",
       "2    29732       180   2014-10  124.0  2014\n",
       "3    29732       180   2014-11  121.0  2014\n",
       "4    29732       180   2014-12  124.0  2014"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the year out of the Sales record\n",
    "sales_df['Year'] = sales_df['YearMonth'].str.split('-').str[0]\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZipCode  SizeRank  Year\n",
       "29944    13111     2017    42.0\n",
       "                   2018    28.0\n",
       "                   2019     3.0\n",
       "29945    12932     2008    22.0\n",
       "                   2009    20.0\n",
       "                   2010    20.0\n",
       "                   2011    25.0\n",
       "                   2012    30.0\n",
       "                   2013    23.0\n",
       "                   2014    23.0\n",
       "                   2015    26.0\n",
       "                   2016    14.0\n",
       "                   2017    23.0\n",
       "                   2018    17.0\n",
       "                   2019     3.0\n",
       "Name: Sales, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# yearly sales calculated - sum over ZipCode and year\n",
    "yearly_sales = sales_df.groupby(['ZipCode', 'SizeRank', 'Year']).Sales.sum()\n",
    "yearly_sales.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip to Lat/Long xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "zip_xref = pd.read_csv('sc-zip-code-latitude-and-longitude.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Daylight savings time flag</th>\n",
       "      <th>geopoint</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29607</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29164</td>\n",
       "      <td>Wagener</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29325</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29520</td>\n",
       "      <td>Cheraw</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29615</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>SC</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "      <td>-5</td>\n",
       "      <td>1</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Zip        City State   Latitude  Longitude  Timezone  \\\n",
       "0  29607  Greenville    SC  34.825592  -82.34099        -5   \n",
       "1  29164     Wagener    SC  33.659078  -81.40845        -5   \n",
       "2  29325     Clinton    SC  34.470115  -81.86761        -5   \n",
       "3  29520      Cheraw    SC  34.688620  -79.92315        -5   \n",
       "4  29615  Greenville    SC  34.866801  -82.31739        -5   \n",
       "\n",
       "   Daylight savings time flag   geopoint  Unnamed: 8  \n",
       "0                           1  34.825592   -82.34099  \n",
       "1                           1  33.659078   -81.40845  \n",
       "2                           1  34.470115   -81.86761  \n",
       "3                           1  34.688620   -79.92315  \n",
       "4                           1  34.866801   -82.31739  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_xref.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the zip code to lat/long xref to the yearly sales data\n",
    "merged_sales = yearly_sales.reset_index().merge(zip_xref, how='left', left_on='ZipCode', right_on='Zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop zip codes that have a length less than 5\n",
    "merged_sales = merged_sales.loc[merged_sales.ZipCode.apply(lambda x: len(str(x)) >= 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns i don't care about\n",
    "merged_sales = merged_sales.drop(['Zip','Timezone', 'Daylight savings time flag', 'geopoint', 'Unnamed: 8'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2013</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2014</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2017</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2018</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>29001</td>\n",
       "      <td>17838</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2012</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2013</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2014</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2018</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>29003</td>\n",
       "      <td>11324</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bamberg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.272026</td>\n",
       "      <td>-81.03203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>29006</td>\n",
       "      <td>9409</td>\n",
       "      <td>2008</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Batesburg</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.872503</td>\n",
       "      <td>-81.55245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ZipCode  SizeRank  Year  Sales       City State   Latitude  Longitude\n",
       "12    29001     17838  2008   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "13    29001     17838  2009   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "14    29001     17838  2010   11.0     Alcolu    SC  33.769930  -80.17278\n",
       "15    29001     17838  2011    8.0     Alcolu    SC  33.769930  -80.17278\n",
       "16    29001     17838  2012    9.0     Alcolu    SC  33.769930  -80.17278\n",
       "17    29001     17838  2013   12.0     Alcolu    SC  33.769930  -80.17278\n",
       "18    29001     17838  2014   10.0     Alcolu    SC  33.769930  -80.17278\n",
       "19    29001     17838  2015    3.0     Alcolu    SC  33.769930  -80.17278\n",
       "20    29001     17838  2016   14.0     Alcolu    SC  33.769930  -80.17278\n",
       "21    29001     17838  2017   12.0     Alcolu    SC  33.769930  -80.17278\n",
       "22    29001     17838  2018   19.0     Alcolu    SC  33.769930  -80.17278\n",
       "23    29001     17838  2019    4.0     Alcolu    SC  33.769930  -80.17278\n",
       "24    29003     11324  2008    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "25    29003     11324  2009    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "26    29003     11324  2010    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "27    29003     11324  2011    0.0    Bamberg    SC  33.272026  -81.03203\n",
       "28    29003     11324  2012   19.0    Bamberg    SC  33.272026  -81.03203\n",
       "29    29003     11324  2013   26.0    Bamberg    SC  33.272026  -81.03203\n",
       "30    29003     11324  2014    3.0    Bamberg    SC  33.272026  -81.03203\n",
       "31    29003     11324  2015    1.0    Bamberg    SC  33.272026  -81.03203\n",
       "32    29003     11324  2016    7.0    Bamberg    SC  33.272026  -81.03203\n",
       "33    29003     11324  2017    2.0    Bamberg    SC  33.272026  -81.03203\n",
       "34    29003     11324  2018    9.0    Bamberg    SC  33.272026  -81.03203\n",
       "35    29003     11324  2019    3.0    Bamberg    SC  33.272026  -81.03203\n",
       "36    29006      9409  2008   93.0  Batesburg    SC  33.872503  -81.55245"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_sales.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I'd like to calculate how far each Zip Code is from each station. \n",
    "I searched online for a way to calculate the as-the-crow-flies distance between two lat/long points.\n",
    "The first reference I found referred to the \"haversine\" formula, detailed here - https://www.movable-type.co.uk/scripts/latlong.html. \n",
    "I found a nice numpy implmentation on Stack Overflow here: https://stackoverflow.com/questions/29545704/fast-haversine-approximation-python-pandas from derricw.\n",
    "\n",
    "In order to calculate the distance between each possible combination of points, I will be taking all unique lat/long points from traffic data and crossjoining with all unique lat/long points from zip code data. Then, I will apply the haversine formula to get the linear distance between each pair of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique zip to lat/long\n",
    "zip_xref['Latitude'] = zip_xref.Latitude.astype('float')\n",
    "zip_xref['Longitude'] = zip_xref.Longitude.astype('float')\n",
    "unique_zip = zip_xref.loc[:, ['Zip', 'Latitude', 'Longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>549</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>551</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>552</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>553</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Zip   Latitude  Longitude\n",
       "0    29607  34.825592  -82.34099\n",
       "1    29164  33.659078  -81.40845\n",
       "2    29325  34.470115  -81.86761\n",
       "3    29520  34.688620  -79.92315\n",
       "4    29615  34.866801  -82.31739\n",
       "..     ...        ...        ...\n",
       "549  29592  34.283207  -79.47272\n",
       "550  29646  34.169781  -82.15474\n",
       "551  29142  33.462378  -80.50903\n",
       "552  29449  32.715745  -80.26738\n",
       "553  29564  33.493553  -79.87402\n",
       "\n",
       "[554 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the unique station/routeid/route number lat/long\n",
    "unique_station = traffic_df \\\n",
    "    .loc[:, ['station_id', 'route_identifier', 'route_number', 'latitude', 'longitude']] \\\n",
    "    .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_long</th>\n",
       "      <th>Zip</th>\n",
       "      <th>zip_lat</th>\n",
       "      <th>zip_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061833</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061834</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061835</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061836</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061837</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7061838 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_id route_identifier  route_number  station_lat  station_long  \\\n",
       "0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "...             ...              ...           ...          ...           ...   \n",
       "7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "\n",
       "           Zip    zip_lat  zip_long  \n",
       "0        29607  34.825592 -82.34099  \n",
       "1        29164  33.659078 -81.40845  \n",
       "2        29325  34.470115 -81.86761  \n",
       "3        29520  34.688620 -79.92315  \n",
       "4        29615  34.866801 -82.31739  \n",
       "...        ...        ...       ...  \n",
       "7061833  29592  34.283207 -79.47272  \n",
       "7061834  29646  34.169781 -82.15474  \n",
       "7061835  29142  33.462378 -80.50903  \n",
       "7061836  29449  32.715745 -80.26738  \n",
       "7061837  29564  33.493553 -79.87402  \n",
       "\n",
       "[7061838 rows x 8 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the cartesian product/crossjoin by merging on a uniform key\n",
    "unique_zip['key'] = 0\n",
    "unique_station['key'] = 0\n",
    "\n",
    "station_zip_xref = unique_station.merge(unique_zip, on='key').drop('key', axis=1)\n",
    "station_zip_xref.columns = [\n",
    "        'station_id',\n",
    "        'route_identifier',\n",
    "        'route_number',\n",
    "        'station_lat',\n",
    "        'station_long',\n",
    "        'Zip',\n",
    "        'zip_lat',\n",
    "        'zip_long'\n",
    "    ]\n",
    "\n",
    "station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_zip_xref['distance_km'] = haversine_np(\n",
    "    station_zip_xref.station_long.values,\n",
    "    station_zip_xref.station_lat.values,\n",
    "    station_zip_xref.zip_long.values,\n",
    "    station_zip_xref.zip_lat.values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>route_identifier</th>\n",
       "      <th>route_number</th>\n",
       "      <th>station_lat</th>\n",
       "      <th>station_long</th>\n",
       "      <th>Zip</th>\n",
       "      <th>zip_lat</th>\n",
       "      <th>zip_long</th>\n",
       "      <th>distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29607</td>\n",
       "      <td>34.825592</td>\n",
       "      <td>-82.34099</td>\n",
       "      <td>50.578796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29164</td>\n",
       "      <td>33.659078</td>\n",
       "      <td>-81.40845</td>\n",
       "      <td>124.877525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29325</td>\n",
       "      <td>34.470115</td>\n",
       "      <td>-81.86761</td>\n",
       "      <td>54.263882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29520</td>\n",
       "      <td>34.688620</td>\n",
       "      <td>-79.92315</td>\n",
       "      <td>233.784632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>01040018500N</td>\n",
       "      <td>185.0</td>\n",
       "      <td>34.37925</td>\n",
       "      <td>-82.44926</td>\n",
       "      <td>29615</td>\n",
       "      <td>34.866801</td>\n",
       "      <td>-82.31739</td>\n",
       "      <td>55.504933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061833</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29592</td>\n",
       "      <td>34.283207</td>\n",
       "      <td>-79.47272</td>\n",
       "      <td>240.272498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061834</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29646</td>\n",
       "      <td>34.169781</td>\n",
       "      <td>-82.15474</td>\n",
       "      <td>70.885076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061835</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29142</td>\n",
       "      <td>33.462378</td>\n",
       "      <td>-80.50903</td>\n",
       "      <td>131.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061836</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29449</td>\n",
       "      <td>32.715745</td>\n",
       "      <td>-80.26738</td>\n",
       "      <td>180.818763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7061837</td>\n",
       "      <td>2607.0</td>\n",
       "      <td>02010052000E</td>\n",
       "      <td>520.0</td>\n",
       "      <td>33.56019</td>\n",
       "      <td>-81.92848</td>\n",
       "      <td>29564</td>\n",
       "      <td>33.493553</td>\n",
       "      <td>-79.87402</td>\n",
       "      <td>190.459639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7061838 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         station_id route_identifier  route_number  station_lat  station_long  \\\n",
       "0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       "...             ...              ...           ...          ...           ...   \n",
       "7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       "\n",
       "           Zip    zip_lat  zip_long  distance_km  \n",
       "0        29607  34.825592 -82.34099    50.578796  \n",
       "1        29164  33.659078 -81.40845   124.877525  \n",
       "2        29325  34.470115 -81.86761    54.263882  \n",
       "3        29520  34.688620 -79.92315   233.784632  \n",
       "4        29615  34.866801 -82.31739    55.504933  \n",
       "...        ...        ...       ...          ...  \n",
       "7061833  29592  34.283207 -79.47272   240.272498  \n",
       "7061834  29646  34.169781 -82.15474    70.885076  \n",
       "7061835  29142  33.462378 -80.50903   131.964450  \n",
       "7061836  29449  32.715745 -80.26738   180.818763  \n",
       "7061837  29564  33.493553 -79.87402   190.459639  \n",
       "\n",
       "[7061838 rows x 9 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'station_zip_xref' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4c0c70bdf1f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstation_zip_xref\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstation_zip_xref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance_km\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Zip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'distance_km'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'station_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_number'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_sales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZipCode'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sales'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Zip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ZipCode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'station_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'route_number'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mSales\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'station_zip_xref' is not defined"
     ]
    }
   ],
   "source": [
    "station_zip_xref \\\n",
    "    .loc[station_zip_xref.distance_km <= 50, ['Zip', 'distance_km', 'station_id', 'route_identifier', 'route_number']] \\\n",
    "    .merge(merged_sales[['ZipCode', 'Year', 'Sales']], left_on=['Zip'], right_on=['ZipCode']) \\\n",
    "    .groupby(['station_id', 'route_identifier', 'route_number', 'Year']) \\\n",
    "    .Sales \\\n",
    "    .sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point I can calculate the home sales within a certain radius of a station for the current year or previous year and see if that has any bearing on traffic patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Sales</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>29001</td>\n",
       "      <td>2008</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>29001</td>\n",
       "      <td>2009</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>29001</td>\n",
       "      <td>2010</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>29001</td>\n",
       "      <td>2011</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>29001</td>\n",
       "      <td>2012</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Alcolu</td>\n",
       "      <td>SC</td>\n",
       "      <td>33.769930</td>\n",
       "      <td>-80.17278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4507</td>\n",
       "      <td>29945</td>\n",
       "      <td>2015</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4508</td>\n",
       "      <td>29945</td>\n",
       "      <td>2016</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4509</td>\n",
       "      <td>29945</td>\n",
       "      <td>2017</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4510</td>\n",
       "      <td>29945</td>\n",
       "      <td>2018</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4511</td>\n",
       "      <td>29945</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Yemassee</td>\n",
       "      <td>SC</td>\n",
       "      <td>32.681058</td>\n",
       "      <td>-80.83348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4500 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ZipCode  Year  Sales      City State   Latitude  Longitude\n",
       "12      29001  2008   10.0    Alcolu    SC  33.769930  -80.17278\n",
       "13      29001  2009   10.0    Alcolu    SC  33.769930  -80.17278\n",
       "14      29001  2010   11.0    Alcolu    SC  33.769930  -80.17278\n",
       "15      29001  2011    8.0    Alcolu    SC  33.769930  -80.17278\n",
       "16      29001  2012    9.0    Alcolu    SC  33.769930  -80.17278\n",
       "...       ...   ...    ...       ...   ...        ...        ...\n",
       "4507    29945  2015   26.0  Yemassee    SC  32.681058  -80.83348\n",
       "4508    29945  2016   14.0  Yemassee    SC  32.681058  -80.83348\n",
       "4509    29945  2017   23.0  Yemassee    SC  32.681058  -80.83348\n",
       "4510    29945  2018   17.0  Yemassee    SC  32.681058  -80.83348\n",
       "4511    29945  2019    3.0  Yemassee    SC  32.681058  -80.83348\n",
       "\n",
       "[4500 rows x 7 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_home_sales(traffic_df, sales_df, zip_xref, radius_cutoff, curr_or_prev='curr'):\n",
    "    filtered_zips = zip_xref.loc[zip_xref.distance_km <= radius_cutoff]\n",
    "    sales_modified = sales_df.copy(deep=True)\n",
    "    sales_modified['next_year'] = sales_modified.Year + 1\n",
    "    sales_per_station = zip_xref.merge(sales_modified, how='left', left_on='Zip', right_on='ZipCode')\n",
    "    sales_per_station = sales_per_station.groupby(['station_id', 'route_identifier', 'route_number'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      ZipCode  Year  Sales      City State   Latitude  Longitude\n",
       " 12      29001  2008   10.0    Alcolu    SC  33.769930  -80.17278\n",
       " 13      29001  2009   10.0    Alcolu    SC  33.769930  -80.17278\n",
       " 14      29001  2010   11.0    Alcolu    SC  33.769930  -80.17278\n",
       " 15      29001  2011    8.0    Alcolu    SC  33.769930  -80.17278\n",
       " 16      29001  2012    9.0    Alcolu    SC  33.769930  -80.17278\n",
       " ...       ...   ...    ...       ...   ...        ...        ...\n",
       " 4507    29945  2015   26.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4508    29945  2016   14.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4509    29945  2017   23.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4510    29945  2018   17.0  Yemassee    SC  32.681058  -80.83348\n",
       " 4511    29945  2019    3.0  Yemassee    SC  32.681058  -80.83348\n",
       " \n",
       " [4500 rows x 7 columns],\n",
       "          station_id route_identifier  route_number  station_lat  station_long  \\\n",
       " 0             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 1             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 2             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 3             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " 4             100.0     01040018500N         185.0     34.37925     -82.44926   \n",
       " ...             ...              ...           ...          ...           ...   \n",
       " 7061833      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061834      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061835      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061836      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " 7061837      2607.0     02010052000E         520.0     33.56019     -81.92848   \n",
       " \n",
       "            Zip    zip_lat  zip_long  distance_km  \n",
       " 0        29607  34.825592 -82.34099    50.578796  \n",
       " 1        29164  33.659078 -81.40845   124.877525  \n",
       " 2        29325  34.470115 -81.86761    54.263882  \n",
       " 3        29520  34.688620 -79.92315   233.784632  \n",
       " 4        29615  34.866801 -82.31739    55.504933  \n",
       " ...        ...        ...       ...          ...  \n",
       " 7061833  29592  34.283207 -79.47272   240.272498  \n",
       " 7061834  29646  34.169781 -82.15474    70.885076  \n",
       " 7061835  29142  33.462378 -80.50903   131.964450  \n",
       " 7061836  29449  32.715745 -80.26738   180.818763  \n",
       " 7061837  29564  33.493553 -79.87402   190.459639  \n",
       " \n",
       " [7061838 rows x 9 columns])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_sales, station_zip_xref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generalprojects",
   "language": "python",
   "name": "generalprojects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
